2023-07-10 15:34:54,468 [INFO] [train.py:113] Namespace(arch='wide_resnet', num_workers=12, output_dirpath='./models-tmp/id-0000', batch_size=64, learning_rate=0.01, tau=1.0, tau_method='fixmatch', mu=7, loss_eps=0.0001, patience=20, embedding_dim=16, weight_decay=0.0005, cycle_factor=2.0, num_lr_reductions=2, epoch_size=1024, lr_reduction_factor=0.2, use_ema=False, ema_decay=0.999, pseudo_label_threshold=0.95, num_classes=10, num_labeled_datapoints=250, optimizer='sgd', strong_augmentation=True, debug=False, last_layer='fc', nprefc=0, use_tanh=0, num_epochs=None, trainer='supervised')
2023-07-10 15:34:54,468 [INFO] [train.py:125] Job running on host: g907732
2023-07-10 15:34:54,506 [INFO] [train.py:76] Total Model params: 1.47M
2023-07-10 15:34:56,163 [INFO] [train.py:139] writing args to config.json
2023-07-10 15:34:56,163 [INFO] [train.py:147] criterion setup
2023-07-10 15:34:56,163 [INFO] [train.py:157] trainer setup
2023-07-10 15:34:56,752 [INFO] [trainer.py:47] num decayed parameter tensors: 29, with 1463984 parameters
2023-07-10 15:34:56,752 [INFO] [trainer.py:48] num non-decayed parameter tensors: 51, with 3626 parameters
2023-07-10 15:34:56,752 [INFO] [trainer.py:52] Using SGD
2023-07-10 15:34:56,752 [INFO] [train.py:190] Epoch: 0
2023-07-10 15:34:56,759 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:34:58,248 [INFO] [trainer.py:122]   batch 0/1024  loss: 2.3499718  lr: 0.005029  cpu_mem: 22.5%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:35:00,463 [INFO] [trainer.py:122]   batch 100/1024  loss: 1.9096309  lr: 0.007959  cpu_mem: 22.5%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:35:02,749 [INFO] [trainer.py:122]   batch 200/1024  loss: 1.7519625  lr: 0.01089  cpu_mem: 22.5%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:35:04,956 [INFO] [trainer.py:122]   batch 300/1024  loss: 1.4816246  lr: 0.01382  cpu_mem: 22.5%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:35:07,227 [INFO] [trainer.py:122]   batch 400/1024  loss: 1.5124824  lr: 0.01675  cpu_mem: 22.5%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:35:09,430 [INFO] [trainer.py:122]   batch 500/1024  loss: 1.3702184  lr: 0.01968  cpu_mem: 22.5%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:35:11,640 [INFO] [trainer.py:122]   batch 600/1024  loss: 1.1269015  lr: 0.01739  cpu_mem: 22.5%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:35:13,840 [INFO] [trainer.py:122]   batch 700/1024  loss: 1.4051235  lr: 0.01446  cpu_mem: 22.5%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:35:16,090 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.97270107  lr: 0.01153  cpu_mem: 22.5%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:35:18,419 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.67797589  lr: 0.008604  cpu_mem: 22.6%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:35:20,702 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.71924692  lr: 0.005674  cpu_mem: 22.6%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:35:21,212 [INFO] [metadata.py:55] train_wall_time: 24.453046321868896
2023-07-10 15:35:21,213 [INFO] [metadata.py:55] train_loss: 1.393838408344891
2023-07-10 15:35:21,213 [INFO] [metadata.py:55] train_accuracy: 0.5154571533203125
2023-07-10 15:35:21,213 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:35:22,141 [INFO] [trainer.py:169]   batch 0/157  loss: 2.6863143  cpu_mem: 22.5%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:35:22,961 [INFO] [trainer.py:169]   batch 100/157  loss: 2.6799686  cpu_mem: 22.6%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:35:23,333 [INFO] [metadata.py:55] test_wall_time: 2.118955373764038
2023-07-10 15:35:23,333 [INFO] [metadata.py:55] test_loss: 2.290567959190174
2023-07-10 15:35:23,333 [INFO] [metadata.py:55] test_accuracy: 0.3927149681528662
2023-07-10 15:35:23,336 [INFO] [train.py:216] Updating best model with epoch: 0
2023-07-10 15:35:23,349 [INFO] [train.py:190] Epoch: 1
2023-07-10 15:35:23,877 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:35:24,815 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.72757071  lr: 0.005029  cpu_mem: 22.6%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:35:27,016 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.87639982  lr: 0.007959  cpu_mem: 22.6%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:35:29,243 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.56778389  lr: 0.01089  cpu_mem: 23.4%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:35:31,532 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.58250058  lr: 0.01382  cpu_mem: 23.4%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:35:33,816 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.99365664  lr: 0.01675  cpu_mem: 23.4%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:35:36,084 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.94478983  lr: 0.01968  cpu_mem: 23.4%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:35:38,400 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.93737757  lr: 0.01739  cpu_mem: 23.4%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:35:40,620 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.80568975  lr: 0.01446  cpu_mem: 23.4%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:35:42,947 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.52205157  lr: 0.01153  cpu_mem: 23.4%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:35:45,202 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.46888986  lr: 0.008604  cpu_mem: 23.4%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:35:47,447 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.45847827  lr: 0.005674  cpu_mem: 23.5%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:35:47,989 [INFO] [metadata.py:55] train_wall_time: 24.111778736114502
2023-07-10 15:35:47,989 [INFO] [metadata.py:55] train_loss: 0.6989476663729874
2023-07-10 15:35:47,989 [INFO] [metadata.py:55] train_accuracy: 0.7762908935546875
2023-07-10 15:35:47,990 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:35:48,891 [INFO] [trainer.py:169]   batch 0/157  loss: 2.6206648  cpu_mem: 22.6%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:35:49,712 [INFO] [trainer.py:169]   batch 100/157  loss: 2.6834235  cpu_mem: 22.7%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:35:50,064 [INFO] [metadata.py:55] test_wall_time: 2.073762893676758
2023-07-10 15:35:50,064 [INFO] [metadata.py:55] test_loss: 2.385268221994874
2023-07-10 15:35:50,064 [INFO] [metadata.py:55] test_accuracy: 0.4010748407643312
2023-07-10 15:35:50,066 [INFO] [train.py:216] Updating best model with epoch: 1
2023-07-10 15:35:50,079 [INFO] [train.py:190] Epoch: 2
2023-07-10 15:35:50,637 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:35:51,569 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.52647722  lr: 0.005029  cpu_mem: 22.6%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:35:53,915 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.59180427  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:35:56,131 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.72299403  lr: 0.01089  cpu_mem: 22.7%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:35:58,351 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.3741129  lr: 0.01382  cpu_mem: 22.7%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:36:00,632 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.55266017  lr: 0.01675  cpu_mem: 22.7%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:36:02,874 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.72791922  lr: 0.01968  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:05,085 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.38486466  lr: 0.01739  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:07,288 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.39954558  lr: 0.01446  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:09,608 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.47177175  lr: 0.01153  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:11,904 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.33732978  lr: 0.008604  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:14,242 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.41951421  lr: 0.005674  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:14,761 [INFO] [metadata.py:55] train_wall_time: 24.12434959411621
2023-07-10 15:36:14,762 [INFO] [metadata.py:55] train_loss: 0.4919397191988537
2023-07-10 15:36:14,762 [INFO] [metadata.py:55] train_accuracy: 0.845977783203125
2023-07-10 15:36:14,762 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:36:15,619 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1806445  cpu_mem: 22.6%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:16,447 [INFO] [trainer.py:169]   batch 100/157  loss: 3.0202777  cpu_mem: 22.6%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:16,819 [INFO] [metadata.py:55] test_wall_time: 2.056736707687378
2023-07-10 15:36:16,820 [INFO] [metadata.py:55] test_loss: 2.353023881365539
2023-07-10 15:36:16,820 [INFO] [metadata.py:55] test_accuracy: 0.42237261146496813
2023-07-10 15:36:16,822 [INFO] [train.py:216] Updating best model with epoch: 2
2023-07-10 15:36:16,834 [INFO] [train.py:190] Epoch: 3
2023-07-10 15:36:17,429 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:36:18,343 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.1559429  lr: 0.005029  cpu_mem: 22.6%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:20,499 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.42703652  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:22,729 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.48884955  lr: 0.01089  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:25,025 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.5985781  lr: 0.01382  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:27,279 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.41265708  lr: 0.01675  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:29,520 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.82285172  lr: 0.01968  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:31,700 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.62467939  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:33,944 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.47811154  lr: 0.01446  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:36,108 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.31898108  lr: 0.01153  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:38,324 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.28412974  lr: 0.008604  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:40,586 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.33729586  lr: 0.005674  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:41,067 [INFO] [metadata.py:55] train_wall_time: 23.63780379295349
2023-07-10 15:36:41,068 [INFO] [metadata.py:55] train_loss: 0.3904068924675812
2023-07-10 15:36:41,068 [INFO] [metadata.py:55] train_accuracy: 0.8763885498046875
2023-07-10 15:36:41,068 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:36:41,945 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9314563  cpu_mem: 22.6%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:36:42,727 [INFO] [trainer.py:169]   batch 100/157  loss: 2.711117  cpu_mem: 22.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:43,086 [INFO] [metadata.py:55] test_wall_time: 2.016908884048462
2023-07-10 15:36:43,086 [INFO] [metadata.py:55] test_loss: 1.963677626506538
2023-07-10 15:36:43,086 [INFO] [metadata.py:55] test_accuracy: 0.4635748407643312
2023-07-10 15:36:43,089 [INFO] [train.py:216] Updating best model with epoch: 3
2023-07-10 15:36:43,107 [INFO] [train.py:190] Epoch: 4
2023-07-10 15:36:43,681 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:36:44,584 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.19205242  lr: 0.005029  cpu_mem: 22.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:46,689 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.19677283  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:48,858 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.33648798  lr: 0.01089  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:51,162 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.4857406  lr: 0.01382  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:53,386 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.35028997  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:55,591 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.57038254  lr: 0.01968  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:57,731 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.47483242  lr: 0.01739  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:36:59,882 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.41401002  lr: 0.01446  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:02,062 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.39842209  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:04,415 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.30119029  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:06,736 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.22139098  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:07,228 [INFO] [metadata.py:55] train_wall_time: 23.546919345855713
2023-07-10 15:37:07,228 [INFO] [metadata.py:55] train_loss: 0.32292203914403217
2023-07-10 15:37:07,228 [INFO] [metadata.py:55] train_accuracy: 0.899871826171875
2023-07-10 15:37:07,229 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:37:08,172 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0591784  cpu_mem: 22.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:09,007 [INFO] [trainer.py:169]   batch 100/157  loss: 2.8754361  cpu_mem: 22.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:09,372 [INFO] [metadata.py:55] test_wall_time: 2.142620325088501
2023-07-10 15:37:09,372 [INFO] [metadata.py:55] test_loss: 2.225397364349122
2023-07-10 15:37:09,372 [INFO] [metadata.py:55] test_accuracy: 0.4576035031847134
2023-07-10 15:37:09,375 [INFO] [train.py:190] Epoch: 5
2023-07-10 15:37:09,955 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:37:10,925 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.19396468  lr: 0.005029  cpu_mem: 22.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:13,098 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.25148433  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:37:15,320 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.18559359  lr: 0.01089  cpu_mem: 22.7%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:37:17,632 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.26348302  lr: 0.01382  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:19,718 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.12846617  lr: 0.01675  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:21,801 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.30671033  lr: 0.01968  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:23,938 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.40502816  lr: 0.01739  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:26,169 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.34110552  lr: 0.01446  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:28,379 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.28722107  lr: 0.01153  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:30,632 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.27815977  lr: 0.008604  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:32,854 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.047141723  lr: 0.005674  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:33,397 [INFO] [metadata.py:55] train_wall_time: 23.441633462905884
2023-07-10 15:37:33,397 [INFO] [metadata.py:55] train_loss: 0.2652685027460393
2023-07-10 15:37:33,398 [INFO] [metadata.py:55] train_accuracy: 0.917144775390625
2023-07-10 15:37:33,398 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:37:34,288 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2051435  cpu_mem: 22.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:35,133 [INFO] [trainer.py:169]   batch 100/157  loss: 2.898046  cpu_mem: 22.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:35,505 [INFO] [metadata.py:55] test_wall_time: 2.1069676876068115
2023-07-10 15:37:35,506 [INFO] [metadata.py:55] test_loss: 2.2048254802728153
2023-07-10 15:37:35,506 [INFO] [metadata.py:55] test_accuracy: 0.4653662420382166
2023-07-10 15:37:35,508 [INFO] [train.py:216] Updating best model with epoch: 5
2023-07-10 15:37:35,521 [INFO] [train.py:190] Epoch: 6
2023-07-10 15:37:36,072 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:37:36,970 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.23473848  lr: 0.005029  cpu_mem: 22.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:39,205 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.25967473  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:41,485 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.23547252  lr: 0.01089  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:43,734 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.29248944  lr: 0.01382  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:45,972 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.31273741  lr: 0.01675  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:48,186 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.34259051  lr: 0.01968  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:50,484 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.36058334  lr: 0.01739  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:52,677 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.13760033  lr: 0.01446  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:54,917 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.31071806  lr: 0.01153  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:57,098 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.15445822  lr: 0.008604  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:59,322 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.12383409  lr: 0.005674  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:37:59,823 [INFO] [metadata.py:55] train_wall_time: 23.751116275787354
2023-07-10 15:37:59,823 [INFO] [metadata.py:55] train_loss: 0.23607154929777607
2023-07-10 15:37:59,823 [INFO] [metadata.py:55] train_accuracy: 0.9269561767578125
2023-07-10 15:37:59,824 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:38:00,716 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0574207  cpu_mem: 22.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:01,560 [INFO] [trainer.py:169]   batch 100/157  loss: 3.0864432  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:01,917 [INFO] [metadata.py:55] test_wall_time: 2.093203544616699
2023-07-10 15:38:01,918 [INFO] [metadata.py:55] test_loss: 2.131375172335631
2023-07-10 15:38:01,918 [INFO] [metadata.py:55] test_accuracy: 0.4608877388535032
2023-07-10 15:38:01,920 [INFO] [train.py:190] Epoch: 7
2023-07-10 15:38:02,468 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:38:03,358 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.15035798  lr: 0.005029  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:05,656 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.16210029  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:08,003 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.084866457  lr: 0.01089  cpu_mem: 23.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:10,322 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.19586751  lr: 0.01382  cpu_mem: 23.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:12,690 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.12415556  lr: 0.01675  cpu_mem: 23.6%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:38:15,175 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.15234835  lr: 0.01968  cpu_mem: 23.6%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:38:17,461 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.32531354  lr: 0.01739  cpu_mem: 23.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:19,801 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.32272395  lr: 0.01446  cpu_mem: 23.5%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:22,097 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.18705469  lr: 0.01153  cpu_mem: 23.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:24,416 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.15569231  lr: 0.008604  cpu_mem: 23.6%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:26,666 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.14290805  lr: 0.005674  cpu_mem: 23.5%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:27,151 [INFO] [metadata.py:55] train_wall_time: 24.68282961845398
2023-07-10 15:38:27,151 [INFO] [metadata.py:55] train_loss: 0.2107462630883674
2023-07-10 15:38:27,152 [INFO] [metadata.py:55] train_accuracy: 0.9358978271484375
2023-07-10 15:38:27,152 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:38:28,033 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9931716  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:38:28,856 [INFO] [trainer.py:169]   batch 100/157  loss: 2.7484708  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:38:29,203 [INFO] [metadata.py:55] test_wall_time: 2.0508058071136475
2023-07-10 15:38:29,203 [INFO] [metadata.py:55] test_loss: 2.023497489607258
2023-07-10 15:38:29,204 [INFO] [metadata.py:55] test_accuracy: 0.48815684713375795
2023-07-10 15:38:29,206 [INFO] [train.py:216] Updating best model with epoch: 7
2023-07-10 15:38:29,218 [INFO] [train.py:190] Epoch: 8
2023-07-10 15:38:29,800 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:38:30,806 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.055255607  lr: 0.005029  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:32,931 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.12703097  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:35,163 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.14021382  lr: 0.01089  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:37,360 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.1254686  lr: 0.01382  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:39,516 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.1753386  lr: 0.01675  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:41,758 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.29989967  lr: 0.01968  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:43,944 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.25011814  lr: 0.01739  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:46,074 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.20050941  lr: 0.01446  cpu_mem: 22.7%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:38:48,215 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.29472616  lr: 0.01153  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:38:50,446 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.10829599  lr: 0.008604  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:38:52,643 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.083430901  lr: 0.005674  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:38:53,119 [INFO] [metadata.py:55] train_wall_time: 23.31916570663452
2023-07-10 15:38:53,119 [INFO] [metadata.py:55] train_loss: 0.18949321788204543
2023-07-10 15:38:53,120 [INFO] [metadata.py:55] train_accuracy: 0.941741943359375
2023-07-10 15:38:53,120 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:38:54,009 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8271289  cpu_mem: 22.6%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:38:54,850 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4618754  cpu_mem: 22.6%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:38:55,262 [INFO] [metadata.py:55] test_wall_time: 2.1418509483337402
2023-07-10 15:38:55,262 [INFO] [metadata.py:55] test_loss: 2.0323955139536767
2023-07-10 15:38:55,263 [INFO] [metadata.py:55] test_accuracy: 0.48347929936305734
2023-07-10 15:38:55,265 [INFO] [train.py:190] Epoch: 9
2023-07-10 15:38:55,850 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:38:56,848 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.14770661  lr: 0.005029  cpu_mem: 22.7%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:38:59,136 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.12307457  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:01,487 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.11574215  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:39:03,627 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.38071841  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:39:05,708 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.22914577  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 15:39:07,918 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.28299782  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 15:39:10,145 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.24239823  lr: 0.01739  cpu_mem: 22.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:39:12,350 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.055818032  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:14,497 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.16017655  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:16,642 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0985955  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:18,828 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.13318783  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:19,337 [INFO] [metadata.py:55] train_wall_time: 23.487080335617065
2023-07-10 15:39:19,337 [INFO] [metadata.py:55] train_loss: 0.17418489673036675
2023-07-10 15:39:19,337 [INFO] [metadata.py:55] train_accuracy: 0.9464263916015625
2023-07-10 15:39:19,338 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:39:20,285 [INFO] [trainer.py:169]   batch 0/157  loss: 1.6313864  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:21,125 [INFO] [trainer.py:169]   batch 100/157  loss: 2.8427737  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:21,505 [INFO] [metadata.py:55] test_wall_time: 2.166696310043335
2023-07-10 15:39:21,505 [INFO] [metadata.py:55] test_loss: 2.00622849099955
2023-07-10 15:39:21,505 [INFO] [metadata.py:55] test_accuracy: 0.48556926751592355
2023-07-10 15:39:21,507 [INFO] [train.py:190] Epoch: 10
2023-07-10 15:39:22,033 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:39:22,965 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.060223281  lr: 0.005029  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:25,183 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.054352421  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:27,500 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.14094441  lr: 0.01089  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:29,775 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.17536941  lr: 0.01382  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:32,056 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.23851843  lr: 0.01675  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:34,316 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.23067652  lr: 0.01968  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:36,579 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.16193239  lr: 0.01739  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:38,879 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.26548785  lr: 0.01446  cpu_mem: 22.7%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:39:41,085 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.099892326  lr: 0.01153  cpu_mem: 22.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:39:43,304 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.084279008  lr: 0.008604  cpu_mem: 22.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:39:45,544 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.15688574  lr: 0.005674  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:39:46,055 [INFO] [metadata.py:55] train_wall_time: 24.02146577835083
2023-07-10 15:39:46,055 [INFO] [metadata.py:55] train_loss: 0.16072057974088239
2023-07-10 15:39:46,055 [INFO] [metadata.py:55] train_accuracy: 0.9504241943359375
2023-07-10 15:39:46,056 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:39:46,971 [INFO] [trainer.py:169]   batch 0/157  loss: 2.275732  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:39:47,884 [INFO] [trainer.py:169]   batch 100/157  loss: 2.7230055  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:39:48,275 [INFO] [metadata.py:55] test_wall_time: 2.219243288040161
2023-07-10 15:39:48,276 [INFO] [metadata.py:55] test_loss: 2.160692245337614
2023-07-10 15:39:48,276 [INFO] [metadata.py:55] test_accuracy: 0.4746218152866242
2023-07-10 15:39:48,278 [INFO] [train.py:190] Epoch: 11
2023-07-10 15:39:48,894 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:39:49,791 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.077885516  lr: 0.005029  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:39:52,092 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.071118414  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:39:54,476 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.2366602  lr: 0.01089  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:39:56,762 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.069744214  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:39:58,950 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.25351375  lr: 0.01675  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:01,193 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.18785784  lr: 0.01968  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:03,458 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.28256968  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:05,699 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.29033208  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:08,036 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.053135395  lr: 0.01153  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:10,276 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.1139704  lr: 0.008604  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:12,468 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.032721478  lr: 0.005674  cpu_mem: 22.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:40:12,960 [INFO] [metadata.py:55] train_wall_time: 24.065980195999146
2023-07-10 15:40:12,960 [INFO] [metadata.py:55] train_loss: 0.14772858052674565
2023-07-10 15:40:12,960 [INFO] [metadata.py:55] train_accuracy: 0.9543914794921875
2023-07-10 15:40:12,961 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:40:13,809 [INFO] [trainer.py:169]   batch 0/157  loss: 2.011471  cpu_mem: 22.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:40:14,673 [INFO] [trainer.py:169]   batch 100/157  loss: 2.7009733  cpu_mem: 22.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:40:15,049 [INFO] [metadata.py:55] test_wall_time: 2.0874857902526855
2023-07-10 15:40:15,049 [INFO] [metadata.py:55] test_loss: 2.034336200185642
2023-07-10 15:40:15,049 [INFO] [metadata.py:55] test_accuracy: 0.5050756369426752
2023-07-10 15:40:15,051 [INFO] [train.py:216] Updating best model with epoch: 11
2023-07-10 15:40:15,064 [INFO] [train.py:190] Epoch: 12
2023-07-10 15:40:15,692 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:40:16,682 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.07518664  lr: 0.005029  cpu_mem: 22.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:40:18,896 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.05306039  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:21,079 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.071127832  lr: 0.01089  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:23,242 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.15329275  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:25,413 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.16159144  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:27,630 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.18312283  lr: 0.01968  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:29,800 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.14403397  lr: 0.01739  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:32,102 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.28611323  lr: 0.01446  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:34,416 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.092535503  lr: 0.01153  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:36,675 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.2688778  lr: 0.008604  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:38,983 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.12084321  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:39,448 [INFO] [metadata.py:55] train_wall_time: 23.755800485610962
2023-07-10 15:40:39,449 [INFO] [metadata.py:55] train_loss: 0.13847025804625446
2023-07-10 15:40:39,449 [INFO] [metadata.py:55] train_accuracy: 0.957122802734375
2023-07-10 15:40:39,449 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:40:40,381 [INFO] [trainer.py:169]   batch 0/157  loss: 1.6495327  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:41,209 [INFO] [trainer.py:169]   batch 100/157  loss: 2.715816  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:41,563 [INFO] [metadata.py:55] test_wall_time: 2.113240957260132
2023-07-10 15:40:41,563 [INFO] [metadata.py:55] test_loss: 1.9033348598297994
2023-07-10 15:40:41,563 [INFO] [metadata.py:55] test_accuracy: 0.5075636942675159
2023-07-10 15:40:41,566 [INFO] [train.py:216] Updating best model with epoch: 12
2023-07-10 15:40:41,578 [INFO] [train.py:190] Epoch: 13
2023-07-10 15:40:42,165 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:40:43,196 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0098165628  lr: 0.005029  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:45,412 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.037599307  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:47,551 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.027119469  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:49,727 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.12919469  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:51,994 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.2130145  lr: 0.01675  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:54,193 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.11477888  lr: 0.01968  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:56,441 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.26198864  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:40:58,672 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.31366375  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:41:00,975 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.1468485  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:41:03,219 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.11010733  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:41:05,446 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.11580776  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:41:05,969 [INFO] [metadata.py:55] train_wall_time: 23.803865671157837
2023-07-10 15:41:05,970 [INFO] [metadata.py:55] train_loss: 0.1293722174928007
2023-07-10 15:41:05,970 [INFO] [metadata.py:55] train_accuracy: 0.960540771484375
2023-07-10 15:41:05,970 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:41:06,865 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9805485  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:41:07,701 [INFO] [trainer.py:169]   batch 100/157  loss: 2.336894  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:41:08,070 [INFO] [metadata.py:55] test_wall_time: 2.0987861156463623
2023-07-10 15:41:08,070 [INFO] [metadata.py:55] test_loss: 1.9449327591877834
2023-07-10 15:41:08,070 [INFO] [metadata.py:55] test_accuracy: 0.5019904458598726
2023-07-10 15:41:08,072 [INFO] [train.py:190] Epoch: 14
2023-07-10 15:41:08,684 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:41:09,679 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.13740985  lr: 0.005029  cpu_mem: 22.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:41:11,956 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.046241932  lr: 0.007959  cpu_mem: 22.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:41:14,242 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.064779907  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:41:16,550 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.14183444  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:41:18,890 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.22495712  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:41:21,216 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.16962637  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:41:23,556 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.081045277  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:41:25,854 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.27587226  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:41:28,102 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.099815652  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:41:30,359 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.043837864  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:41:32,663 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.12869857  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:41:33,229 [INFO] [metadata.py:55] train_wall_time: 24.544501543045044
2023-07-10 15:41:33,229 [INFO] [metadata.py:55] train_loss: 0.12406232239573001
2023-07-10 15:41:33,229 [INFO] [metadata.py:55] train_accuracy: 0.9608612060546875
2023-07-10 15:41:33,230 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:41:34,217 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7047143  cpu_mem: 22.8%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:41:35,078 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3509879  cpu_mem: 22.8%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:41:35,472 [INFO] [metadata.py:55] test_wall_time: 2.2414441108703613
2023-07-10 15:41:35,472 [INFO] [metadata.py:55] test_loss: 2.011801989215195
2023-07-10 15:41:35,472 [INFO] [metadata.py:55] test_accuracy: 0.49751194267515925
2023-07-10 15:41:35,474 [INFO] [train.py:190] Epoch: 15
2023-07-10 15:41:36,054 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:41:37,024 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.080924824  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:41:39,378 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.029528929  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:41:41,725 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.048307408  lr: 0.01089  cpu_mem: 23.3%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:41:44,071 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.10086265  lr: 0.01382  cpu_mem: 23.3%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:41:46,418 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.16278744  lr: 0.01675  cpu_mem: 23.4%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:41:48,755 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.12119119  lr: 0.01968  cpu_mem: 23.4%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:41:51,131 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.079942651  lr: 0.01739  cpu_mem: 23.3%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:41:53,424 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.11463034  lr: 0.01446  cpu_mem: 23.3%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:41:55,677 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.11867782  lr: 0.01153  cpu_mem: 23.3%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:41:58,024 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.11982299  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:42:00,283 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.039975878  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 15:42:00,793 [INFO] [metadata.py:55] train_wall_time: 24.73935580253601
2023-07-10 15:42:00,794 [INFO] [metadata.py:55] train_loss: 0.11846129384321102
2023-07-10 15:42:00,794 [INFO] [metadata.py:55] train_accuracy: 0.963897705078125
2023-07-10 15:42:00,794 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:42:01,679 [INFO] [trainer.py:169]   batch 0/157  loss:  1.78468  cpu_mem: 22.9%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 15:42:02,554 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2338228  cpu_mem: 22.9%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 15:42:02,932 [INFO] [metadata.py:55] test_wall_time: 2.1373109817504883
2023-07-10 15:42:02,932 [INFO] [metadata.py:55] test_loss: 1.9395504225591185
2023-07-10 15:42:02,932 [INFO] [metadata.py:55] test_accuracy: 0.48785828025477707
2023-07-10 15:42:02,935 [INFO] [train.py:190] Epoch: 16
2023-07-10 15:42:03,534 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:42:04,555 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.044472914  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:42:06,947 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.073947281  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 15:42:09,252 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.048650093  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 15:42:11,472 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.074635394  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:42:13,735 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.18028904  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:42:16,089 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.23270606  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:42:18,340 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.1507366  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:42:20,689 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.21308343  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:42:22,999 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.32840475  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 15:42:25,442 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.10816426  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:42:27,946 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.087266125  lr: 0.005674  cpu_mem: 23.4%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:42:28,462 [INFO] [metadata.py:55] train_wall_time: 24.927526473999023
2023-07-10 15:42:28,462 [INFO] [metadata.py:55] train_loss: 0.1163377208458769
2023-07-10 15:42:28,462 [INFO] [metadata.py:55] train_accuracy: 0.9637298583984375
2023-07-10 15:42:28,462 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:42:29,316 [INFO] [trainer.py:169]   batch 0/157  loss: 1.912528  cpu_mem: 23.3%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:42:30,178 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3378365  cpu_mem: 23.2%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:42:30,566 [INFO] [metadata.py:55] test_wall_time: 2.103389263153076
2023-07-10 15:42:30,566 [INFO] [metadata.py:55] test_loss: 2.0039738841876864
2023-07-10 15:42:30,567 [INFO] [metadata.py:55] test_accuracy: 0.5008957006369427
2023-07-10 15:42:30,569 [INFO] [train.py:190] Epoch: 17
2023-07-10 15:42:31,224 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:42:32,209 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.11184704  lr: 0.005029  cpu_mem: 23.3%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:42:34,456 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.055569325  lr: 0.007959  cpu_mem: 23.3%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:42:36,724 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.051812273  lr: 0.01089  cpu_mem: 23.3%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:42:38,951 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.07753972  lr: 0.01382  cpu_mem: 23.2%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:42:41,277 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.16213615  lr: 0.01675  cpu_mem: 23.3%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:42:43,503 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.10408068  lr: 0.01968  cpu_mem: 23.3%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:42:45,777 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.12259126  lr: 0.01739  cpu_mem: 23.3%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:42:47,974 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.078020275  lr: 0.01446  cpu_mem: 23.3%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:42:50,325 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.041365474  lr: 0.01153  cpu_mem: 23.2%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:42:52,635 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.061256934  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:42:54,935 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.088426381  lr: 0.005674  cpu_mem: 23.2%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:42:55,462 [INFO] [metadata.py:55] train_wall_time: 24.237797737121582
2023-07-10 15:42:55,462 [INFO] [metadata.py:55] train_loss: 0.1102691356163632
2023-07-10 15:42:55,462 [INFO] [metadata.py:55] train_accuracy: 0.9658050537109375
2023-07-10 15:42:55,463 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:42:56,378 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2158382  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:42:57,171 [INFO] [trainer.py:169]   batch 100/157  loss: 2.6659892  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:42:57,528 [INFO] [metadata.py:55] test_wall_time: 2.064409017562866
2023-07-10 15:42:57,528 [INFO] [metadata.py:55] test_loss: 2.1426191231247724
2023-07-10 15:42:57,528 [INFO] [metadata.py:55] test_accuracy: 0.4737261146496815
2023-07-10 15:42:57,530 [INFO] [train.py:190] Epoch: 18
2023-07-10 15:42:58,142 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:42:59,136 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.046933174  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:43:01,403 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.03914272  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:43:03,636 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.039862253  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:43:05,725 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.24035047  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:43:07,863 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.18843259  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:43:10,184 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.15953627  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:43:12,433 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.21762215  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:14,651 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.27545452  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:17,026 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.035849072  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:19,449 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.048510939  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:21,705 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.017985109  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:22,200 [INFO] [metadata.py:55] train_wall_time: 24.058299779891968
2023-07-10 15:43:22,201 [INFO] [metadata.py:55] train_loss: 0.10549471022704893
2023-07-10 15:43:22,201 [INFO] [metadata.py:55] train_accuracy: 0.96722412109375
2023-07-10 15:43:22,201 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:43:23,102 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2274303  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:24,052 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2597065  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:24,424 [INFO] [metadata.py:55] test_wall_time: 2.2219576835632324
2023-07-10 15:43:24,424 [INFO] [metadata.py:55] test_loss: 2.0005158216330656
2023-07-10 15:43:24,424 [INFO] [metadata.py:55] test_accuracy: 0.49751194267515925
2023-07-10 15:43:24,427 [INFO] [train.py:190] Epoch: 19
2023-07-10 15:43:25,011 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:43:26,013 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.019217633  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:28,251 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.063846193  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:30,503 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.052893262  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:32,733 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.02608119  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:35,005 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.18684563  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:37,224 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.058613885  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:39,387 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.058264244  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:41,538 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.10896709  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:43,777 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.15186585  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:46,017 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.08417961  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:43:48,215 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.049569752  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:43:48,718 [INFO] [metadata.py:55] train_wall_time: 23.706971883773804
2023-07-10 15:43:48,718 [INFO] [metadata.py:55] train_loss: 0.10183672174343883
2023-07-10 15:43:48,718 [INFO] [metadata.py:55] train_accuracy: 0.9678497314453125
2023-07-10 15:43:48,719 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:43:49,573 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2386074  cpu_mem: 23.0%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:43:50,384 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2171102  cpu_mem: 23.0%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:43:50,765 [INFO] [metadata.py:55] test_wall_time: 2.0456314086914062
2023-07-10 15:43:50,765 [INFO] [metadata.py:55] test_loss: 2.1076623208963188
2023-07-10 15:43:50,765 [INFO] [metadata.py:55] test_accuracy: 0.4987062101910828
2023-07-10 15:43:50,768 [INFO] [train.py:190] Epoch: 20
2023-07-10 15:43:51,429 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:43:52,392 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.026540224  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:43:54,646 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.058934715  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:43:56,921 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.03224374  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:43:59,239 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.06222827  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:44:01,576 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.25951424  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:44:03,871 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.11412657  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:44:06,195 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.25846678  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:44:08,563 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.14869419  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:44:10,762 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.10363574  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:44:13,078 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.14961258  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:44:15,337 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.030057564  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:44:15,816 [INFO] [metadata.py:55] train_wall_time: 24.38743495941162
2023-07-10 15:44:15,817 [INFO] [metadata.py:55] train_loss: 0.09898228660767927
2023-07-10 15:44:15,817 [INFO] [metadata.py:55] train_accuracy: 0.9695892333984375
2023-07-10 15:44:15,817 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:44:16,715 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1583774  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:44:17,572 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3855844  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:17,940 [INFO] [metadata.py:55] test_wall_time: 2.122648239135742
2023-07-10 15:44:17,941 [INFO] [metadata.py:55] test_loss: 2.0018677157201585
2023-07-10 15:44:17,941 [INFO] [metadata.py:55] test_accuracy: 0.5039808917197452
2023-07-10 15:44:17,943 [INFO] [train.py:190] Epoch: 21
2023-07-10 15:44:18,542 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:44:19,437 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.036313538  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:21,680 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.026192872  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:23,826 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.038530186  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:26,117 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.090578414  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:28,312 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.11168657  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:30,512 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.27365479  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:32,689 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.085169218  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:34,834 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.10938349  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:37,064 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.052976899  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:39,286 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.036063038  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:41,597 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.042127803  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:42,074 [INFO] [metadata.py:55] train_wall_time: 23.532009840011597
2023-07-10 15:44:42,074 [INFO] [metadata.py:55] train_loss: 0.09587908532284928
2023-07-10 15:44:42,074 [INFO] [metadata.py:55] train_accuracy: 0.9702606201171875
2023-07-10 15:44:42,075 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:44:42,992 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9502872  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:43,825 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0546103  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:44,182 [INFO] [metadata.py:55] test_wall_time: 2.106738567352295
2023-07-10 15:44:44,182 [INFO] [metadata.py:55] test_loss: 2.0457989326707877
2023-07-10 15:44:44,182 [INFO] [metadata.py:55] test_accuracy: 0.49562101910828027
2023-07-10 15:44:44,185 [INFO] [train.py:190] Epoch: 22
2023-07-10 15:44:44,733 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:44:45,646 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.015899712  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:47,933 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.060323302  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:44:50,216 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.046747874  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:44:52,596 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.1061575  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:44:54,844 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.055781286  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:44:57,149 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.1297195  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:44:59,395 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.20421481  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:01,662 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.12525903  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:03,936 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.052959125  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:06,228 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.044943571  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:08,492 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.090018965  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:09,047 [INFO] [metadata.py:55] train_wall_time: 24.31385564804077
2023-07-10 15:45:09,047 [INFO] [metadata.py:55] train_loss: 0.09485563251655549
2023-07-10 15:45:09,047 [INFO] [metadata.py:55] train_accuracy: 0.9715423583984375
2023-07-10 15:45:09,048 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:45:09,966 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8877391  cpu_mem: 22.9%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:10,844 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3529613  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:11,233 [INFO] [metadata.py:55] test_wall_time: 2.184684991836548
2023-07-10 15:45:11,233 [INFO] [metadata.py:55] test_loss: 1.9696101679164133
2023-07-10 15:45:11,233 [INFO] [metadata.py:55] test_accuracy: 0.512937898089172
2023-07-10 15:45:11,235 [INFO] [train.py:216] Updating best model with epoch: 22
2023-07-10 15:45:11,248 [INFO] [train.py:190] Epoch: 23
2023-07-10 15:45:11,833 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:45:12,752 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.068235382  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:45:14,970 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.09402135  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:45:17,106 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.022754664  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:19,435 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0363205  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:21,614 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.11936931  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:23,769 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.076431476  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:25,999 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.32086504  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:28,244 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.11723354  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:30,540 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.081846893  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:32,751 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.079857871  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:35,036 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.04849394  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:35,563 [INFO] [metadata.py:55] train_wall_time: 23.72949981689453
2023-07-10 15:45:35,563 [INFO] [metadata.py:55] train_loss: 0.09132336582842981
2023-07-10 15:45:35,563 [INFO] [metadata.py:55] train_accuracy: 0.9718475341796875
2023-07-10 15:45:35,563 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:45:36,450 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2720065  cpu_mem: 22.9%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:37,328 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4948549  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:37,692 [INFO] [metadata.py:55] test_wall_time: 2.1280574798583984
2023-07-10 15:45:37,692 [INFO] [metadata.py:55] test_loss: 2.0750462355887054
2023-07-10 15:45:37,692 [INFO] [metadata.py:55] test_accuracy: 0.4993033439490446
2023-07-10 15:45:37,695 [INFO] [train.py:190] Epoch: 24
2023-07-10 15:45:38,255 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:45:39,184 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.011211236  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:41,526 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.021654924  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:43,836 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.08560501  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:46,084 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.13322151  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:48,227 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.23034398  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:50,369 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.27703759  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:52,538 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.15535779  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:54,684 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.19440801  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:56,855 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.051852692  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:45:59,018 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.016410537  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:01,236 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.019818313  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:01,738 [INFO] [metadata.py:55] train_wall_time: 23.482167959213257
2023-07-10 15:46:01,738 [INFO] [metadata.py:55] train_loss: 0.08968237320823391
2023-07-10 15:46:01,738 [INFO] [metadata.py:55] train_accuracy: 0.9729461669921875
2023-07-10 15:46:01,739 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:46:02,685 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0021663  cpu_mem: 22.9%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:03,545 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4516094  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:03,923 [INFO] [metadata.py:55] test_wall_time: 2.1842992305755615
2023-07-10 15:46:03,924 [INFO] [metadata.py:55] test_loss: 2.0852924319589214
2023-07-10 15:46:03,924 [INFO] [metadata.py:55] test_accuracy: 0.5103503184713376
2023-07-10 15:46:03,926 [INFO] [train.py:190] Epoch: 25
2023-07-10 15:46:04,516 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:46:05,440 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.04541656  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:07,653 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.01019332  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:09,912 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.11575804  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:12,191 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.027644113  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:46:14,470 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.20980722  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:46:16,764 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.1247468  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:18,982 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.056200318  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:21,137 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.150538  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:23,277 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.031784277  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:25,378 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.1352859  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:27,548 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.02182731  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:28,024 [INFO] [metadata.py:55] train_wall_time: 23.507635831832886
2023-07-10 15:46:28,024 [INFO] [metadata.py:55] train_loss: 0.0870014827930845
2023-07-10 15:46:28,024 [INFO] [metadata.py:55] train_accuracy: 0.9731597900390625
2023-07-10 15:46:28,025 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:46:28,949 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3435934  cpu_mem: 22.9%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:29,752 [INFO] [trainer.py:169]   batch 100/157  loss: 2.9567337  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:30,172 [INFO] [metadata.py:55] test_wall_time: 2.147369623184204
2023-07-10 15:46:30,173 [INFO] [metadata.py:55] test_loss: 2.10488795474836
2023-07-10 15:46:30,173 [INFO] [metadata.py:55] test_accuracy: 0.504578025477707
2023-07-10 15:46:30,175 [INFO] [train.py:190] Epoch: 26
2023-07-10 15:46:30,730 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:46:31,718 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.028520672  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:33,802 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.041905172  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:35,879 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.037799314  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:37,931 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.14866114  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:40,068 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.032897871  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:42,240 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.1150827  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:46:44,530 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.048329294  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:46:46,712 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.16293614  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:46:48,919 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.17017165  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:46:51,133 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.044762719  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:46:53,292 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.11609681  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:46:53,775 [INFO] [metadata.py:55] train_wall_time: 23.04518699645996
2023-07-10 15:46:53,776 [INFO] [metadata.py:55] train_loss: 0.08449802069139878
2023-07-10 15:46:53,776 [INFO] [metadata.py:55] train_accuracy: 0.9737701416015625
2023-07-10 15:46:53,776 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:46:54,702 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1481488  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:46:55,554 [INFO] [trainer.py:169]   batch 100/157  loss: 2.5859158  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:46:55,936 [INFO] [metadata.py:55] test_wall_time: 2.1593871116638184
2023-07-10 15:46:55,936 [INFO] [metadata.py:55] test_loss: 2.196165549527308
2023-07-10 15:46:55,936 [INFO] [metadata.py:55] test_accuracy: 0.47929936305732485
2023-07-10 15:46:55,939 [INFO] [train.py:190] Epoch: 27
2023-07-10 15:46:56,577 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:46:57,516 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.044693664  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:46:59,807 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.023843562  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:47:02,145 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.064004324  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:47:04,398 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.083393879  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:47:06,843 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.022920514  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:47:09,002 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.14478613  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:47:11,175 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.16316693  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:47:13,365 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.10829474  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:47:15,588 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.021733869  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:47:17,832 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.048124637  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:20,125 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.045758545  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:20,623 [INFO] [metadata.py:55] train_wall_time: 24.04636859893799
2023-07-10 15:47:20,624 [INFO] [metadata.py:55] train_loss: 0.08287906196210315
2023-07-10 15:47:20,624 [INFO] [metadata.py:55] train_accuracy: 0.9747772216796875
2023-07-10 15:47:20,624 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:47:21,510 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8385794  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:22,398 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2350111  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:22,771 [INFO] [metadata.py:55] test_wall_time: 2.146813154220581
2023-07-10 15:47:22,772 [INFO] [metadata.py:55] test_loss: 2.03879985687839
2023-07-10 15:47:22,772 [INFO] [metadata.py:55] test_accuracy: 0.5001990445859873
2023-07-10 15:47:22,774 [INFO] [train.py:190] Epoch: 28
2023-07-10 15:47:23,350 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:47:24,361 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.10080968  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:26,630 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.045039937  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:28,856 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.021338753  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:31,148 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.054488357  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:33,423 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.084140539  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:35,583 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.052273598  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:37,739 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.10105143  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:39,884 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.031510685  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:42,108 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.029325247  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:47:44,403 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.020524377  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:47:46,736 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.082242638  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:47:47,243 [INFO] [metadata.py:55] train_wall_time: 23.89260697364807
2023-07-10 15:47:47,243 [INFO] [metadata.py:55] train_loss: 0.08492694649328314
2023-07-10 15:47:47,243 [INFO] [metadata.py:55] train_accuracy: 0.9739990234375
2023-07-10 15:47:47,244 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:47:48,203 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3124437  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:47:49,074 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4504948  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:47:49,440 [INFO] [metadata.py:55] test_wall_time: 2.1957223415374756
2023-07-10 15:47:49,440 [INFO] [metadata.py:55] test_loss: 2.1388355949122433
2023-07-10 15:47:49,440 [INFO] [metadata.py:55] test_accuracy: 0.498109076433121
2023-07-10 15:47:49,443 [INFO] [train.py:190] Epoch: 29
2023-07-10 15:47:50,010 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:47:51,033 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0058312756  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:47:53,370 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.11963459  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:47:55,668 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.10024708  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:47:58,110 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.15402366  lr: 0.01382  cpu_mem: 23.2%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:48:00,597 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.073873535  lr: 0.01675  cpu_mem: 23.5%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:48:02,968 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.13536249  lr: 0.01968  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:48:05,321 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.14364609  lr: 0.01739  cpu_mem: 23.4%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:48:07,614 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.14406347  lr: 0.01446  cpu_mem: 23.4%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:48:09,914 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.17876568  lr: 0.01153  cpu_mem: 23.3%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 15:48:12,202 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.032863736  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:48:14,463 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.060493153  lr: 0.005674  cpu_mem: 23.2%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:48:14,940 [INFO] [metadata.py:55] train_wall_time: 24.929766416549683
2023-07-10 15:48:14,940 [INFO] [metadata.py:55] train_loss: 0.0799400768189571
2023-07-10 15:48:14,941 [INFO] [metadata.py:55] train_accuracy: 0.9754486083984375
2023-07-10 15:48:14,941 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:48:15,760 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0963066  cpu_mem: 23.1%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:48:16,564 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2126446  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:48:16,965 [INFO] [metadata.py:55] test_wall_time: 2.0234553813934326
2023-07-10 15:48:16,965 [INFO] [metadata.py:55] test_loss: 2.0622767916150915
2023-07-10 15:48:16,965 [INFO] [metadata.py:55] test_accuracy: 0.4929339171974522
2023-07-10 15:48:16,968 [INFO] [train.py:190] Epoch: 30
2023-07-10 15:48:17,639 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:48:18,586 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.011050684  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:48:20,919 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.16312388  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:48:23,225 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.086587764  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:48:25,422 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.017444167  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:48:27,706 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.10726763  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:29,958 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.18298814  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:32,223 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.058709521  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:34,530 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.090215072  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:36,817 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.059188034  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:39,120 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.064949527  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:41,434 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.057748076  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:41,905 [INFO] [metadata.py:55] train_wall_time: 24.26483464241028
2023-07-10 15:48:41,905 [INFO] [metadata.py:55] train_loss: 0.07805361877387895
2023-07-10 15:48:41,905 [INFO] [metadata.py:55] train_accuracy: 0.975830078125
2023-07-10 15:48:41,905 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:48:42,816 [INFO] [trainer.py:169]   batch 0/157  loss: 2.104234  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:43,694 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1584008  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:44,088 [INFO] [metadata.py:55] test_wall_time: 2.181856870651245
2023-07-10 15:48:44,088 [INFO] [metadata.py:55] test_loss: 2.066668597755918
2023-07-10 15:48:44,088 [INFO] [metadata.py:55] test_accuracy: 0.509156050955414
2023-07-10 15:48:44,091 [INFO] [train.py:190] Epoch: 31
2023-07-10 15:48:44,671 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:48:45,635 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.087147206  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:47,955 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0030151566  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:50,256 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.032037616  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:52,539 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.044168301  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:48:54,731 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.13641132  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:48:57,166 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.067977488  lr: 0.01968  cpu_mem: 23.7%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:48:59,563 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.039896712  lr: 0.01739  cpu_mem: 23.6%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:49:01,987 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.016612321  lr: 0.01446  cpu_mem: 23.6%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:49:04,372 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.054097489  lr: 0.01153  cpu_mem: 23.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:49:06,797 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0063200379  lr: 0.008604  cpu_mem: 23.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:49:09,088 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.08298932  lr: 0.005674  cpu_mem: 23.8%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:49:09,609 [INFO] [metadata.py:55] train_wall_time: 24.937915802001953
2023-07-10 15:49:09,610 [INFO] [metadata.py:55] train_loss: 0.07512708670515167
2023-07-10 15:49:09,610 [INFO] [metadata.py:55] train_accuracy: 0.9774169921875
2023-07-10 15:49:09,610 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:49:10,564 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8177141  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:49:11,483 [INFO] [trainer.py:169]   batch 100/157  loss: 2.537709  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:49:11,878 [INFO] [metadata.py:55] test_wall_time: 2.2670974731445312
2023-07-10 15:49:11,878 [INFO] [metadata.py:55] test_loss: 1.9951250613874691
2023-07-10 15:49:11,878 [INFO] [metadata.py:55] test_accuracy: 0.5066679936305732
2023-07-10 15:49:11,881 [INFO] [train.py:190] Epoch: 32
2023-07-10 15:49:12,477 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:49:13,392 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0084854597  lr: 0.005029  cpu_mem: 23.6%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:15,691 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.052107614  lr: 0.007959  cpu_mem: 23.7%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:17,951 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.052646916  lr: 0.01089  cpu_mem: 23.7%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:49:20,260 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.016115448  lr: 0.01382  cpu_mem: 23.7%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:49:22,555 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.24850649  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:49:24,855 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.11704233  lr: 0.01968  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:49:27,071 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.079282396  lr: 0.01739  cpu_mem: 23.8%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:49:29,226 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.058185432  lr: 0.01446  cpu_mem: 23.8%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:49:31,464 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.2112473  lr: 0.01153  cpu_mem: 23.8%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:49:33,672 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.019025238  lr: 0.008604  cpu_mem: 23.7%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:36,040 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.03436001  lr: 0.005674  cpu_mem: 23.7%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:36,558 [INFO] [metadata.py:55] train_wall_time: 24.081378936767578
2023-07-10 15:49:36,559 [INFO] [metadata.py:55] train_loss: 0.07818988137842098
2023-07-10 15:49:36,559 [INFO] [metadata.py:55] train_accuracy: 0.9755706787109375
2023-07-10 15:49:36,559 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:49:37,420 [INFO] [trainer.py:169]   batch 0/157  loss: 1.820259  cpu_mem: 23.6%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:38,269 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9761928  cpu_mem: 23.7%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:38,657 [INFO] [metadata.py:55] test_wall_time: 2.0973384380340576
2023-07-10 15:49:38,657 [INFO] [metadata.py:55] test_loss: 2.0143514241382574
2023-07-10 15:49:38,657 [INFO] [metadata.py:55] test_accuracy: 0.492734872611465
2023-07-10 15:49:38,660 [INFO] [train.py:190] Epoch: 33
2023-07-10 15:49:39,252 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:49:40,237 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.15113048  lr: 0.005029  cpu_mem: 23.7%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:42,555 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.028881526  lr: 0.007959  cpu_mem: 23.9%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:44,849 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0083515607  lr: 0.01089  cpu_mem: 24.6%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:47,115 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.098686092  lr: 0.01382  cpu_mem: 24.7%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:49,388 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.18796277  lr: 0.01675  cpu_mem: 24.6%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:51,642 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.18220408  lr: 0.01968  cpu_mem: 24.6%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:53,866 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.021300066  lr: 0.01739  cpu_mem: 24.6%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:56,131 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.11370172  lr: 0.01446  cpu_mem: 24.6%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:49:58,443 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.081203513  lr: 0.01153  cpu_mem: 24.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:50:00,773 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.015590873  lr: 0.008604  cpu_mem: 24.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:50:03,190 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.10933308  lr: 0.005674  cpu_mem: 24.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:50:03,703 [INFO] [metadata.py:55] train_wall_time: 24.450443983078003
2023-07-10 15:50:03,703 [INFO] [metadata.py:55] train_loss: 0.07509783787008928
2023-07-10 15:50:03,703 [INFO] [metadata.py:55] train_accuracy: 0.976287841796875
2023-07-10 15:50:03,703 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:50:04,581 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8237233  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:50:05,437 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3146446  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:50:05,847 [INFO] [metadata.py:55] test_wall_time: 2.143040895462036
2023-07-10 15:50:05,847 [INFO] [metadata.py:55] test_loss: 1.9379745015672818
2023-07-10 15:50:05,847 [INFO] [metadata.py:55] test_accuracy: 0.5140326433121019
2023-07-10 15:50:05,850 [INFO] [train.py:216] Updating best model with epoch: 33
2023-07-10 15:50:05,863 [INFO] [train.py:190] Epoch: 34
2023-07-10 15:50:06,456 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:50:07,345 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0029820702  lr: 0.005029  cpu_mem: 23.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:50:09,601 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.1286016  lr: 0.007959  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:50:11,788 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0018496256  lr: 0.01089  cpu_mem: 23.7%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:50:14,124 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.024489406  lr: 0.01382  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:16,275 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.04059276  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:18,437 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.08140298  lr: 0.01968  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:20,575 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.021344699  lr: 0.01739  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:22,773 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.097106449  lr: 0.01446  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:25,028 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.018040253  lr: 0.01153  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:27,128 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.019841142  lr: 0.008604  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:29,311 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.061260935  lr: 0.005674  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:29,826 [INFO] [metadata.py:55] train_wall_time: 23.369081020355225
2023-07-10 15:50:29,826 [INFO] [metadata.py:55] train_loss: 0.07056600830730986
2023-07-10 15:50:29,826 [INFO] [metadata.py:55] train_accuracy: 0.97796630859375
2023-07-10 15:50:29,826 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:50:30,777 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0200639  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:31,594 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2457368  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:31,955 [INFO] [metadata.py:55] test_wall_time: 2.128551959991455
2023-07-10 15:50:31,956 [INFO] [metadata.py:55] test_loss: 2.025694658042519
2023-07-10 15:50:31,956 [INFO] [metadata.py:55] test_accuracy: 0.5256767515923567
2023-07-10 15:50:31,958 [INFO] [train.py:216] Updating best model with epoch: 34
2023-07-10 15:50:31,971 [INFO] [train.py:190] Epoch: 35
2023-07-10 15:50:32,554 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:50:33,461 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.018944366  lr: 0.005029  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:35,757 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.015326767  lr: 0.007959  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:37,918 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.067294136  lr: 0.01089  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:40,153 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.11249609  lr: 0.01382  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:42,303 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.075586669  lr: 0.01675  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:44,501 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.083714038  lr: 0.01968  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:46,946 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.18781556  lr: 0.01739  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:49,295 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.16989289  lr: 0.01446  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:51,537 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.2318576  lr: 0.01153  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:53,755 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.058047604  lr: 0.008604  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:56,065 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.06715852  lr: 0.005674  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:56,597 [INFO] [metadata.py:55] train_wall_time: 24.042316675186157
2023-07-10 15:50:56,597 [INFO] [metadata.py:55] train_loss: 0.07122764053826813
2023-07-10 15:50:56,597 [INFO] [metadata.py:55] train_accuracy: 0.9779052734375
2023-07-10 15:50:56,597 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:50:57,448 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8347914  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:58,314 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0430388  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:50:58,705 [INFO] [metadata.py:55] test_wall_time: 2.1069555282592773
2023-07-10 15:50:58,705 [INFO] [metadata.py:55] test_loss: 1.9125840375377874
2023-07-10 15:50:58,705 [INFO] [metadata.py:55] test_accuracy: 0.5227906050955414
2023-07-10 15:50:58,708 [INFO] [train.py:190] Epoch: 36
2023-07-10 15:50:59,315 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:51:00,265 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.013382376  lr: 0.005029  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:51:02,506 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0020222431  lr: 0.007959  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:51:04,819 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.018624242  lr: 0.01089  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:51:07,037 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.044502046  lr: 0.01382  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:51:09,305 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.075998038  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:51:11,734 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.12261873  lr: 0.01968  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:51:14,015 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.15316623  lr: 0.01739  cpu_mem: 23.7%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:51:16,430 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.05957615  lr: 0.01446  cpu_mem: 23.8%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:51:18,684 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.092293411  lr: 0.01153  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:21,068 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.11579288  lr: 0.008604  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:23,400 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.025685543  lr: 0.005674  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:23,888 [INFO] [metadata.py:55] train_wall_time: 24.57263946533203
2023-07-10 15:51:23,889 [INFO] [metadata.py:55] train_loss: 0.0715372074980678
2023-07-10 15:51:23,889 [INFO] [metadata.py:55] train_accuracy: 0.97802734375
2023-07-10 15:51:23,889 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:51:24,765 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9019692  cpu_mem: 23.5%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:25,599 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9971497  cpu_mem: 23.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:25,990 [INFO] [metadata.py:55] test_wall_time: 2.099972724914551
2023-07-10 15:51:25,990 [INFO] [metadata.py:55] test_loss: 2.02296232152137
2023-07-10 15:51:25,990 [INFO] [metadata.py:55] test_accuracy: 0.5133359872611465
2023-07-10 15:51:25,993 [INFO] [train.py:190] Epoch: 37
2023-07-10 15:51:26,601 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:51:27,510 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.036754727  lr: 0.005029  cpu_mem: 23.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:29,740 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.024390908  lr: 0.007959  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:31,943 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.073867053  lr: 0.01089  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:34,156 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.019747104  lr: 0.01382  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:36,415 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.058029793  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:38,616 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.17954378  lr: 0.01968  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:40,879 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.067065544  lr: 0.01739  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:43,078 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.072770126  lr: 0.01446  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:45,258 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.041652989  lr: 0.01153  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:47,532 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.11215004  lr: 0.008604  cpu_mem: 23.7%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:51:49,752 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0030519592  lr: 0.005674  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:50,295 [INFO] [metadata.py:55] train_wall_time: 23.694600820541382
2023-07-10 15:51:50,296 [INFO] [metadata.py:55] train_loss: 0.06891270722866238
2023-07-10 15:51:50,296 [INFO] [metadata.py:55] train_accuracy: 0.979156494140625
2023-07-10 15:51:50,296 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:51:51,224 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1086326  cpu_mem: 23.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:52,051 [INFO] [trainer.py:169]   batch 100/157  loss: 2.529408  cpu_mem: 23.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:52,428 [INFO] [metadata.py:55] test_wall_time: 2.1310415267944336
2023-07-10 15:51:52,428 [INFO] [metadata.py:55] test_loss: 2.071419767893044
2023-07-10 15:51:52,428 [INFO] [metadata.py:55] test_accuracy: 0.5057722929936306
2023-07-10 15:51:52,431 [INFO] [train.py:190] Epoch: 38
2023-07-10 15:51:53,021 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:51:53,961 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.12998451  lr: 0.005029  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:51:56,209 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.10077687  lr: 0.007959  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:51:58,507 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.039536003  lr: 0.01089  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:52:00,796 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.080444425  lr: 0.01382  cpu_mem: 23.7%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:52:02,930 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.10507966  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:52:05,105 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.050636481  lr: 0.01968  cpu_mem: 23.7%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:52:07,381 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.10604176  lr: 0.01739  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:52:09,564 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.088944137  lr: 0.01446  cpu_mem: 23.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:52:11,861 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.014093988  lr: 0.01153  cpu_mem: 23.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:52:14,183 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.072215848  lr: 0.008604  cpu_mem: 23.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:52:16,412 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.088645995  lr: 0.005674  cpu_mem: 23.6%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:52:16,956 [INFO] [metadata.py:55] train_wall_time: 23.934640884399414
2023-07-10 15:52:16,956 [INFO] [metadata.py:55] train_loss: 0.06699541437194512
2023-07-10 15:52:16,956 [INFO] [metadata.py:55] train_accuracy: 0.9791412353515625
2023-07-10 15:52:16,957 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:52:17,827 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1552045  cpu_mem: 23.6%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:52:18,749 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3232529  cpu_mem: 23.6%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:52:19,147 [INFO] [metadata.py:55] test_wall_time: 2.189279556274414
2023-07-10 15:52:19,147 [INFO] [metadata.py:55] test_loss: 2.006640212551044
2023-07-10 15:52:19,147 [INFO] [metadata.py:55] test_accuracy: 0.5178144904458599
2023-07-10 15:52:19,150 [INFO] [train.py:190] Epoch: 39
2023-07-10 15:52:19,740 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:52:20,687 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0079963449  lr: 0.005029  cpu_mem: 23.5%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:52:22,963 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.011798364  lr: 0.007959  cpu_mem: 23.6%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:52:25,325 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.094564445  lr: 0.01089  cpu_mem: 23.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:52:27,624 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.1263281  lr: 0.01382  cpu_mem: 23.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:52:29,802 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.030301889  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:52:32,116 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.087148942  lr: 0.01968  cpu_mem: 24.1%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:52:34,365 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.075231098  lr: 0.01739  cpu_mem: 24.1%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:52:36,713 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.17994744  lr: 0.01446  cpu_mem: 24.0%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:52:38,945 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.11565658  lr: 0.01153  cpu_mem: 23.9%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:52:41,244 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.018228402  lr: 0.008604  cpu_mem: 24.0%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:52:43,447 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.089223549  lr: 0.005674  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:52:43,965 [INFO] [metadata.py:55] train_wall_time: 24.224311590194702
2023-07-10 15:52:43,965 [INFO] [metadata.py:55] train_loss: 0.0666043870038493
2023-07-10 15:52:43,965 [INFO] [metadata.py:55] train_accuracy: 0.9795989990234375
2023-07-10 15:52:43,965 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:52:44,908 [INFO] [trainer.py:169]   batch 0/157  loss: 2.223382  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:52:45,767 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1182563  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:52:46,137 [INFO] [metadata.py:55] test_wall_time: 2.1713433265686035
2023-07-10 15:52:46,137 [INFO] [metadata.py:55] test_loss: 2.038424894308588
2023-07-10 15:52:46,138 [INFO] [metadata.py:55] test_accuracy: 0.502687101910828
2023-07-10 15:52:46,140 [INFO] [train.py:190] Epoch: 40
2023-07-10 15:52:46,745 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:52:47,639 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.083120704  lr: 0.005029  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:52:49,987 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0043360214  lr: 0.007959  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:52:52,292 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.028723501  lr: 0.01089  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:52:54,511 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.063275002  lr: 0.01382  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:52:56,812 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.071491063  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:52:59,152 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.087589465  lr: 0.01968  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:53:01,381 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.08321216  lr: 0.01739  cpu_mem: 23.7%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:53:03,678 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.053259075  lr: 0.01446  cpu_mem: 23.7%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:53:06,130 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.033727907  lr: 0.01153  cpu_mem: 23.8%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:53:08,419 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.12609555  lr: 0.008604  cpu_mem: 23.8%  gpu_mem: [11.0]% of [20470]MiB
2023-07-10 15:53:10,698 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.035108749  lr: 0.005674  cpu_mem: 23.8%  gpu_mem: [10.8]% of [20470]MiB
2023-07-10 15:53:11,209 [INFO] [metadata.py:55] train_wall_time: 24.463874101638794
2023-07-10 15:53:11,209 [INFO] [metadata.py:55] train_loss: 0.06664744456361404
2023-07-10 15:53:11,209 [INFO] [metadata.py:55] train_accuracy: 0.9795379638671875
2023-07-10 15:53:11,210 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:53:12,108 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1555951  cpu_mem: 23.7%  gpu_mem: [10.5]% of [20470]MiB
2023-07-10 15:53:12,968 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2273035  cpu_mem: 23.7%  gpu_mem: [10.5]% of [20470]MiB
2023-07-10 15:53:13,356 [INFO] [metadata.py:55] test_wall_time: 2.145648956298828
2023-07-10 15:53:13,356 [INFO] [metadata.py:55] test_loss: 1.923728244319843
2023-07-10 15:53:13,356 [INFO] [metadata.py:55] test_accuracy: 0.5141321656050956
2023-07-10 15:53:13,359 [INFO] [train.py:190] Epoch: 41
2023-07-10 15:53:13,995 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:53:14,928 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.011263396  lr: 0.005029  cpu_mem: 23.7%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 15:53:17,184 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0086429268  lr: 0.007959  cpu_mem: 23.7%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:53:19,445 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.068896018  lr: 0.01089  cpu_mem: 23.7%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:53:21,674 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.12508912  lr: 0.01382  cpu_mem: 23.7%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:53:23,907 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.050617743  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 15:53:26,208 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.053676594  lr: 0.01968  cpu_mem: 23.8%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:53:28,420 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.1506267  lr: 0.01739  cpu_mem: 23.8%  gpu_mem: [10.5]% of [20470]MiB
2023-07-10 15:53:30,587 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.088657677  lr: 0.01446  cpu_mem: 23.8%  gpu_mem: [10.5]% of [20470]MiB
2023-07-10 15:53:32,836 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.046904821  lr: 0.01153  cpu_mem: 23.8%  gpu_mem: [10.5]% of [20470]MiB
2023-07-10 15:53:35,003 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.064790294  lr: 0.008604  cpu_mem: 23.7%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:53:37,212 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.02761724  lr: 0.005674  cpu_mem: 23.7%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:53:37,708 [INFO] [metadata.py:55] train_wall_time: 23.712379693984985
2023-07-10 15:53:37,708 [INFO] [metadata.py:55] train_loss: 0.06645735761583182
2023-07-10 15:53:37,708 [INFO] [metadata.py:55] train_accuracy: 0.9794158935546875
2023-07-10 15:53:37,709 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:53:38,617 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8960226  cpu_mem: 23.6%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:53:39,467 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2492206  cpu_mem: 23.6%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:53:39,845 [INFO] [metadata.py:55] test_wall_time: 2.1354918479919434
2023-07-10 15:53:39,845 [INFO] [metadata.py:55] test_loss: 2.0039449246825685
2023-07-10 15:53:39,845 [INFO] [metadata.py:55] test_accuracy: 0.5120421974522293
2023-07-10 15:53:39,848 [INFO] [train.py:190] Epoch: 42
2023-07-10 15:53:40,437 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:53:41,322 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.027397178  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 15:53:43,662 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.15671393  lr: 0.007959  cpu_mem: 23.2%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 15:53:46,025 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.051631078  lr: 0.01089  cpu_mem: 23.7%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:53:48,382 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.076132588  lr: 0.01382  cpu_mem: 23.9%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:53:50,714 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.054440867  lr: 0.01675  cpu_mem: 23.9%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:53:53,152 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.10424885  lr: 0.01968  cpu_mem: 23.9%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:53:55,516 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.071424559  lr: 0.01739  cpu_mem: 23.9%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:53:57,754 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.026571065  lr: 0.01446  cpu_mem: 23.9%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:54:00,097 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.04751524  lr: 0.01153  cpu_mem: 23.8%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:54:02,422 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.056840271  lr: 0.008604  cpu_mem: 23.8%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:54:04,765 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0054058195  lr: 0.005674  cpu_mem: 23.8%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:54:05,339 [INFO] [metadata.py:55] train_wall_time: 24.902083158493042
2023-07-10 15:54:05,339 [INFO] [metadata.py:55] train_loss: 0.06614319834113758
2023-07-10 15:54:05,339 [INFO] [metadata.py:55] train_accuracy: 0.98016357421875
2023-07-10 15:54:05,340 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:54:06,224 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0462399  cpu_mem: 23.7%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:54:07,125 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2230358  cpu_mem: 23.7%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:54:07,504 [INFO] [metadata.py:55] test_wall_time: 2.163418769836426
2023-07-10 15:54:07,504 [INFO] [metadata.py:55] test_loss: 2.0325317451149036
2023-07-10 15:54:07,504 [INFO] [metadata.py:55] test_accuracy: 0.5084593949044586
2023-07-10 15:54:07,507 [INFO] [train.py:190] Epoch: 43
2023-07-10 15:54:08,151 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:54:09,200 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.024452144  lr: 0.005029  cpu_mem: 23.7%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:54:11,525 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.036166787  lr: 0.007959  cpu_mem: 23.8%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:54:13,824 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.020587679  lr: 0.01089  cpu_mem: 23.7%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:54:16,256 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.030667625  lr: 0.01382  cpu_mem: 23.7%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:54:18,580 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.042481955  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [10.5]% of [20470]MiB
2023-07-10 15:54:20,847 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.17205226  lr: 0.01968  cpu_mem: 23.7%  gpu_mem: [10.6]% of [20470]MiB
2023-07-10 15:54:23,094 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.1115691  lr: 0.01739  cpu_mem: 23.7%  gpu_mem: [10.6]% of [20470]MiB
2023-07-10 15:54:25,354 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.1154009  lr: 0.01446  cpu_mem: 23.7%  gpu_mem: [10.6]% of [20470]MiB
2023-07-10 15:54:27,559 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.035677869  lr: 0.01153  cpu_mem: 23.7%  gpu_mem: [10.6]% of [20470]MiB
2023-07-10 15:54:29,760 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0034832137  lr: 0.008604  cpu_mem: 23.7%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:54:31,956 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.043805275  lr: 0.005674  cpu_mem: 23.6%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:54:32,448 [INFO] [metadata.py:55] train_wall_time: 24.296264171600342
2023-07-10 15:54:32,448 [INFO] [metadata.py:55] train_loss: 0.06519027259417953
2023-07-10 15:54:32,448 [INFO] [metadata.py:55] train_accuracy: 0.980133056640625
2023-07-10 15:54:32,448 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:54:33,311 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7705544  cpu_mem: 23.6%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:54:34,131 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1064301  cpu_mem: 23.6%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 15:54:34,492 [INFO] [metadata.py:55] test_wall_time: 2.0428037643432617
2023-07-10 15:54:34,492 [INFO] [metadata.py:55] test_loss: 2.0514926834470906
2023-07-10 15:54:34,492 [INFO] [metadata.py:55] test_accuracy: 0.5153264331210191
2023-07-10 15:54:34,495 [INFO] [train.py:190] Epoch: 44
2023-07-10 15:54:35,049 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:54:35,969 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.025769649  lr: 0.005029  cpu_mem: 23.6%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:54:38,256 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0062348749  lr: 0.007959  cpu_mem: 23.6%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:54:40,594 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.071651652  lr: 0.01089  cpu_mem: 23.7%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:54:42,843 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0059506642  lr: 0.01382  cpu_mem: 23.7%  gpu_mem: [10.2]% of [20470]MiB
2023-07-10 15:54:45,177 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.12798515  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:54:47,500 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.1285989  lr: 0.01968  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:54:49,850 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.10402569  lr: 0.01739  cpu_mem: 23.7%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:54:52,254 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.10111956  lr: 0.01446  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:54:54,680 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.063822836  lr: 0.01153  cpu_mem: 23.8%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:54:56,977 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.034674052  lr: 0.008604  cpu_mem: 23.8%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 15:54:59,297 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.052024644  lr: 0.005674  cpu_mem: 23.7%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:54:59,791 [INFO] [metadata.py:55] train_wall_time: 24.74177837371826
2023-07-10 15:54:59,792 [INFO] [metadata.py:55] train_loss: 0.06465093907604569
2023-07-10 15:54:59,792 [INFO] [metadata.py:55] train_accuracy: 0.980224609375
2023-07-10 15:54:59,792 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:55:00,751 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9228719  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:01,641 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0823395  cpu_mem: 23.7%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:02,009 [INFO] [metadata.py:55] test_wall_time: 2.216181516647339
2023-07-10 15:55:02,009 [INFO] [metadata.py:55] test_loss: 1.9526537094905878
2023-07-10 15:55:02,009 [INFO] [metadata.py:55] test_accuracy: 0.5186106687898089
2023-07-10 15:55:02,012 [INFO] [train.py:190] Epoch: 45
2023-07-10 15:55:02,626 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:55:03,544 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.045334324  lr: 0.005029  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:05,882 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.11262009  lr: 0.007959  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:08,127 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.15903403  lr: 0.01089  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:10,468 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.031216098  lr: 0.01382  cpu_mem: 23.6%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:55:12,792 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.06201021  lr: 0.01675  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:15,051 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.010184448  lr: 0.01968  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:17,299 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.072788902  lr: 0.01739  cpu_mem: 23.6%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:19,460 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.14547202  lr: 0.01446  cpu_mem: 23.7%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:21,785 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.035949692  lr: 0.01153  cpu_mem: 23.7%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:24,198 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.10163532  lr: 0.008604  cpu_mem: 23.9%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:26,579 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.063821785  lr: 0.005674  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:27,089 [INFO] [metadata.py:55] train_wall_time: 24.463366746902466
2023-07-10 15:55:27,090 [INFO] [metadata.py:55] train_loss: 0.06451511574562119
2023-07-10 15:55:27,090 [INFO] [metadata.py:55] train_accuracy: 0.98046875
2023-07-10 15:55:27,090 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:55:28,024 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8089492  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:28,913 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4147182  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:29,302 [INFO] [metadata.py:55] test_wall_time: 2.2115378379821777
2023-07-10 15:55:29,302 [INFO] [metadata.py:55] test_loss: 1.9922066516936965
2023-07-10 15:55:29,303 [INFO] [metadata.py:55] test_accuracy: 0.5235867834394905
2023-07-10 15:55:29,305 [INFO] [train.py:190] Epoch: 46
2023-07-10 15:55:29,893 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:55:30,847 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.055169255  lr: 0.005029  cpu_mem: 23.9%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:33,082 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.018918779  lr: 0.007959  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:35,311 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.038694702  lr: 0.01089  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:37,484 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.091074705  lr: 0.01382  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:39,704 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.087139942  lr: 0.01675  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:42,008 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.035294104  lr: 0.01968  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:44,332 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.15535562  lr: 0.01739  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:46,712 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.16863576  lr: 0.01446  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:49,122 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.012634507  lr: 0.01153  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:51,443 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.012401343  lr: 0.008604  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:53,745 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.022365546  lr: 0.005674  cpu_mem: 24.2%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:54,260 [INFO] [metadata.py:55] train_wall_time: 24.366726875305176
2023-07-10 15:55:54,260 [INFO] [metadata.py:55] train_loss: 0.06304359030229989
2023-07-10 15:55:54,260 [INFO] [metadata.py:55] train_accuracy: 0.9805908203125
2023-07-10 15:55:54,260 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:55:55,096 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0739982  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:56,021 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1328294  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:55:56,420 [INFO] [metadata.py:55] test_wall_time: 2.1592917442321777
2023-07-10 15:55:56,421 [INFO] [metadata.py:55] test_loss: 2.0238532017750344
2023-07-10 15:55:56,421 [INFO] [metadata.py:55] test_accuracy: 0.5188097133757962
2023-07-10 15:55:56,423 [INFO] [train.py:190] Epoch: 47
2023-07-10 15:55:56,991 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:55:57,940 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.01306292  lr: 0.005029  cpu_mem: 24.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:56:00,290 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.02246543  lr: 0.007959  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:56:02,636 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0031563679  lr: 0.01089  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:56:04,977 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.029001275  lr: 0.01382  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:56:07,267 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.03496132  lr: 0.01675  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:56:09,664 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.034142673  lr: 0.01968  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:56:11,958 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.023810381  lr: 0.01739  cpu_mem: 24.1%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:56:14,310 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.17329767  lr: 0.01446  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:56:16,659 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.020307776  lr: 0.01153  cpu_mem: 24.1%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:56:19,095 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.026092768  lr: 0.008604  cpu_mem: 24.1%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:21,466 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.036233671  lr: 0.005674  cpu_mem: 24.2%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:21,952 [INFO] [metadata.py:55] train_wall_time: 24.960641622543335
2023-07-10 15:56:21,952 [INFO] [metadata.py:55] train_loss: 0.05989929285817652
2023-07-10 15:56:21,953 [INFO] [metadata.py:55] train_accuracy: 0.9814300537109375
2023-07-10 15:56:21,953 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:56:22,902 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2787144  cpu_mem: 24.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:23,709 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4999523  cpu_mem: 24.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:24,071 [INFO] [metadata.py:55] test_wall_time: 2.1178882122039795
2023-07-10 15:56:24,072 [INFO] [metadata.py:55] test_loss: 2.147008158598736
2023-07-10 15:56:24,072 [INFO] [metadata.py:55] test_accuracy: 0.4912420382165605
2023-07-10 15:56:24,075 [INFO] [train.py:190] Epoch: 48
2023-07-10 15:56:24,662 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:56:25,693 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0067690453  lr: 0.005029  cpu_mem: 23.6%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:27,921 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.060532082  lr: 0.007959  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:30,256 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.055791739  lr: 0.01089  cpu_mem: 23.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:32,571 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.084724121  lr: 0.01382  cpu_mem: 23.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:34,899 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.066165611  lr: 0.01675  cpu_mem: 23.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:37,147 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.053385429  lr: 0.01968  cpu_mem: 23.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:39,464 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0089605134  lr: 0.01739  cpu_mem: 23.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:41,837 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.029034847  lr: 0.01446  cpu_mem: 23.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:44,102 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.060072638  lr: 0.01153  cpu_mem: 23.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:46,362 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.084869117  lr: 0.008604  cpu_mem: 23.9%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:48,678 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0063510137  lr: 0.005674  cpu_mem: 23.9%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 15:56:49,217 [INFO] [metadata.py:55] train_wall_time: 24.55496048927307
2023-07-10 15:56:49,217 [INFO] [metadata.py:55] train_loss: 0.061013557470346313
2023-07-10 15:56:49,217 [INFO] [metadata.py:55] train_accuracy: 0.9814453125
2023-07-10 15:56:49,218 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:56:50,101 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1739442  cpu_mem: 23.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:50,994 [INFO] [trainer.py:169]   batch 100/157  loss: 2.121273  cpu_mem: 23.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:51,370 [INFO] [metadata.py:55] test_wall_time: 2.1520755290985107
2023-07-10 15:56:51,371 [INFO] [metadata.py:55] test_loss: 2.021868943408796
2023-07-10 15:56:51,371 [INFO] [metadata.py:55] test_accuracy: 0.51453025477707
2023-07-10 15:56:51,373 [INFO] [train.py:190] Epoch: 49
2023-07-10 15:56:51,970 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:56:52,920 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.071412355  lr: 0.005029  cpu_mem: 23.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:55,255 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.039359618  lr: 0.007959  cpu_mem: 23.7%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:56:57,559 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.026434138  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 15:56:59,812 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.057996437  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:57:01,995 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.11431281  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 15:57:04,369 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.1872808  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:57:06,622 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.044720452  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 15:57:08,865 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0773983  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 15:57:11,044 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.070718847  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 15:57:13,405 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.01495335  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:57:15,617 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.033990242  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:57:16,152 [INFO] [metadata.py:55] train_wall_time: 24.182249546051025
2023-07-10 15:57:16,153 [INFO] [metadata.py:55] train_loss: 0.060718196710467964
2023-07-10 15:57:16,153 [INFO] [metadata.py:55] train_accuracy: 0.981048583984375
2023-07-10 15:57:16,153 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:57:17,095 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2103517  cpu_mem: 22.7%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:57:17,940 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0318611  cpu_mem: 22.8%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:57:18,313 [INFO] [metadata.py:55] test_wall_time: 2.159921646118164
2023-07-10 15:57:18,314 [INFO] [metadata.py:55] test_loss: 2.0350491142576668
2023-07-10 15:57:18,314 [INFO] [metadata.py:55] test_accuracy: 0.5106488853503185
2023-07-10 15:57:18,316 [INFO] [train.py:190] Epoch: 50
2023-07-10 15:57:18,949 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:57:19,920 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0092236185  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:57:22,264 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0071903258  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:57:24,613 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0062705157  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 15:57:26,997 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.026050042  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:57:29,419 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0022241336  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:57:31,812 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.092294492  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:57:34,043 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.039997563  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:57:36,439 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.013616001  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:57:38,726 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.021184687  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:57:41,093 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.024692135  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:57:43,468 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0076534757  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:57:43,985 [INFO] [metadata.py:55] train_wall_time: 25.035473108291626
2023-07-10 15:57:43,985 [INFO] [metadata.py:55] train_loss: 0.05737196519601184
2023-07-10 15:57:43,985 [INFO] [metadata.py:55] train_accuracy: 0.9823455810546875
2023-07-10 15:57:43,985 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:57:44,977 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2923412  cpu_mem: 22.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:57:45,894 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9090139  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:57:46,257 [INFO] [metadata.py:55] test_wall_time: 2.271348714828491
2023-07-10 15:57:46,258 [INFO] [metadata.py:55] test_loss: 2.05311677030697
2023-07-10 15:57:46,258 [INFO] [metadata.py:55] test_accuracy: 0.5088574840764332
2023-07-10 15:57:46,260 [INFO] [train.py:190] Epoch: 51
2023-07-10 15:57:46,826 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:57:47,731 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0017317367  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:57:49,988 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.024006497  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:57:52,259 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.017442651  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:57:54,596 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.049637105  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:57:56,982 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.021606846  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:57:59,299 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.042591553  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:58:01,583 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.10879147  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:58:03,871 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.19233333  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:06,249 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.059822276  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:08,550 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.081341282  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:58:10,797 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.034032494  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:58:11,317 [INFO] [metadata.py:55] train_wall_time: 24.490861892700195
2023-07-10 15:58:11,318 [INFO] [metadata.py:55] train_loss: 0.06022920517136754
2023-07-10 15:58:11,318 [INFO] [metadata.py:55] train_accuracy: 0.9811859130859375
2023-07-10 15:58:11,318 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:58:12,204 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1152532  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:13,017 [INFO] [trainer.py:169]   batch 100/157  loss: 2.624263  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:13,371 [INFO] [metadata.py:55] test_wall_time: 2.052370548248291
2023-07-10 15:58:13,371 [INFO] [metadata.py:55] test_loss: 2.1083603239363167
2023-07-10 15:58:13,371 [INFO] [metadata.py:55] test_accuracy: 0.5203025477707006
2023-07-10 15:58:13,374 [INFO] [train.py:190] Epoch: 52
2023-07-10 15:58:13,944 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:58:14,936 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0074411104  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:17,232 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.08383546  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:19,490 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0058376854  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:21,705 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.23727991  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:23,918 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.026535265  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:26,136 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.1159306  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:28,427 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.024764452  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:30,668 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0094077215  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:32,912 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.02056792  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:58:35,063 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.019018445  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 15:58:37,243 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.023926364  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:37,732 [INFO] [metadata.py:55] train_wall_time: 23.78785514831543
2023-07-10 15:58:37,733 [INFO] [metadata.py:55] train_loss: 0.05892405112376764
2023-07-10 15:58:37,733 [INFO] [metadata.py:55] train_accuracy: 0.981689453125
2023-07-10 15:58:37,733 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:58:38,616 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2379506  cpu_mem: 22.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:39,447 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4500809  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:39,813 [INFO] [metadata.py:55] test_wall_time: 2.079401731491089
2023-07-10 15:58:39,813 [INFO] [metadata.py:55] test_loss: 2.0223436932654897
2023-07-10 15:58:39,813 [INFO] [metadata.py:55] test_accuracy: 0.5248805732484076
2023-07-10 15:58:39,816 [INFO] [train.py:190] Epoch: 53
2023-07-10 15:58:40,478 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:58:41,407 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0035982232  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:43,695 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.060627554  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:46,033 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.043821536  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:48,194 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.01894805  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:50,523 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.09600988  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:52,818 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.09633147  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:55,145 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.011377219  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:57,342 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.020029927  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:58:59,470 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.032738477  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:59:01,676 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0049253688  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:59:03,864 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0069437013  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:59:04,392 [INFO] [metadata.py:55] train_wall_time: 23.913283824920654
2023-07-10 15:59:04,392 [INFO] [metadata.py:55] train_loss: 0.05922162483960847
2023-07-10 15:59:04,392 [INFO] [metadata.py:55] train_accuracy: 0.982513427734375
2023-07-10 15:59:04,393 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:59:05,244 [INFO] [trainer.py:169]   batch 0/157  loss: 2.4976254  cpu_mem: 22.8%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:59:06,097 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4127758  cpu_mem: 22.8%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:59:06,476 [INFO] [metadata.py:55] test_wall_time: 2.083065986633301
2023-07-10 15:59:06,477 [INFO] [metadata.py:55] test_loss: 2.09968026959972
2023-07-10 15:59:06,477 [INFO] [metadata.py:55] test_accuracy: 0.5157245222929936
2023-07-10 15:59:06,479 [INFO] [train.py:190] Epoch: 54
2023-07-10 15:59:07,038 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:59:07,955 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.033234745  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:59:10,149 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.011816241  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 15:59:12,249 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.18000227  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:14,406 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.01546938  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:59:16,519 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.081226774  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 15:59:18,752 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.11020883  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:21,032 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.010071986  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:23,355 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.037380163  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:25,639 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0057843616  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:27,929 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.11565983  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:30,229 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.03999421  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:30,753 [INFO] [metadata.py:55] train_wall_time: 23.71516728401184
2023-07-10 15:59:30,754 [INFO] [metadata.py:55] train_loss: 0.060733297163722
2023-07-10 15:59:30,754 [INFO] [metadata.py:55] train_accuracy: 0.981689453125
2023-07-10 15:59:30,754 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:59:31,620 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8168869  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:32,490 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8673662  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:32,894 [INFO] [metadata.py:55] test_wall_time: 2.139474391937256
2023-07-10 15:59:32,894 [INFO] [metadata.py:55] test_loss: 1.9773355247868094
2023-07-10 15:59:32,894 [INFO] [metadata.py:55] test_accuracy: 0.5399084394904459
2023-07-10 15:59:32,897 [INFO] [train.py:216] Updating best model with epoch: 54
2023-07-10 15:59:32,910 [INFO] [train.py:190] Epoch: 55
2023-07-10 15:59:33,495 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 15:59:34,520 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.041879587  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:36,842 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.059851766  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:39,139 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0034505855  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:41,377 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.052595649  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:43,502 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.064481355  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:45,624 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.048443619  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:47,815 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.015019052  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:49,980 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.019000292  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:52,196 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.041627888  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:54,433 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.091523252  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:56,776 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.010150751  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:57,268 [INFO] [metadata.py:55] train_wall_time: 23.772625207901
2023-07-10 15:59:57,268 [INFO] [metadata.py:55] train_loss: 0.05587488939488594
2023-07-10 15:59:57,269 [INFO] [metadata.py:55] train_accuracy: 0.982818603515625
2023-07-10 15:59:57,269 [INFO] [train.py:200]   evaluating against test data
2023-07-10 15:59:58,176 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8393157  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:58,992 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1767197  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 15:59:59,366 [INFO] [metadata.py:55] test_wall_time: 2.097107410430908
2023-07-10 15:59:59,367 [INFO] [metadata.py:55] test_loss: 1.9239599625016475
2023-07-10 15:59:59,367 [INFO] [metadata.py:55] test_accuracy: 0.5336385350318471
2023-07-10 15:59:59,370 [INFO] [train.py:190] Epoch: 56
2023-07-10 16:00:00,011 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:00:00,991 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0071413894  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:00:03,248 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0011017821  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:00:05,474 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.013328608  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:00:07,651 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.094036102  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:00:09,858 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.16496941  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:00:12,223 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.014583967  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:14,578 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.038654186  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:16,780 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.29063961  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:18,994 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.039498068  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:21,210 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0014086406  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:23,550 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0028001477  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:24,074 [INFO] [metadata.py:55] train_wall_time: 24.06307554244995
2023-07-10 16:00:24,074 [INFO] [metadata.py:55] train_loss: 0.05742815400901691
2023-07-10 16:00:24,075 [INFO] [metadata.py:55] train_accuracy: 0.982086181640625
2023-07-10 16:00:24,075 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:00:24,999 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0657985  cpu_mem: 22.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:25,806 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1989791  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:26,188 [INFO] [metadata.py:55] test_wall_time: 2.1128125190734863
2023-07-10 16:00:26,189 [INFO] [metadata.py:55] test_loss: 2.0127621539838754
2023-07-10 16:00:26,189 [INFO] [metadata.py:55] test_accuracy: 0.5344347133757962
2023-07-10 16:00:26,191 [INFO] [train.py:190] Epoch: 57
2023-07-10 16:00:26,774 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:00:27,736 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.021026313  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:30,096 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0085707875  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:32,384 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.082733132  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:34,656 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.015369941  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:36,832 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.049021151  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:38,976 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0796813  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:41,081 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.012458653  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:43,397 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0052495967  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:45,727 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.033903848  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:47,972 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0042733476  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:50,185 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.023334246  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:50,641 [INFO] [metadata.py:55] train_wall_time: 23.866925477981567
2023-07-10 16:00:50,642 [INFO] [metadata.py:55] train_loss: 0.05643854594717368
2023-07-10 16:00:50,642 [INFO] [metadata.py:55] train_accuracy: 0.9825592041015625
2023-07-10 16:00:50,642 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:00:51,487 [INFO] [trainer.py:169]   batch 0/157  loss: 2.6317661  cpu_mem: 22.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:52,382 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0657716  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:52,761 [INFO] [metadata.py:55] test_wall_time: 2.118533134460449
2023-07-10 16:00:52,762 [INFO] [metadata.py:55] test_loss: 1.9438813400875992
2023-07-10 16:00:52,762 [INFO] [metadata.py:55] test_accuracy: 0.5392117834394905
2023-07-10 16:00:52,765 [INFO] [train.py:190] Epoch: 58
2023-07-10 16:00:53,347 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:00:54,339 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.007413432  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:56,653 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.086232543  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:00:58,918 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.10681291  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:01,074 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0093757287  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:03,232 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.068923935  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:05,504 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.046225019  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:07,672 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.073049977  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:09,826 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.078404397  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:12,038 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.01355388  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:01:14,243 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.013081416  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:01:16,478 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.031565424  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:01:16,987 [INFO] [metadata.py:55] train_wall_time: 23.6396222114563
2023-07-10 16:01:16,987 [INFO] [metadata.py:55] train_loss: 0.05579900222755896
2023-07-10 16:01:16,988 [INFO] [metadata.py:55] train_accuracy: 0.98297119140625
2023-07-10 16:01:16,988 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:01:17,847 [INFO] [trainer.py:169]   batch 0/157  loss: 2.067997  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:18,727 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8008668  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:19,109 [INFO] [metadata.py:55] test_wall_time: 2.1210291385650635
2023-07-10 16:01:19,110 [INFO] [metadata.py:55] test_loss: 1.9243920646655333
2023-07-10 16:01:19,110 [INFO] [metadata.py:55] test_accuracy: 0.5309514331210191
2023-07-10 16:01:19,113 [INFO] [train.py:190] Epoch: 59
2023-07-10 16:01:19,712 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:01:20,816 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00066648523  lr: 0.005029  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:23,250 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.049081121  lr: 0.007959  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:25,456 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.027615638  lr: 0.01089  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:27,689 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.10641328  lr: 0.01382  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:30,070 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.014704268  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:32,283 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.076935418  lr: 0.01968  cpu_mem: 23.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:34,523 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.087210961  lr: 0.01739  cpu_mem: 23.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:36,780 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.057182118  lr: 0.01446  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:39,051 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.012375827  lr: 0.01153  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:41,296 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0053549949  lr: 0.008604  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:43,539 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.020649759  lr: 0.005674  cpu_mem: 23.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:01:44,040 [INFO] [metadata.py:55] train_wall_time: 24.327847957611084
2023-07-10 16:01:44,040 [INFO] [metadata.py:55] train_loss: 0.05507803729631178
2023-07-10 16:01:44,041 [INFO] [metadata.py:55] train_accuracy: 0.982421875
2023-07-10 16:01:44,041 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:01:44,936 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2316675  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:01:45,781 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2198918  cpu_mem: 22.8%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:01:46,149 [INFO] [metadata.py:55] test_wall_time: 2.1079752445220947
2023-07-10 16:01:46,150 [INFO] [metadata.py:55] test_loss: 2.0251269909986265
2023-07-10 16:01:46,150 [INFO] [metadata.py:55] test_accuracy: 0.517515923566879
2023-07-10 16:01:46,153 [INFO] [train.py:190] Epoch: 60
2023-07-10 16:01:46,732 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:01:47,641 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0026381004  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:49,891 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.048853502  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:52,237 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.029940661  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:54,473 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.061090887  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:56,671 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.060138911  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:01:58,863 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.073557138  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:01,161 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.10540918  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:03,393 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.056770209  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:05,613 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.027377747  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:07,757 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.03000081  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:09,972 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.040341023  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:10,516 [INFO] [metadata.py:55] train_wall_time: 23.783578872680664
2023-07-10 16:02:10,516 [INFO] [metadata.py:55] train_loss: 0.05440126525789424
2023-07-10 16:02:10,516 [INFO] [metadata.py:55] train_accuracy: 0.9829254150390625
2023-07-10 16:02:10,517 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:02:11,396 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1089814  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:12,256 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1809783  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:02:12,637 [INFO] [metadata.py:55] test_wall_time: 2.119877338409424
2023-07-10 16:02:12,637 [INFO] [metadata.py:55] test_loss: 2.0273030582506943
2023-07-10 16:02:12,637 [INFO] [metadata.py:55] test_accuracy: 0.5244824840764332
2023-07-10 16:02:12,640 [INFO] [train.py:190] Epoch: 61
2023-07-10 16:02:13,218 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:02:14,187 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.020170078  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:02:16,472 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0043077273  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:02:18,686 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0050688446  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:20,962 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.056737669  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:23,160 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0651972  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:25,340 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.25414708  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:27,531 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.012432815  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:29,791 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.038896304  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:32,061 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.13605742  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:34,223 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.019030333  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:36,355 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.050670322  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:36,829 [INFO] [metadata.py:55] train_wall_time: 23.610374450683594
2023-07-10 16:02:36,829 [INFO] [metadata.py:55] train_loss: 0.05575102977087454
2023-07-10 16:02:36,829 [INFO] [metadata.py:55] train_accuracy: 0.9825897216796875
2023-07-10 16:02:36,830 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:02:37,759 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1830101  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:38,696 [INFO] [trainer.py:169]   batch 100/157  loss: 1.6565745  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:39,077 [INFO] [metadata.py:55] test_wall_time: 2.247295379638672
2023-07-10 16:02:39,078 [INFO] [metadata.py:55] test_loss: 1.9321036293248461
2023-07-10 16:02:39,078 [INFO] [metadata.py:55] test_accuracy: 0.53015525477707
2023-07-10 16:02:39,081 [INFO] [train.py:190] Epoch: 62
2023-07-10 16:02:39,659 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:02:40,682 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.048543654  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:42,927 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.021974275  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:45,228 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.11716923  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:47,485 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.025873428  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:49,707 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.011724655  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:51,939 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.11102056  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:54,142 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.018832423  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:56,334 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.089380644  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:02:58,480 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.10357002  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:00,683 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.16795975  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:02,976 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.045091882  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:03,445 [INFO] [metadata.py:55] train_wall_time: 23.784932374954224
2023-07-10 16:03:03,445 [INFO] [metadata.py:55] train_loss: 0.0564155152976582
2023-07-10 16:03:03,445 [INFO] [metadata.py:55] train_accuracy: 0.9830322265625
2023-07-10 16:03:03,445 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:03:04,343 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0956769  cpu_mem: 22.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:05,206 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9224646  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:05,569 [INFO] [metadata.py:55] test_wall_time: 2.1232481002807617
2023-07-10 16:03:05,569 [INFO] [metadata.py:55] test_loss: 2.028511221241799
2023-07-10 16:03:05,569 [INFO] [metadata.py:55] test_accuracy: 0.5261743630573248
2023-07-10 16:03:05,573 [INFO] [train.py:190] Epoch: 63
2023-07-10 16:03:06,232 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:03:07,137 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.09283299  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:09,328 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.11492898  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:11,587 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0026950981  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:13,825 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0066650216  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:03:15,970 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.12151054  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:03:18,155 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.063699394  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:20,411 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.042636026  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:22,700 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.10839423  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:25,004 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.1458807  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:27,289 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.012348404  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:29,511 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.020816548  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:29,997 [INFO] [metadata.py:55] train_wall_time: 23.764851808547974
2023-07-10 16:03:29,997 [INFO] [metadata.py:55] train_loss: 0.05459673425883693
2023-07-10 16:03:29,997 [INFO] [metadata.py:55] train_accuracy: 0.9834136962890625
2023-07-10 16:03:29,998 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:03:30,940 [INFO] [trainer.py:169]   batch 0/157  loss: 2.094707  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:31,837 [INFO] [trainer.py:169]   batch 100/157  loss: 2.050668  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:32,228 [INFO] [metadata.py:55] test_wall_time: 2.2295703887939453
2023-07-10 16:03:32,228 [INFO] [metadata.py:55] test_loss: 2.0172625203041514
2023-07-10 16:03:32,228 [INFO] [metadata.py:55] test_accuracy: 0.5326433121019108
2023-07-10 16:03:32,231 [INFO] [train.py:190] Epoch: 64
2023-07-10 16:03:32,814 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:03:33,739 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.020058544  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:36,095 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.013969917  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:38,464 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.085321315  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:40,688 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.034632105  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:42,898 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0079606725  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:45,030 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.20662051  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:47,356 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.16481091  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:49,600 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.090431891  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:51,870 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0017443885  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:54,106 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.013053919  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:56,409 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.085534953  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:56,900 [INFO] [metadata.py:55] train_wall_time: 24.08589506149292
2023-07-10 16:03:56,900 [INFO] [metadata.py:55] train_loss: 0.05529418795771335
2023-07-10 16:03:56,900 [INFO] [metadata.py:55] train_accuracy: 0.983001708984375
2023-07-10 16:03:56,901 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:03:57,833 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0788195  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:58,722 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9411707  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:03:59,121 [INFO] [metadata.py:55] test_wall_time: 2.220181465148926
2023-07-10 16:03:59,121 [INFO] [metadata.py:55] test_loss: 2.0199105830708888
2023-07-10 16:03:59,122 [INFO] [metadata.py:55] test_accuracy: 0.5324442675159236
2023-07-10 16:03:59,125 [INFO] [train.py:190] Epoch: 65
2023-07-10 16:03:59,716 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:04:00,706 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0054293163  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:02,883 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0074532232  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:05,069 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.022386618  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:07,356 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.17224748  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:09,607 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.060490277  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:11,869 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.090609282  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:04:14,020 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.077866785  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:04:16,287 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.090522692  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:04:18,654 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.16779703  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:20,845 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.018134583  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:23,028 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0089166174  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:23,527 [INFO] [metadata.py:55] train_wall_time: 23.810308694839478
2023-07-10 16:04:23,527 [INFO] [metadata.py:55] train_loss: 0.0568779779169688
2023-07-10 16:04:23,527 [INFO] [metadata.py:55] train_accuracy: 0.98223876953125
2023-07-10 16:04:23,528 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:04:24,451 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1437228  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:25,370 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9211266  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:25,742 [INFO] [metadata.py:55] test_wall_time: 2.2140960693359375
2023-07-10 16:04:25,743 [INFO] [metadata.py:55] test_loss: 2.040923013808621
2023-07-10 16:04:25,743 [INFO] [metadata.py:55] test_accuracy: 0.5227906050955414
2023-07-10 16:04:25,746 [INFO] [train.py:190] Epoch: 66
2023-07-10 16:04:26,323 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:04:27,403 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.003625972  lr: 0.005029  cpu_mem: 23.3%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:29,730 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0088124657  lr: 0.007959  cpu_mem: 23.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:32,015 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.01098318  lr: 0.01089  cpu_mem: 23.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:34,368 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.03857163  lr: 0.01382  cpu_mem: 23.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:36,592 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0091444589  lr: 0.01675  cpu_mem: 23.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:38,839 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.16487551  lr: 0.01968  cpu_mem: 23.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:41,244 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0096401917  lr: 0.01739  cpu_mem: 23.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:43,544 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.085008368  lr: 0.01446  cpu_mem: 23.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:45,801 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0055040801  lr: 0.01153  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:48,078 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0074079554  lr: 0.008604  cpu_mem: 23.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:50,360 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.18212053  lr: 0.005674  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:50,857 [INFO] [metadata.py:55] train_wall_time: 24.533342838287354
2023-07-10 16:04:50,857 [INFO] [metadata.py:55] train_loss: 0.05207488957944406
2023-07-10 16:04:50,857 [INFO] [metadata.py:55] train_accuracy: 0.983734130859375
2023-07-10 16:04:50,858 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:04:51,691 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8042109  cpu_mem: 22.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:52,515 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9307525  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:52,874 [INFO] [metadata.py:55] test_wall_time: 2.015519618988037
2023-07-10 16:04:52,874 [INFO] [metadata.py:55] test_loss: 1.915495287460886
2023-07-10 16:04:52,874 [INFO] [metadata.py:55] test_accuracy: 0.5415007961783439
2023-07-10 16:04:52,877 [INFO] [train.py:216] Updating best model with epoch: 66
2023-07-10 16:04:52,889 [INFO] [train.py:190] Epoch: 67
2023-07-10 16:04:53,452 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:04:54,443 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0058779726  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:56,729 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.051391236  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:04:58,961 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.1610017  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:01,249 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.055407833  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:03,552 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.01737689  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:05,775 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0050664288  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:08,102 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.075718433  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:10,428 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.17893416  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:12,668 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.083093747  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:05:14,932 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0050171283  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:05:17,115 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.010521095  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:17,613 [INFO] [metadata.py:55] train_wall_time: 24.160748958587646
2023-07-10 16:05:17,613 [INFO] [metadata.py:55] train_loss: 0.05018861855316459
2023-07-10 16:05:17,613 [INFO] [metadata.py:55] train_accuracy: 0.9844818115234375
2023-07-10 16:05:17,613 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:05:18,508 [INFO] [trainer.py:169]   batch 0/157  loss: 2.5510042  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:19,360 [INFO] [trainer.py:169]   batch 100/157  loss: 2.289186  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:19,732 [INFO] [metadata.py:55] test_wall_time: 2.1179275512695312
2023-07-10 16:05:19,732 [INFO] [metadata.py:55] test_loss: 2.0609868878771547
2023-07-10 16:05:19,732 [INFO] [metadata.py:55] test_accuracy: 0.5216958598726115
2023-07-10 16:05:19,735 [INFO] [train.py:190] Epoch: 68
2023-07-10 16:05:20,342 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:05:21,265 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0020757352  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:23,424 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.035391159  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:25,637 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0043655052  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:27,808 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.027072202  lr: 0.01382  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:30,005 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.065740027  lr: 0.01675  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:32,167 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.044592272  lr: 0.01968  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:34,396 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.056096062  lr: 0.01739  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:36,594 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.056478046  lr: 0.01446  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:38,884 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0094201295  lr: 0.01153  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:41,168 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.072720155  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:43,312 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.019838367  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:43,783 [INFO] [metadata.py:55] train_wall_time: 23.440938472747803
2023-07-10 16:05:43,784 [INFO] [metadata.py:55] train_loss: 0.053079424508723605
2023-07-10 16:05:43,784 [INFO] [metadata.py:55] train_accuracy: 0.9836883544921875
2023-07-10 16:05:43,784 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:05:44,660 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0651054  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:45,468 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1980982  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:45,825 [INFO] [metadata.py:55] test_wall_time: 2.0400445461273193
2023-07-10 16:05:45,825 [INFO] [metadata.py:55] test_loss: 2.041512966156006
2023-07-10 16:05:45,825 [INFO] [metadata.py:55] test_accuracy: 0.5234872611464968
2023-07-10 16:05:45,828 [INFO] [train.py:190] Epoch: 69
2023-07-10 16:05:46,413 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:05:47,298 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.031778771  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:49,565 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.018283853  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:51,778 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.007342712  lr: 0.01089  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:54,012 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.01619315  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:56,250 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.10528092  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:05:58,505 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.044079389  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:06:00,736 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.15166014  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:06:02,934 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.042581279  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:06:05,113 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.021832079  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:06:07,284 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.014868481  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:06:09,524 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0026541874  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:06:10,007 [INFO] [metadata.py:55] train_wall_time: 23.594086408615112
2023-07-10 16:06:10,008 [INFO] [metadata.py:55] train_loss: 0.05538890103719041
2023-07-10 16:06:10,008 [INFO] [metadata.py:55] train_accuracy: 0.9824981689453125
2023-07-10 16:06:10,008 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:06:10,919 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2662902  cpu_mem: 22.8%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:06:11,743 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1470933  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:06:12,098 [INFO] [metadata.py:55] test_wall_time: 2.089946985244751
2023-07-10 16:06:12,099 [INFO] [metadata.py:55] test_loss: 2.0460977896003967
2023-07-10 16:06:12,099 [INFO] [metadata.py:55] test_accuracy: 0.5210987261146497
2023-07-10 16:06:12,102 [INFO] [train.py:190] Epoch: 70
2023-07-10 16:06:12,701 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:06:13,591 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.017930886  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:06:15,824 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0073666349  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:06:18,121 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.043914452  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:20,477 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.16106428  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:22,713 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0075085652  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:24,932 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.094597228  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:27,085 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.080013759  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:29,312 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.060496576  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:31,508 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0022888535  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:33,776 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.063491262  lr: 0.008604  cpu_mem: 22.8%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:35,988 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.024439426  lr: 0.005674  cpu_mem: 22.8%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:36,486 [INFO] [metadata.py:55] train_wall_time: 23.784867763519287
2023-07-10 16:06:36,486 [INFO] [metadata.py:55] train_loss: 0.051584368388802204
2023-07-10 16:06:36,486 [INFO] [metadata.py:55] train_accuracy: 0.984130859375
2023-07-10 16:06:36,486 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:06:37,348 [INFO] [trainer.py:169]   batch 0/157  loss: 2.5032489  cpu_mem: 22.8%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:38,130 [INFO] [trainer.py:169]   batch 100/157  loss: 1.7675802  cpu_mem: 22.8%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:38,486 [INFO] [metadata.py:55] test_wall_time: 1.9987924098968506
2023-07-10 16:06:38,486 [INFO] [metadata.py:55] test_loss: 2.0681622650972598
2023-07-10 16:06:38,486 [INFO] [metadata.py:55] test_accuracy: 0.5207006369426752
2023-07-10 16:06:38,489 [INFO] [train.py:190] Epoch: 71
2023-07-10 16:06:39,078 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:06:40,081 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.021725371  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:42,403 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.044932168  lr: 0.007959  cpu_mem: 22.8%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:06:44,630 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.032288823  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:06:46,856 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.043112483  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:06:49,078 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.038707893  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:06:51,227 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.12780996  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:06:53,434 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.088378347  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:06:55,575 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.024305567  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:06:57,700 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.01817737  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:06:59,867 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.052331902  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:02,049 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.087643243  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:02,585 [INFO] [metadata.py:55] train_wall_time: 23.506844758987427
2023-07-10 16:07:02,585 [INFO] [metadata.py:55] train_loss: 0.051353694943969685
2023-07-10 16:07:02,585 [INFO] [metadata.py:55] train_accuracy: 0.983856201171875
2023-07-10 16:07:02,585 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:07:03,417 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3461711  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:04,248 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0661318  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:04,606 [INFO] [metadata.py:55] test_wall_time: 2.019818067550659
2023-07-10 16:07:04,606 [INFO] [metadata.py:55] test_loss: 2.077831011668892
2023-07-10 16:07:04,606 [INFO] [metadata.py:55] test_accuracy: 0.528562898089172
2023-07-10 16:07:04,609 [INFO] [train.py:190] Epoch: 72
2023-07-10 16:07:05,230 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:07:06,192 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0039951946  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:08,530 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0066317795  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:10,771 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.036428202  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:13,090 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.053126138  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:07:15,358 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.056911923  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:07:17,564 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.052371714  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:19,874 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.077818401  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:22,051 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.11722811  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:24,226 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.067366555  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:26,484 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.03066794  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:28,794 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0021741292  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:29,323 [INFO] [metadata.py:55] train_wall_time: 24.092584371566772
2023-07-10 16:07:29,323 [INFO] [metadata.py:55] train_loss: 0.0521830700641317
2023-07-10 16:07:29,324 [INFO] [metadata.py:55] train_accuracy: 0.9839630126953125
2023-07-10 16:07:29,324 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:07:30,261 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9965121  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:31,100 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9022346  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:31,474 [INFO] [metadata.py:55] test_wall_time: 2.1496188640594482
2023-07-10 16:07:31,474 [INFO] [metadata.py:55] test_loss: 2.064017381637719
2023-07-10 16:07:31,474 [INFO] [metadata.py:55] test_accuracy: 0.5334394904458599
2023-07-10 16:07:31,477 [INFO] [train.py:190] Epoch: 73
2023-07-10 16:07:32,139 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:07:33,151 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.055791512  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:35,550 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.12023352  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:37,862 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0070175347  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:40,108 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0050015505  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:42,299 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0099116378  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:44,548 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.038961902  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:46,732 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.070557043  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:48,927 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.025881136  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:51,037 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.029043227  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:53,216 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.021023665  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:55,364 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.12387754  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:55,818 [INFO] [metadata.py:55] train_wall_time: 23.679099082946777
2023-07-10 16:07:55,818 [INFO] [metadata.py:55] train_loss: 0.050762313663540226
2023-07-10 16:07:55,819 [INFO] [metadata.py:55] train_accuracy: 0.9842681884765625
2023-07-10 16:07:55,819 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:07:56,765 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2706099  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:57,683 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4023032  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:07:58,045 [INFO] [metadata.py:55] test_wall_time: 2.225127696990967
2023-07-10 16:07:58,045 [INFO] [metadata.py:55] test_loss: 2.1798330932665784
2023-07-10 16:07:58,045 [INFO] [metadata.py:55] test_accuracy: 0.5109474522292994
2023-07-10 16:07:58,048 [INFO] [train.py:190] Epoch: 74
2023-07-10 16:07:58,648 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:07:59,670 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0023079875  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:01,924 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0041629318  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:04,165 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.088244997  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:06,540 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.03837594  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:08,756 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.041554596  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:10,914 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.018029846  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:13,003 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.26240063  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:08:15,117 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.073352247  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:08:17,249 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.13189837  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:19,340 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.046626791  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:21,470 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.042899497  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:21,952 [INFO] [metadata.py:55] train_wall_time: 23.303977012634277
2023-07-10 16:08:21,953 [INFO] [metadata.py:55] train_loss: 0.05161761649432606
2023-07-10 16:08:21,953 [INFO] [metadata.py:55] train_accuracy: 0.98370361328125
2023-07-10 16:08:21,953 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:08:22,917 [INFO] [trainer.py:169]   batch 0/157  loss: 2.456773  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:23,759 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2438195  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:24,137 [INFO] [metadata.py:55] test_wall_time: 2.183688163757324
2023-07-10 16:08:24,138 [INFO] [metadata.py:55] test_loss: 2.240920873204614
2023-07-10 16:08:24,146 [INFO] [metadata.py:55] test_accuracy: 0.4955214968152866
2023-07-10 16:08:24,150 [INFO] [train.py:190] Epoch: 75
2023-07-10 16:08:24,744 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:08:25,672 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0020576953  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:27,903 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.062764816  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:30,157 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0086004287  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:32,440 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.013651079  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:34,659 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.1238228  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:36,971 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.059303869  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:39,220 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.07295581  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:41,437 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.042110328  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:43,706 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.11128362  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:46,000 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.016090112  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:48,260 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.019325461  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:48,744 [INFO] [metadata.py:55] train_wall_time: 23.99971842765808
2023-07-10 16:08:48,744 [INFO] [metadata.py:55] train_loss: 0.04892013676612805
2023-07-10 16:08:48,744 [INFO] [metadata.py:55] train_accuracy: 0.98486328125
2023-07-10 16:08:48,744 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:08:49,626 [INFO] [trainer.py:169]   batch 0/157  loss: 2.4327011  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:50,467 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9348563  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:50,832 [INFO] [metadata.py:55] test_wall_time: 2.0873260498046875
2023-07-10 16:08:50,832 [INFO] [metadata.py:55] test_loss: 2.1043511340572576
2023-07-10 16:08:50,833 [INFO] [metadata.py:55] test_accuracy: 0.5218949044585988
2023-07-10 16:08:50,836 [INFO] [train.py:190] Epoch: 76
2023-07-10 16:08:51,487 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:08:52,492 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.006125553  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:54,663 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.061968304  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:56,794 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0017719679  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:08:58,959 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.046286389  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:01,173 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.03883668  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:03,399 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.2312469  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:05,584 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.027419837  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:07,757 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.034505345  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:10,088 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.056064505  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:12,271 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.025561512  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:09:14,566 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0083834836  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:09:15,090 [INFO] [metadata.py:55] train_wall_time: 23.60232949256897
2023-07-10 16:09:15,090 [INFO] [metadata.py:55] train_loss: 0.05132665688688576
2023-07-10 16:09:15,091 [INFO] [metadata.py:55] train_accuracy: 0.9840240478515625
2023-07-10 16:09:15,091 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:09:16,039 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0525904  cpu_mem: 22.8%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:09:16,935 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0996709  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:17,325 [INFO] [metadata.py:55] test_wall_time: 2.233302593231201
2023-07-10 16:09:17,325 [INFO] [metadata.py:55] test_loss: 2.0060833609028226
2023-07-10 16:09:17,325 [INFO] [metadata.py:55] test_accuracy: 0.542296974522293
2023-07-10 16:09:17,328 [INFO] [train.py:216] Updating best model with epoch: 76
2023-07-10 16:09:17,341 [INFO] [train.py:190] Epoch: 77
2023-07-10 16:09:17,985 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:09:18,952 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.030708186  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:21,260 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0098765315  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:23,460 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.065019213  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:25,683 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.013817354  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:27,821 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.019655805  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:30,072 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.03999047  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:32,334 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.10102293  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:34,576 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0045198342  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:36,814 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.11485472  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:39,056 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.061690457  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:41,254 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.057095733  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:41,751 [INFO] [metadata.py:55] train_wall_time: 23.765825033187866
2023-07-10 16:09:41,752 [INFO] [metadata.py:55] train_loss: 0.048587947710984736
2023-07-10 16:09:41,752 [INFO] [metadata.py:55] train_accuracy: 0.9848175048828125
2023-07-10 16:09:41,752 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:09:42,641 [INFO] [trainer.py:169]   batch 0/157  loss: 2.4230978  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:43,409 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1087782  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:43,773 [INFO] [metadata.py:55] test_wall_time: 2.0205795764923096
2023-07-10 16:09:43,774 [INFO] [metadata.py:55] test_loss: 2.1081155887834586
2023-07-10 16:09:43,774 [INFO] [metadata.py:55] test_accuracy: 0.5320461783439491
2023-07-10 16:09:43,777 [INFO] [train.py:190] Epoch: 78
2023-07-10 16:09:44,384 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:09:45,324 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0018446919  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:47,609 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.011400713  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:49,896 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.064458802  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:52,259 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.019605404  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:54,576 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.044655751  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:56,888 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.063417763  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:09:59,152 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.059616148  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:01,341 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.052578576  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:03,593 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0056331148  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:05,853 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.05087693  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:08,197 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.014116208  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:08,676 [INFO] [metadata.py:55] train_wall_time: 24.291968822479248
2023-07-10 16:10:08,676 [INFO] [metadata.py:55] train_loss: 0.04972957480467244
2023-07-10 16:10:08,677 [INFO] [metadata.py:55] train_accuracy: 0.98468017578125
2023-07-10 16:10:08,677 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:10:09,546 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2525151  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:10,443 [INFO] [trainer.py:169]   batch 100/157  loss: 2.215723  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:10,820 [INFO] [metadata.py:55] test_wall_time: 2.1426711082458496
2023-07-10 16:10:10,820 [INFO] [metadata.py:55] test_loss: 2.069679537396522
2023-07-10 16:10:10,820 [INFO] [metadata.py:55] test_accuracy: 0.5302547770700637
2023-07-10 16:10:10,824 [INFO] [train.py:190] Epoch: 79
2023-07-10 16:10:11,445 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:10:12,378 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.10684821  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:10:14,701 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0048500942  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:10:17,009 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.045557339  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:19,227 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.23596638  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:21,420 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.046503723  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:23,708 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.072434016  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:10:26,022 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.012012874  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:10:28,360 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.10403842  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:10:30,698 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.017629361  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:10:33,295 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.018500729  lr: 0.008604  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:10:35,663 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.026739512  lr: 0.005674  cpu_mem: 23.4%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:10:36,187 [INFO] [metadata.py:55] train_wall_time: 24.741309881210327
2023-07-10 16:10:36,187 [INFO] [metadata.py:55] train_loss: 0.052900749793110435
2023-07-10 16:10:36,187 [INFO] [metadata.py:55] train_accuracy: 0.9838104248046875
2023-07-10 16:10:36,187 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:10:37,122 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0322247  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:10:37,986 [INFO] [trainer.py:169]   batch 100/157  loss: 2.5946867  cpu_mem: 23.4%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:10:38,460 [INFO] [metadata.py:55] test_wall_time: 2.271575450897217
2023-07-10 16:10:38,460 [INFO] [metadata.py:55] test_loss: 2.012552457250607
2023-07-10 16:10:38,460 [INFO] [metadata.py:55] test_accuracy: 0.5311504777070064
2023-07-10 16:10:38,464 [INFO] [train.py:190] Epoch: 80
2023-07-10 16:10:39,150 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:10:40,206 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.014859006  lr: 0.005029  cpu_mem: 23.4%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:10:42,579 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.14319064  lr: 0.007959  cpu_mem: 23.4%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:10:44,931 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.030231696  lr: 0.01089  cpu_mem: 23.4%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:10:47,223 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.066610023  lr: 0.01382  cpu_mem: 23.4%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:10:49,544 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.021628698  lr: 0.01675  cpu_mem: 23.4%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:10:51,765 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.070629157  lr: 0.01968  cpu_mem: 23.3%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:10:54,019 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.15605003  lr: 0.01739  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:10:56,449 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.20023957  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:10:58,749 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0075289966  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:00,999 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.036925513  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:03,304 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.049291085  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:03,820 [INFO] [metadata.py:55] train_wall_time: 24.66958522796631
2023-07-10 16:11:03,820 [INFO] [metadata.py:55] train_loss: 0.048527222775476275
2023-07-10 16:11:03,820 [INFO] [metadata.py:55] train_accuracy: 0.985015869140625
2023-07-10 16:11:03,820 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:11:04,756 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3307207  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:05,602 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2807033  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:05,999 [INFO] [metadata.py:55] test_wall_time: 2.1783969402313232
2023-07-10 16:11:06,000 [INFO] [metadata.py:55] test_loss: 2.1368206291441707
2023-07-10 16:11:06,000 [INFO] [metadata.py:55] test_accuracy: 0.5184116242038217
2023-07-10 16:11:06,003 [INFO] [train.py:190] Epoch: 81
2023-07-10 16:11:06,600 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:11:07,511 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.12286824  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:11:09,880 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.037211623  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:11:12,261 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.007855257  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:14,562 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.11258624  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:16,774 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.004062342  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:18,940 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.15604998  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:21,090 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.03674154  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:23,410 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.061676871  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:11:25,788 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.001841614  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:11:28,199 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.025185011  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 16:11:30,436 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.086897321  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 16:11:30,944 [INFO] [metadata.py:55] train_wall_time: 24.34391975402832
2023-07-10 16:11:30,944 [INFO] [metadata.py:55] train_loss: 0.050573051476305864
2023-07-10 16:11:30,944 [INFO] [metadata.py:55] train_accuracy: 0.9842529296875
2023-07-10 16:11:30,944 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:11:31,820 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2929194  cpu_mem: 22.9%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 16:11:32,655 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8804411  cpu_mem: 22.9%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 16:11:33,068 [INFO] [metadata.py:55] test_wall_time: 2.1230742931365967
2023-07-10 16:11:33,068 [INFO] [metadata.py:55] test_loss: 2.0306053472931977
2023-07-10 16:11:33,068 [INFO] [metadata.py:55] test_accuracy: 0.53015525477707
2023-07-10 16:11:33,072 [INFO] [train.py:190] Epoch: 82
2023-07-10 16:11:33,694 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:11:34,701 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0062299995  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 16:11:37,075 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.050425258  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 16:11:39,363 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0057514599  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:11:41,653 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.014206508  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 16:11:43,892 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.14632167  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.9]% of [20470]MiB
2023-07-10 16:11:46,271 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.080909468  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:11:48,492 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.062093537  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:11:50,683 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.019040555  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:11:52,837 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.018649885  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:11:55,015 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.06530454  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:11:57,177 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.12120861  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:11:57,660 [INFO] [metadata.py:55] train_wall_time: 23.96598505973816
2023-07-10 16:11:57,660 [INFO] [metadata.py:55] train_loss: 0.0519016615182295
2023-07-10 16:11:57,660 [INFO] [metadata.py:55] train_accuracy: 0.9839019775390625
2023-07-10 16:11:57,661 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:11:58,565 [INFO] [trainer.py:169]   batch 0/157  loss: 2.5949566  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:11:59,437 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1263824  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:11:59,809 [INFO] [metadata.py:55] test_wall_time: 2.147738218307495
2023-07-10 16:11:59,809 [INFO] [metadata.py:55] test_loss: 2.153084130803491
2023-07-10 16:11:59,809 [INFO] [metadata.py:55] test_accuracy: 0.5203025477707006
2023-07-10 16:11:59,813 [INFO] [train.py:190] Epoch: 83
2023-07-10 16:12:00,486 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:12:01,418 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.089225441  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:12:03,718 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.081777595  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:12:05,960 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.013516109  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:12:08,162 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.007582448  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:12:10,461 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.055123355  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:12:12,688 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.17041634  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:12:14,963 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.14636509  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:12:17,240 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.10757449  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:12:19,431 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.061537735  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:12:21,605 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.01090149  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:12:23,824 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.062120784  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:12:24,314 [INFO] [metadata.py:55] train_wall_time: 23.827440977096558
2023-07-10 16:12:24,314 [INFO] [metadata.py:55] train_loss: 0.04798706430489119
2023-07-10 16:12:24,314 [INFO] [metadata.py:55] train_accuracy: 0.9853668212890625
2023-07-10 16:12:24,315 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:12:25,215 [INFO] [trainer.py:169]   batch 0/157  loss: 2.4250567  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:12:26,048 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3207128  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:12:26,432 [INFO] [metadata.py:55] test_wall_time: 2.1171040534973145
2023-07-10 16:12:26,432 [INFO] [metadata.py:55] test_loss: 1.980242446729332
2023-07-10 16:12:26,432 [INFO] [metadata.py:55] test_accuracy: 0.5387141719745223
2023-07-10 16:12:26,436 [INFO] [train.py:190] Epoch: 84
2023-07-10 16:12:27,011 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:12:27,988 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.010100345  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:12:30,224 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0078618247  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:12:32,362 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.024854848  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:12:34,513 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.17904778  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:12:36,672 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.012143591  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:12:38,875 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.066379264  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:12:41,106 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.017353088  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:12:43,260 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.079829365  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:12:45,468 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.01048034  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:12:47,701 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.01406586  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:12:49,919 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0035782829  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:12:50,421 [INFO] [metadata.py:55] train_wall_time: 23.40930438041687
2023-07-10 16:12:50,421 [INFO] [metadata.py:55] train_loss: 0.049526930060778795
2023-07-10 16:12:50,421 [INFO] [metadata.py:55] train_accuracy: 0.984405517578125
2023-07-10 16:12:50,422 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:12:51,327 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8532038  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:12:52,225 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3420813  cpu_mem: 22.9%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:12:52,579 [INFO] [metadata.py:55] test_wall_time: 2.156360387802124
2023-07-10 16:12:52,579 [INFO] [metadata.py:55] test_loss: 1.9445662118826703
2023-07-10 16:12:52,579 [INFO] [metadata.py:55] test_accuracy: 0.5363256369426752
2023-07-10 16:12:52,583 [INFO] [train.py:190] Epoch: 85
2023-07-10 16:12:53,152 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:12:54,134 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0027884315  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:12:56,466 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.002857297  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:12:58,612 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0045965873  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:13:00,897 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.015708603  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:13:03,094 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.051656231  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:13:05,399 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.031575304  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:13:07,620 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.024809286  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:13:09,792 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.055225201  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:13:12,158 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.12976618  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:13:14,488 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.022567602  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:13:16,776 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.003099581  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:13:17,321 [INFO] [metadata.py:55] train_wall_time: 24.168609142303467
2023-07-10 16:13:17,321 [INFO] [metadata.py:55] train_loss: 0.04952386796145447
2023-07-10 16:13:17,321 [INFO] [metadata.py:55] train_accuracy: 0.984771728515625
2023-07-10 16:13:17,322 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:13:18,240 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0413725  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:13:19,153 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4461455  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:13:19,519 [INFO] [metadata.py:55] test_wall_time: 2.197068691253662
2023-07-10 16:13:19,519 [INFO] [metadata.py:55] test_loss: 2.101739220558458
2023-07-10 16:13:19,520 [INFO] [metadata.py:55] test_accuracy: 0.5295581210191083
2023-07-10 16:13:19,523 [INFO] [train.py:190] Epoch: 86
2023-07-10 16:13:20,204 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:13:21,155 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0095112743  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:13:23,355 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.044690177  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:13:25,689 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.013592731  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:13:28,023 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0084254099  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:13:30,287 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.051002834  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:13:32,548 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.037529469  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:13:34,815 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.024594223  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:13:37,102 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.03954358  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:13:39,399 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.082493797  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:13:41,736 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.015289022  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:13:43,976 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.078204013  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:13:44,496 [INFO] [metadata.py:55] train_wall_time: 24.290965795516968
2023-07-10 16:13:44,496 [INFO] [metadata.py:55] train_loss: 0.04811942165727601
2023-07-10 16:13:44,496 [INFO] [metadata.py:55] train_accuracy: 0.9849090576171875
2023-07-10 16:13:44,496 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:13:45,353 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2321546  cpu_mem: 22.9%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:13:46,247 [INFO] [trainer.py:169]   batch 100/157  loss: 2.258827  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:13:46,616 [INFO] [metadata.py:55] test_wall_time: 2.119182825088501
2023-07-10 16:13:46,616 [INFO] [metadata.py:55] test_loss: 2.004261205910118
2023-07-10 16:13:46,616 [INFO] [metadata.py:55] test_accuracy: 0.533937101910828
2023-07-10 16:13:46,620 [INFO] [train.py:190] Epoch: 87
2023-07-10 16:13:47,180 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:13:48,140 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.01194369  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:13:50,390 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0095552756  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:13:52,695 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.076269247  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:13:55,080 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0079023726  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:13:57,308 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.019607445  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:13:59,501 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.059374288  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:14:01,697 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.021211635  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:14:04,049 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.086464629  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:14:06,466 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.056292087  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:14:08,812 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0067009418  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:14:11,043 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0015292016  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:14:11,540 [INFO] [metadata.py:55] train_wall_time: 24.360036849975586
2023-07-10 16:14:11,541 [INFO] [metadata.py:55] train_loss: 0.0490336859911622
2023-07-10 16:14:11,541 [INFO] [metadata.py:55] train_accuracy: 0.984710693359375
2023-07-10 16:14:11,541 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:14:12,476 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8197598  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:14:13,296 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2589433  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:14:13,669 [INFO] [metadata.py:55] test_wall_time: 2.127067804336548
2023-07-10 16:14:13,669 [INFO] [metadata.py:55] test_loss: 2.0856157715912835
2023-07-10 16:14:13,669 [INFO] [metadata.py:55] test_accuracy: 0.5234872611464968
2023-07-10 16:14:13,672 [INFO] [train.py:190] Epoch: 88
2023-07-10 16:14:14,238 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:14:15,140 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0014188796  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:14:17,351 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0020343971  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:14:19,626 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.046421763  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:14:21,952 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0060687549  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:14:24,193 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.057844281  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:14:26,484 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.098371163  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:14:28,828 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.057953291  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:14:31,111 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.11709959  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:14:33,363 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0009493673  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:14:35,624 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.022825422  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:14:37,960 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0024344362  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:14:38,434 [INFO] [metadata.py:55] train_wall_time: 24.19662880897522
2023-07-10 16:14:38,435 [INFO] [metadata.py:55] train_loss: 0.04841886273109708
2023-07-10 16:14:38,435 [INFO] [metadata.py:55] train_accuracy: 0.985321044921875
2023-07-10 16:14:38,435 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:14:39,297 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9214375  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:14:40,173 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2141695  cpu_mem: 22.9%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:14:40,555 [INFO] [metadata.py:55] test_wall_time: 2.11969256401062
2023-07-10 16:14:40,556 [INFO] [metadata.py:55] test_loss: 2.010144412897195
2023-07-10 16:14:40,556 [INFO] [metadata.py:55] test_accuracy: 0.5391122611464968
2023-07-10 16:14:40,559 [INFO] [train.py:190] Epoch: 89
2023-07-10 16:14:41,120 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:14:42,098 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0066997632  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:14:44,407 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.056271546  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:14:46,848 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.017584249  lr: 0.01089  cpu_mem: 23.6%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:14:49,024 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.060063131  lr: 0.01382  cpu_mem: 23.6%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:14:51,323 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.06711515  lr: 0.01675  cpu_mem: 23.6%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:14:53,598 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.06589371  lr: 0.01968  cpu_mem: 23.6%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:14:55,908 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.064533226  lr: 0.01739  cpu_mem: 23.8%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:14:58,195 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.006166548  lr: 0.01446  cpu_mem: 23.7%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:15:00,591 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0033726343  lr: 0.01153  cpu_mem: 23.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:15:02,986 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.033789992  lr: 0.008604  cpu_mem: 23.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:15:05,257 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.063909605  lr: 0.005674  cpu_mem: 23.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:15:05,775 [INFO] [metadata.py:55] train_wall_time: 24.654003381729126
2023-07-10 16:15:05,775 [INFO] [metadata.py:55] train_loss: 0.0461390891912572
2023-07-10 16:15:05,775 [INFO] [metadata.py:55] train_accuracy: 0.9857025146484375
2023-07-10 16:15:05,775 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:15:06,748 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0269995  cpu_mem: 22.9%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 16:15:07,672 [INFO] [trainer.py:169]   batch 100/157  loss: 2.381566  cpu_mem: 22.9%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 16:15:08,058 [INFO] [metadata.py:55] test_wall_time: 2.281839370727539
2023-07-10 16:15:08,058 [INFO] [metadata.py:55] test_loss: 2.0829839000276698
2023-07-10 16:15:08,058 [INFO] [metadata.py:55] test_accuracy: 0.5322452229299363
2023-07-10 16:15:08,061 [INFO] [train.py:190] Epoch: 90
2023-07-10 16:15:08,628 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:15:09,525 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.048468295  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 16:15:11,755 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.045991711  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 16:15:13,988 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0080904672  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:15:16,179 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.045227718  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:15:18,412 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0068775495  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:15:20,631 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.16014647  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:15:22,792 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.041168664  lr: 0.01739  cpu_mem: 22.9%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:15:24,971 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0080253836  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:15:27,254 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.012402193  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:15:29,532 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0023264696  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:15:31,739 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.046383474  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:15:32,271 [INFO] [metadata.py:55] train_wall_time: 23.64329695701599
2023-07-10 16:15:32,272 [INFO] [metadata.py:55] train_loss: 0.04841996055856157
2023-07-10 16:15:32,272 [INFO] [metadata.py:55] train_accuracy: 0.984954833984375
2023-07-10 16:15:32,272 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:15:33,131 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3220103  cpu_mem: 22.9%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:15:33,997 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1452351  cpu_mem: 22.9%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:15:34,380 [INFO] [metadata.py:55] test_wall_time: 2.106829881668091
2023-07-10 16:15:34,380 [INFO] [metadata.py:55] test_loss: 2.0800180579446685
2023-07-10 16:15:34,380 [INFO] [metadata.py:55] test_accuracy: 0.5321457006369427
2023-07-10 16:15:34,383 [INFO] [train.py:190] Epoch: 91
2023-07-10 16:15:34,970 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:15:35,953 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.016468959  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:15:38,276 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0070939721  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:15:40,480 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0020813392  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:15:42,738 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.050098501  lr: 0.01382  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:15:45,026 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.033497106  lr: 0.01675  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:15:47,197 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.053950354  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:15:49,553 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.083315812  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:15:51,867 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.059314076  lr: 0.01446  cpu_mem: 22.9%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:15:54,201 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.038710494  lr: 0.01153  cpu_mem: 22.9%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:15:56,586 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.037718054  lr: 0.008604  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:15:58,890 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0034703447  lr: 0.005674  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:15:59,393 [INFO] [metadata.py:55] train_wall_time: 24.42323112487793
2023-07-10 16:15:59,394 [INFO] [metadata.py:55] train_loss: 0.04830312569217199
2023-07-10 16:15:59,394 [INFO] [metadata.py:55] train_accuracy: 0.9850616455078125
2023-07-10 16:15:59,394 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:16:00,292 [INFO] [trainer.py:169]   batch 0/157  loss: 2.4010069  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:16:01,138 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2105112  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:16:01,506 [INFO] [metadata.py:55] test_wall_time: 2.110975742340088
2023-07-10 16:16:01,506 [INFO] [metadata.py:55] test_loss: 2.128871104519838
2023-07-10 16:16:01,506 [INFO] [metadata.py:55] test_accuracy: 0.527468152866242
2023-07-10 16:16:01,509 [INFO] [train.py:190] Epoch: 92
2023-07-10 16:16:02,068 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:16:02,987 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.17486469  lr: 0.005029  cpu_mem: 22.8%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:16:05,300 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0057192491  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:16:07,516 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.019410525  lr: 0.01089  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:16:09,709 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.020512739  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:16:11,920 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.015257952  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:16:14,169 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.19627762  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:16:16,536 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.073849358  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:16:18,946 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.099379644  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:16:21,283 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.010513689  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:16:23,484 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0025693255  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:25,703 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0044004116  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:26,202 [INFO] [metadata.py:55] train_wall_time: 24.134109020233154
2023-07-10 16:16:26,202 [INFO] [metadata.py:55] train_loss: 0.0479056743174624
2023-07-10 16:16:26,203 [INFO] [metadata.py:55] train_accuracy: 0.98492431640625
2023-07-10 16:16:26,203 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:16:27,065 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9695956  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:27,975 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1108055  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:28,382 [INFO] [metadata.py:55] test_wall_time: 2.1781058311462402
2023-07-10 16:16:28,382 [INFO] [metadata.py:55] test_loss: 2.0082824541504976
2023-07-10 16:16:28,382 [INFO] [metadata.py:55] test_accuracy: 0.5387141719745223
2023-07-10 16:16:28,386 [INFO] [train.py:190] Epoch: 93
2023-07-10 16:16:29,030 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:16:29,999 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0062435949  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:32,305 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.015211659  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:34,500 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.010131013  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:36,736 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.029929833  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:39,037 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.02877616  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:16:41,279 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.080287673  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:16:43,441 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.11190366  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:16:45,625 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0087094465  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:47,821 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.11297677  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:50,085 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.018361749  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:52,299 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.018396325  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:52,776 [INFO] [metadata.py:55] train_wall_time: 23.745831727981567
2023-07-10 16:16:52,776 [INFO] [metadata.py:55] train_loss: 0.0475121874006561
2023-07-10 16:16:52,777 [INFO] [metadata.py:55] train_accuracy: 0.9852294921875
2023-07-10 16:16:52,777 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:16:53,645 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1260958  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:54,525 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8246788  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:16:54,908 [INFO] [metadata.py:55] test_wall_time: 2.1309165954589844
2023-07-10 16:16:54,909 [INFO] [metadata.py:55] test_loss: 2.0217026191152585
2023-07-10 16:16:54,909 [INFO] [metadata.py:55] test_accuracy: 0.5360270700636943
2023-07-10 16:16:54,912 [INFO] [train.py:190] Epoch: 94
2023-07-10 16:16:55,528 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:16:56,466 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0020166677  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:16:58,711 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00019877321  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:17:00,990 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.019073136  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:17:03,139 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.019274417  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:17:05,322 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.10209175  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:17:07,587 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.042819481  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:17:09,798 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.019705297  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:17:11,975 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.10243821  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:17:14,219 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.012712291  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:17:16,460 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.036379106  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:17:18,648 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.02043427  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:17:19,144 [INFO] [metadata.py:55] train_wall_time: 23.615418434143066
2023-07-10 16:17:19,144 [INFO] [metadata.py:55] train_loss: 0.046628433369605204
2023-07-10 16:17:19,153 [INFO] [metadata.py:55] train_accuracy: 0.9855194091796875
2023-07-10 16:17:19,153 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:17:20,101 [INFO] [trainer.py:169]   batch 0/157  loss: 2.108592  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:17:20,952 [INFO] [trainer.py:169]   batch 100/157  loss: 1.4873329  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:17:21,307 [INFO] [metadata.py:55] test_wall_time: 2.152108907699585
2023-07-10 16:17:21,307 [INFO] [metadata.py:55] test_loss: 2.0612177955117197
2023-07-10 16:17:21,307 [INFO] [metadata.py:55] test_accuracy: 0.537718949044586
2023-07-10 16:17:21,310 [INFO] [train.py:190] Epoch: 95
2023-07-10 16:17:21,860 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:17:22,793 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.021093478  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:17:25,007 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.010966322  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:17:27,252 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.06319645  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:17:29,445 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0026691929  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:17:31,654 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.020951549  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:33,896 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.011560273  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:36,105 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.019905211  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:38,304 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.05640956  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:40,532 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0012827463  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:42,791 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.050722271  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:45,113 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.078652106  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:45,637 [INFO] [metadata.py:55] train_wall_time: 23.77668571472168
2023-07-10 16:17:45,637 [INFO] [metadata.py:55] train_loss: 0.045151869732677596
2023-07-10 16:17:45,638 [INFO] [metadata.py:55] train_accuracy: 0.9859771728515625
2023-07-10 16:17:45,638 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:17:46,668 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0388227  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:47,484 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8440535  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:47,841 [INFO] [metadata.py:55] test_wall_time: 2.20231032371521
2023-07-10 16:17:47,841 [INFO] [metadata.py:55] test_loss: 2.0448167635377046
2023-07-10 16:17:47,850 [INFO] [metadata.py:55] test_accuracy: 0.544187898089172
2023-07-10 16:17:47,853 [INFO] [train.py:216] Updating best model with epoch: 95
2023-07-10 16:17:47,866 [INFO] [train.py:190] Epoch: 96
2023-07-10 16:17:48,417 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:17:49,506 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.030509019  lr: 0.005029  cpu_mem: 23.7%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:51,704 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0046875058  lr: 0.007959  cpu_mem: 23.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:54,027 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0050872089  lr: 0.01089  cpu_mem: 23.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:56,256 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.13455528  lr: 0.01382  cpu_mem: 23.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:17:58,415 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.018063214  lr: 0.01675  cpu_mem: 23.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:00,535 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0070693735  lr: 0.01968  cpu_mem: 23.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:02,722 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.038996533  lr: 0.01739  cpu_mem: 23.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:04,940 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0035043464  lr: 0.01446  cpu_mem: 23.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:07,163 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.046992932  lr: 0.01153  cpu_mem: 23.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:09,389 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00092738587  lr: 0.008604  cpu_mem: 24.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:11,656 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0026984941  lr: 0.005674  cpu_mem: 23.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:12,137 [INFO] [metadata.py:55] train_wall_time: 23.71961283683777
2023-07-10 16:18:12,138 [INFO] [metadata.py:55] train_loss: 0.046364137739288935
2023-07-10 16:18:12,138 [INFO] [metadata.py:55] train_accuracy: 0.9852752685546875
2023-07-10 16:18:12,138 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:18:13,076 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9954574  cpu_mem: 22.9%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:18:13,940 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3898852  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:18:14,318 [INFO] [metadata.py:55] test_wall_time: 2.1792826652526855
2023-07-10 16:18:14,318 [INFO] [metadata.py:55] test_loss: 2.1331418342651074
2023-07-10 16:18:14,318 [INFO] [metadata.py:55] test_accuracy: 0.5297571656050956
2023-07-10 16:18:14,322 [INFO] [train.py:190] Epoch: 97
2023-07-10 16:18:14,896 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:18:15,831 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.013380447  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:18:18,109 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0062003965  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:20,293 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0026603199  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:22,550 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.036426518  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:24,858 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.072804578  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:27,112 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.2086851  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:29,364 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.12827647  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:31,636 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0037138467  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:33,905 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.011024965  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:36,252 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.025102844  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:38,575 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0011115314  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:39,073 [INFO] [metadata.py:55] train_wall_time: 24.176159620285034
2023-07-10 16:18:39,073 [INFO] [metadata.py:55] train_loss: 0.04625456498884262
2023-07-10 16:18:39,073 [INFO] [metadata.py:55] train_accuracy: 0.9854583740234375
2023-07-10 16:18:39,073 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:18:39,970 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8922119  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:40,889 [INFO] [trainer.py:169]   batch 100/157  loss: 2.139344  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:41,264 [INFO] [metadata.py:55] test_wall_time: 2.190185070037842
2023-07-10 16:18:41,264 [INFO] [metadata.py:55] test_loss: 2.2172334346042315
2023-07-10 16:18:41,265 [INFO] [metadata.py:55] test_accuracy: 0.5193073248407644
2023-07-10 16:18:41,268 [INFO] [train.py:190] Epoch: 98
2023-07-10 16:18:41,849 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:18:42,832 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.011820449  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:45,093 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.053755838  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:47,259 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0025951446  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:49,516 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.013370077  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:51,859 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0084035359  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:54,043 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.050123353  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:56,256 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0082155773  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:18:58,510 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.052822903  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:00,832 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.018106809  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:03,000 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0088569531  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:05,153 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.001917138  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:05,643 [INFO] [metadata.py:55] train_wall_time: 23.792927265167236
2023-07-10 16:19:05,643 [INFO] [metadata.py:55] train_loss: 0.04533376414082113
2023-07-10 16:19:05,643 [INFO] [metadata.py:55] train_accuracy: 0.9862823486328125
2023-07-10 16:19:05,643 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:19:06,585 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0146894  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:07,414 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2861137  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:07,801 [INFO] [metadata.py:55] test_wall_time: 2.15757417678833
2023-07-10 16:19:07,802 [INFO] [metadata.py:55] test_loss: 2.0488815132979377
2023-07-10 16:19:07,802 [INFO] [metadata.py:55] test_accuracy: 0.5361265923566879
2023-07-10 16:19:07,805 [INFO] [train.py:190] Epoch: 99
2023-07-10 16:19:08,376 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:19:09,283 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0029899999  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:11,622 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.039392304  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:13,935 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.013208143  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:19:16,232 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.037431289  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:19:18,499 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.017109286  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:20,820 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.18216915  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:23,108 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.054672748  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:25,319 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0094833607  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:27,588 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.030877784  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:29,836 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0058855251  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:31,993 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0028614805  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:32,467 [INFO] [metadata.py:55] train_wall_time: 24.090333223342896
2023-07-10 16:19:32,467 [INFO] [metadata.py:55] train_loss: 0.04695921555601501
2023-07-10 16:19:32,467 [INFO] [metadata.py:55] train_accuracy: 0.9854888916015625
2023-07-10 16:19:32,468 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:19:33,349 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9364518  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:34,204 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1204386  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:34,572 [INFO] [metadata.py:55] test_wall_time: 2.1035356521606445
2023-07-10 16:19:34,572 [INFO] [metadata.py:55] test_loss: 1.9964652251286112
2023-07-10 16:19:34,572 [INFO] [metadata.py:55] test_accuracy: 0.5437898089171974
2023-07-10 16:19:34,576 [INFO] [train.py:190] Epoch: 100
2023-07-10 16:19:35,233 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:19:36,226 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.019273192  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:38,553 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0062040947  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:40,896 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0056815692  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:43,113 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.034505676  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:45,288 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.011374015  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:47,410 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.15094359  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:49,688 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.018610522  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:51,939 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.10377192  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:54,094 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.030256948  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:56,255 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0049598576  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:58,437 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.017351918  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:19:58,920 [INFO] [metadata.py:55] train_wall_time: 23.687129735946655
2023-07-10 16:19:58,920 [INFO] [metadata.py:55] train_loss: 0.0465732131612242
2023-07-10 16:19:58,920 [INFO] [metadata.py:55] train_accuracy: 0.9858856201171875
2023-07-10 16:19:58,921 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:19:59,841 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0612712  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:00,745 [INFO] [trainer.py:169]   batch 100/157  loss:  2.16927  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:01,144 [INFO] [metadata.py:55] test_wall_time: 2.2228355407714844
2023-07-10 16:20:01,144 [INFO] [metadata.py:55] test_loss: 1.9975581290615592
2023-07-10 16:20:01,144 [INFO] [metadata.py:55] test_accuracy: 0.5447850318471338
2023-07-10 16:20:01,148 [INFO] [train.py:216] Updating best model with epoch: 100
2023-07-10 16:20:01,161 [INFO] [train.py:190] Epoch: 101
2023-07-10 16:20:01,752 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:20:02,735 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0054531242  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:04,971 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.038452495  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:07,268 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0059015984  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:09,524 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.015456527  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:11,794 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.006093821  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:20:13,999 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.17434148  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:20:16,220 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.01837826  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:20:18,464 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.060227454  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:20,672 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.094651878  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:22,975 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0237613  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:25,245 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0068832426  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:25,719 [INFO] [metadata.py:55] train_wall_time: 23.967247486114502
2023-07-10 16:20:25,720 [INFO] [metadata.py:55] train_loss: 0.04464338595798267
2023-07-10 16:20:25,720 [INFO] [metadata.py:55] train_accuracy: 0.9863128662109375
2023-07-10 16:20:25,720 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:20:26,643 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1995032  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:27,432 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0501676  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:27,790 [INFO] [metadata.py:55] test_wall_time: 2.069072723388672
2023-07-10 16:20:27,790 [INFO] [metadata.py:55] test_loss: 2.1176777007473504
2023-07-10 16:20:27,790 [INFO] [metadata.py:55] test_accuracy: 0.5302547770700637
2023-07-10 16:20:27,794 [INFO] [train.py:190] Epoch: 102
2023-07-10 16:20:28,376 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:20:29,316 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.045375552  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:31,541 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0015777984  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:33,776 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0022086555  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:36,097 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0014265903  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:38,460 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0017935088  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:40,775 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.085036375  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:43,005 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.2432752  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:45,294 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.065950289  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:47,483 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.1651258  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:49,649 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.036665224  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:20:51,963 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.028477401  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:20:52,491 [INFO] [metadata.py:55] train_wall_time: 24.11531376838684
2023-07-10 16:20:52,492 [INFO] [metadata.py:55] train_loss: 0.04374996431749878
2023-07-10 16:20:52,492 [INFO] [metadata.py:55] train_accuracy: 0.9866180419921875
2023-07-10 16:20:52,492 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:20:53,322 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2180514  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:20:54,206 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1582096  cpu_mem: 23.3%  gpu_mem: [10.1]% of [20470]MiB
2023-07-10 16:20:54,641 [INFO] [metadata.py:55] test_wall_time: 2.1487557888031006
2023-07-10 16:20:54,642 [INFO] [metadata.py:55] test_loss: 2.062715903968568
2023-07-10 16:20:54,642 [INFO] [metadata.py:55] test_accuracy: 0.5482683121019108
2023-07-10 16:20:54,645 [INFO] [train.py:216] Updating best model with epoch: 102
2023-07-10 16:20:54,658 [INFO] [train.py:190] Epoch: 103
2023-07-10 16:20:55,368 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:20:56,358 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.15193202  lr: 0.005029  cpu_mem: 23.5%  gpu_mem: [9.8]% of [20470]MiB
2023-07-10 16:20:58,697 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0048222411  lr: 0.007959  cpu_mem: 23.4%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:21:01,025 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.040540174  lr: 0.01089  cpu_mem: 23.5%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 16:21:03,359 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.037489098  lr: 0.01382  cpu_mem: 23.5%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 16:21:05,767 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.080663383  lr: 0.01675  cpu_mem: 23.8%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 16:21:08,124 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.15296142  lr: 0.01968  cpu_mem: 24.2%  gpu_mem: [10.0]% of [20470]MiB
2023-07-10 16:21:10,533 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.037009977  lr: 0.01739  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:12,832 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.076506525  lr: 0.01446  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:15,141 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.092832617  lr: 0.01153  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:17,402 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.024005409  lr: 0.008604  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:19,716 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.023089595  lr: 0.005674  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:20,255 [INFO] [metadata.py:55] train_wall_time: 24.88646674156189
2023-07-10 16:21:20,255 [INFO] [metadata.py:55] train_loss: 0.0452987425592255
2023-07-10 16:21:20,256 [INFO] [metadata.py:55] train_accuracy: 0.9862518310546875
2023-07-10 16:21:20,256 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:21:21,201 [INFO] [trainer.py:169]   batch 0/157  loss: 2.5675211  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:22,136 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9203168  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:22,510 [INFO] [metadata.py:55] test_wall_time: 2.2532312870025635
2023-07-10 16:21:22,510 [INFO] [metadata.py:55] test_loss: 2.158402442932129
2023-07-10 16:21:22,510 [INFO] [metadata.py:55] test_accuracy: 0.5313495222929936
2023-07-10 16:21:22,514 [INFO] [train.py:190] Epoch: 104
2023-07-10 16:21:23,098 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:21:24,078 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.022997595  lr: 0.005029  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:26,434 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.039122023  lr: 0.007959  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:28,782 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0089109177  lr: 0.01089  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:31,014 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.02403558  lr: 0.01382  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:33,268 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0056307898  lr: 0.01675  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:35,573 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.045950789  lr: 0.01968  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:37,735 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.13748156  lr: 0.01739  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:40,012 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.026890218  lr: 0.01446  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:42,401 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.022535596  lr: 0.01153  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:44,854 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.014691387  lr: 0.008604  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:47,214 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0036974081  lr: 0.005674  cpu_mem: 24.5%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:47,755 [INFO] [metadata.py:55] train_wall_time: 24.65718173980713
2023-07-10 16:21:47,756 [INFO] [metadata.py:55] train_loss: 0.044994827705835405
2023-07-10 16:21:47,756 [INFO] [metadata.py:55] train_accuracy: 0.986480712890625
2023-07-10 16:21:47,756 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:21:48,654 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9375478  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:49,498 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9603361  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:49,872 [INFO] [metadata.py:55] test_wall_time: 2.114964246749878
2023-07-10 16:21:49,872 [INFO] [metadata.py:55] test_loss: 2.1760266335906495
2023-07-10 16:21:49,872 [INFO] [metadata.py:55] test_accuracy: 0.5226910828025477
2023-07-10 16:21:49,875 [INFO] [train.py:190] Epoch: 105
2023-07-10 16:21:50,464 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:21:51,389 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0018466334  lr: 0.005029  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:53,798 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0015045388  lr: 0.007959  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:56,196 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0034479571  lr: 0.01089  cpu_mem: 24.5%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:21:58,473 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.031383194  lr: 0.01382  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:00,804 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.14013967  lr: 0.01675  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:03,095 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.12351976  lr: 0.01968  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:05,403 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.16299811  lr: 0.01739  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:07,754 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.064839296  lr: 0.01446  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:10,072 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.15605256  lr: 0.01153  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:12,335 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.038725592  lr: 0.008604  cpu_mem: 24.4%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 16:22:14,566 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0013645272  lr: 0.005674  cpu_mem: 24.4%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 16:22:15,101 [INFO] [metadata.py:55] train_wall_time: 24.637394666671753
2023-07-10 16:22:15,102 [INFO] [metadata.py:55] train_loss: 0.04360970310852963
2023-07-10 16:22:15,102 [INFO] [metadata.py:55] train_accuracy: 0.986724853515625
2023-07-10 16:22:15,102 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:22:16,044 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2775197  cpu_mem: 24.3%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 16:22:16,918 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9666672  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:17,282 [INFO] [metadata.py:55] test_wall_time: 2.1790857315063477
2023-07-10 16:22:17,282 [INFO] [metadata.py:55] test_loss: 2.0284989252211942
2023-07-10 16:22:17,282 [INFO] [metadata.py:55] test_accuracy: 0.5445859872611465
2023-07-10 16:22:17,286 [INFO] [train.py:190] Epoch: 106
2023-07-10 16:22:17,861 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:22:18,815 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.006556103  lr: 0.005029  cpu_mem: 24.3%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:21,283 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.026187811  lr: 0.007959  cpu_mem: 25.3%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:23,534 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0055647097  lr: 0.01089  cpu_mem: 25.3%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:25,839 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.03004555  lr: 0.01382  cpu_mem: 25.3%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:28,265 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.012685085  lr: 0.01675  cpu_mem: 25.2%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:30,621 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.053788353  lr: 0.01968  cpu_mem: 25.2%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:32,918 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.058993712  lr: 0.01739  cpu_mem: 25.2%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:35,145 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.074051946  lr: 0.01446  cpu_mem: 25.2%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:37,367 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.033357557  lr: 0.01153  cpu_mem: 25.2%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:39,605 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0053417664  lr: 0.008604  cpu_mem: 25.2%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:41,899 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.014980562  lr: 0.005674  cpu_mem: 25.3%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:42,406 [INFO] [metadata.py:55] train_wall_time: 24.545621395111084
2023-07-10 16:22:42,407 [INFO] [metadata.py:55] train_loss: 0.045723313992724
2023-07-10 16:22:42,407 [INFO] [metadata.py:55] train_accuracy: 0.9861297607421875
2023-07-10 16:22:42,407 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:22:43,269 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9313097  cpu_mem: 24.2%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:44,170 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0997026  cpu_mem: 24.3%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:44,570 [INFO] [metadata.py:55] test_wall_time: 2.1621620655059814
2023-07-10 16:22:44,570 [INFO] [metadata.py:55] test_loss: 2.107960994076577
2023-07-10 16:22:44,570 [INFO] [metadata.py:55] test_accuracy: 0.5391122611464968
2023-07-10 16:22:44,574 [INFO] [train.py:190] Epoch: 107
2023-07-10 16:22:45,186 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:22:46,133 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0026351905  lr: 0.005029  cpu_mem: 24.3%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:48,438 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0010983297  lr: 0.007959  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:50,766 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.04710266  lr: 0.01089  cpu_mem: 24.3%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:53,153 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.1553424  lr: 0.01382  cpu_mem: 24.3%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:55,412 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.037354354  lr: 0.01675  cpu_mem: 24.4%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:22:57,814 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.043164086  lr: 0.01968  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:00,056 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.1650387  lr: 0.01739  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:02,294 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.076159425  lr: 0.01446  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:04,702 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0049319854  lr: 0.01153  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:06,905 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.012880965  lr: 0.008604  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:09,164 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0060776742  lr: 0.005674  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:09,657 [INFO] [metadata.py:55] train_wall_time: 24.470920085906982
2023-07-10 16:23:09,658 [INFO] [metadata.py:55] train_loss: 0.04451921376227119
2023-07-10 16:23:09,658 [INFO] [metadata.py:55] train_accuracy: 0.9861907958984375
2023-07-10 16:23:09,658 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:23:10,645 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1407967  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:11,557 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8193809  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:11,925 [INFO] [metadata.py:55] test_wall_time: 2.266127824783325
2023-07-10 16:23:11,925 [INFO] [metadata.py:55] test_loss: 2.0532222469900825
2023-07-10 16:23:11,934 [INFO] [metadata.py:55] test_accuracy: 0.5419984076433121
2023-07-10 16:23:11,942 [INFO] [train.py:190] Epoch: 108
2023-07-10 16:23:12,535 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:23:13,453 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0047804057  lr: 0.005029  cpu_mem: 24.0%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 16:23:15,703 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.053874791  lr: 0.007959  cpu_mem: 24.0%  gpu_mem: [10.4]% of [20470]MiB
2023-07-10 16:23:18,044 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0031690493  lr: 0.01089  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:20,450 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.016122656  lr: 0.01382  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:22,812 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.027379738  lr: 0.01675  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:25,146 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.12211688  lr: 0.01968  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:27,384 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.040275499  lr: 0.01739  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:29,589 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.059312813  lr: 0.01446  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:31,830 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0549662  lr: 0.01153  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:34,026 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.081616931  lr: 0.008604  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:36,278 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0090192929  lr: 0.005674  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:36,809 [INFO] [metadata.py:55] train_wall_time: 24.274657487869263
2023-07-10 16:23:36,810 [INFO] [metadata.py:55] train_loss: 0.045765231662102224
2023-07-10 16:23:36,810 [INFO] [metadata.py:55] train_accuracy: 0.98663330078125
2023-07-10 16:23:36,810 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:23:37,663 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9501392  cpu_mem: 23.9%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:38,495 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0188181  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:38,854 [INFO] [metadata.py:55] test_wall_time: 2.0430874824523926
2023-07-10 16:23:38,854 [INFO] [metadata.py:55] test_loss: 2.0497120098703228
2023-07-10 16:23:38,854 [INFO] [metadata.py:55] test_accuracy: 0.54796974522293
2023-07-10 16:23:38,858 [INFO] [train.py:190] Epoch: 109
2023-07-10 16:23:39,432 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:23:40,493 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0012753016  lr: 0.005029  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:42,672 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00066895678  lr: 0.007959  cpu_mem: 24.0%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:44,937 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.032030672  lr: 0.01089  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:47,189 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.053839009  lr: 0.01382  cpu_mem: 24.1%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:49,522 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.10597567  lr: 0.01675  cpu_mem: 23.7%  gpu_mem: [10.3]% of [20470]MiB
2023-07-10 16:23:51,861 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.018410638  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:23:54,153 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.050735384  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:23:56,480 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.018955568  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:23:58,806 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0075894757  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:24:01,052 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.04893548  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:03,275 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0009344673  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:03,773 [INFO] [metadata.py:55] train_wall_time: 24.341723918914795
2023-07-10 16:24:03,774 [INFO] [metadata.py:55] train_loss: 0.045494788730721325
2023-07-10 16:24:03,774 [INFO] [metadata.py:55] train_accuracy: 0.9860687255859375
2023-07-10 16:24:03,774 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:24:04,760 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2365725  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:05,554 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2325668  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:05,927 [INFO] [metadata.py:55] test_wall_time: 2.1522531509399414
2023-07-10 16:24:05,927 [INFO] [metadata.py:55] test_loss: 2.175787648577599
2023-07-10 16:24:05,927 [INFO] [metadata.py:55] test_accuracy: 0.5336385350318471
2023-07-10 16:24:05,931 [INFO] [train.py:190] Epoch: 110
2023-07-10 16:24:06,604 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:24:07,527 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.067157909  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:09,807 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.018146355  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:12,083 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.014591046  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:24:14,396 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.04909667  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:24:16,811 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.080323592  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:24:19,134 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.033825219  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:24:21,443 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.11888485  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:24:23,848 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.030866796  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:24:26,046 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.004503076  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:28,226 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0080351587  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:30,420 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0071602017  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:30,922 [INFO] [metadata.py:55] train_wall_time: 24.31744647026062
2023-07-10 16:24:30,922 [INFO] [metadata.py:55] train_loss: 0.043974395152247325
2023-07-10 16:24:30,922 [INFO] [metadata.py:55] train_accuracy: 0.9863433837890625
2023-07-10 16:24:30,923 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:24:31,923 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8321249  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:32,748 [INFO] [trainer.py:169]   batch 100/157  loss: 1.5899945  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:33,112 [INFO] [metadata.py:55] test_wall_time: 2.1882688999176025
2023-07-10 16:24:33,112 [INFO] [metadata.py:55] test_loss: 2.0337926324006097
2023-07-10 16:24:33,112 [INFO] [metadata.py:55] test_accuracy: 0.5467754777070064
2023-07-10 16:24:33,116 [INFO] [train.py:190] Epoch: 111
2023-07-10 16:24:33,691 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:24:34,696 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.008976372  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:37,173 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.035692655  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:39,394 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0037392739  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:41,672 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.042834383  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:24:43,924 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.048671972  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:24:46,196 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.047432408  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:24:48,487 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0049974653  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:24:50,813 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.074376404  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:24:53,116 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.016499925  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:24:55,368 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.020971216  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:24:57,627 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00071548118  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:24:58,129 [INFO] [metadata.py:55] train_wall_time: 24.438335418701172
2023-07-10 16:24:58,130 [INFO] [metadata.py:55] train_loss: 0.04432188382210711
2023-07-10 16:24:58,130 [INFO] [metadata.py:55] train_accuracy: 0.986419677734375
2023-07-10 16:24:58,130 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:24:59,024 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8040729  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:24:59,881 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8222532  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:25:00,270 [INFO] [metadata.py:55] test_wall_time: 2.139575719833374
2023-07-10 16:25:00,270 [INFO] [metadata.py:55] test_loss: 2.034682298162181
2023-07-10 16:25:00,271 [INFO] [metadata.py:55] test_accuracy: 0.5387141719745223
2023-07-10 16:25:00,274 [INFO] [train.py:190] Epoch: 112
2023-07-10 16:25:00,836 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:25:01,730 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0011845736  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:25:03,979 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.026242234  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:25:06,220 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.035439774  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:25:08,492 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.16025436  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:25:10,653 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.015671922  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:25:12,945 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.091127157  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:25:15,233 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.023447974  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:25:17,482 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.042579714  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:25:19,678 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.10931443  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:25:22,067 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0078020277  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:25:24,390 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00094402442  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:25:24,888 [INFO] [metadata.py:55] train_wall_time: 24.051579236984253
2023-07-10 16:25:24,889 [INFO] [metadata.py:55] train_loss: 0.04385889868279946
2023-07-10 16:25:24,889 [INFO] [metadata.py:55] train_accuracy: 0.98638916015625
2023-07-10 16:25:24,889 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:25:25,764 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8192606  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:25:26,670 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8259088  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:25:27,088 [INFO] [metadata.py:55] test_wall_time: 2.198951005935669
2023-07-10 16:25:27,089 [INFO] [metadata.py:55] test_loss: 2.072790320511836
2023-07-10 16:25:27,089 [INFO] [metadata.py:55] test_accuracy: 0.550656847133758
2023-07-10 16:25:27,093 [INFO] [train.py:216] Updating best model with epoch: 112
2023-07-10 16:25:27,105 [INFO] [train.py:190] Epoch: 113
2023-07-10 16:25:27,692 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:25:28,691 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0033011611  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:25:30,944 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.004015178  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:25:33,152 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.078991175  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:25:35,475 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0046237637  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:25:37,893 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.049550161  lr: 0.01675  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:25:40,264 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.079776011  lr: 0.01968  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:25:42,551 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0061882399  lr: 0.01739  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:25:44,885 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.090957135  lr: 0.01446  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:25:47,275 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.054037638  lr: 0.01153  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:25:49,507 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.013350211  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:25:51,776 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00028551489  lr: 0.005674  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:25:52,269 [INFO] [metadata.py:55] train_wall_time: 24.576886892318726
2023-07-10 16:25:52,269 [INFO] [metadata.py:55] train_loss: 0.044682365450313455
2023-07-10 16:25:52,269 [INFO] [metadata.py:55] train_accuracy: 0.9864959716796875
2023-07-10 16:25:52,270 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:25:53,142 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3949027  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:25:54,000 [INFO] [trainer.py:169]   batch 100/157  loss: 1.7273661  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:25:54,377 [INFO] [metadata.py:55] test_wall_time: 2.106757640838623
2023-07-10 16:25:54,377 [INFO] [metadata.py:55] test_loss: 2.109228427243081
2023-07-10 16:25:54,377 [INFO] [metadata.py:55] test_accuracy: 0.5443869426751592
2023-07-10 16:25:54,381 [INFO] [train.py:190] Epoch: 114
2023-07-10 16:25:54,971 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:25:55,933 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0016663724  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:25:58,221 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.024754431  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:26:00,609 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0060359221  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:26:02,934 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.050701626  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:26:05,289 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.066559769  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:26:07,520 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.032765482  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:26:09,780 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.083379626  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:26:12,038 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.089116521  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:26:14,389 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.034983721  lr: 0.01153  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:26:16,811 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0077272849  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:26:19,177 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.03190672  lr: 0.005674  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:26:19,691 [INFO] [metadata.py:55] train_wall_time: 24.7200665473938
2023-07-10 16:26:19,691 [INFO] [metadata.py:55] train_loss: 0.044371285096616475
2023-07-10 16:26:19,692 [INFO] [metadata.py:55] train_accuracy: 0.986907958984375
2023-07-10 16:26:19,692 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:26:20,621 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0477493  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:26:21,512 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0605423  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:26:21,877 [INFO] [metadata.py:55] test_wall_time: 2.184399127960205
2023-07-10 16:26:21,877 [INFO] [metadata.py:55] test_loss: 2.1085263984218523
2023-07-10 16:26:21,877 [INFO] [metadata.py:55] test_accuracy: 0.5272691082802548
2023-07-10 16:26:21,881 [INFO] [train.py:190] Epoch: 115
2023-07-10 16:26:22,486 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:26:23,397 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00076129282  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:26:25,743 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0013944147  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:26:28,052 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.003163547  lr: 0.01089  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:26:30,404 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.02932732  lr: 0.01382  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:26:32,791 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.034665193  lr: 0.01675  cpu_mem: 23.5%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:26:35,307 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.046189453  lr: 0.01968  cpu_mem: 23.6%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:26:37,609 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.11253764  lr: 0.01739  cpu_mem: 23.6%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:26:39,934 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.023850884  lr: 0.01446  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:26:42,289 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.079475231  lr: 0.01153  cpu_mem: 23.7%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:26:44,547 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.085906006  lr: 0.008604  cpu_mem: 23.7%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:26:46,794 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0043052873  lr: 0.005674  cpu_mem: 23.7%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:26:47,299 [INFO] [metadata.py:55] train_wall_time: 24.812767028808594
2023-07-10 16:26:47,300 [INFO] [metadata.py:55] train_loss: 0.04484799337524237
2023-07-10 16:26:47,300 [INFO] [metadata.py:55] train_accuracy: 0.9864044189453125
2023-07-10 16:26:47,300 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:26:48,282 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0769658  cpu_mem: 23.6%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:26:49,128 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0741315  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:26:49,552 [INFO] [metadata.py:55] test_wall_time: 2.2511518001556396
2023-07-10 16:26:49,552 [INFO] [metadata.py:55] test_loss: 2.0803517277833
2023-07-10 16:26:49,552 [INFO] [metadata.py:55] test_accuracy: 0.5477707006369427
2023-07-10 16:26:49,556 [INFO] [train.py:190] Epoch: 116
2023-07-10 16:26:50,161 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:26:51,147 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0063818712  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:26:53,357 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.067161463  lr: 0.007959  cpu_mem: 23.2%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:26:55,631 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.015291583  lr: 0.01089  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:26:57,827 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.04687972  lr: 0.01382  cpu_mem: 23.3%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:26:59,934 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.11577824  lr: 0.01675  cpu_mem: 23.2%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:27:02,215 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0066697802  lr: 0.01968  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:04,599 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.24086411  lr: 0.01739  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:06,808 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.10185338  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:08,955 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.012802119  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:11,115 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0053251828  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:13,394 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0018083862  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:27:13,934 [INFO] [metadata.py:55] train_wall_time: 23.77280354499817
2023-07-10 16:27:13,934 [INFO] [metadata.py:55] train_loss: 0.04570381361912723
2023-07-10 16:27:13,934 [INFO] [metadata.py:55] train_accuracy: 0.9860992431640625
2023-07-10 16:27:13,935 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:27:14,940 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3667297  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:15,771 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0017366  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:16,116 [INFO] [metadata.py:55] test_wall_time: 2.180908203125
2023-07-10 16:27:16,116 [INFO] [metadata.py:55] test_loss: 2.134664602340407
2023-07-10 16:27:16,117 [INFO] [metadata.py:55] test_accuracy: 0.5439888535031847
2023-07-10 16:27:16,120 [INFO] [train.py:190] Epoch: 117
2023-07-10 16:27:16,787 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:27:17,677 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.17615969  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:20,015 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0030100578  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:22,331 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.017308313  lr: 0.01089  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:24,523 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.022651646  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:26,928 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.013168194  lr: 0.01675  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:29,236 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.040227383  lr: 0.01968  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:31,552 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0028711283  lr: 0.01739  cpu_mem: 23.2%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:27:33,848 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.064711407  lr: 0.01446  cpu_mem: 23.2%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:27:36,101 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.13279599  lr: 0.01153  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:27:38,475 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.01797468  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:40,801 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.056953304  lr: 0.005674  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:41,289 [INFO] [metadata.py:55] train_wall_time: 24.502307653427124
2023-07-10 16:27:41,290 [INFO] [metadata.py:55] train_loss: 0.0429558725370498
2023-07-10 16:27:41,290 [INFO] [metadata.py:55] train_accuracy: 0.9864044189453125
2023-07-10 16:27:41,290 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:27:42,205 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1435363  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:43,091 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1618073  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:43,477 [INFO] [metadata.py:55] test_wall_time: 2.186493396759033
2023-07-10 16:27:43,477 [INFO] [metadata.py:55] test_loss: 2.1538470110316186
2023-07-10 16:27:43,478 [INFO] [metadata.py:55] test_accuracy: 0.5399084394904459
2023-07-10 16:27:43,483 [INFO] [train.py:190] Epoch: 118
2023-07-10 16:27:44,067 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:27:45,011 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.043277979  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:47,262 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.028479878  lr: 0.007959  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:49,507 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.054387756  lr: 0.01089  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:51,825 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.030291198  lr: 0.01382  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:54,216 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.016591638  lr: 0.01675  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:27:56,565 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.023483818  lr: 0.01968  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:27:58,832 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.14079154  lr: 0.01739  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:28:00,988 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.021859314  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:28:03,256 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0038410479  lr: 0.01153  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:28:05,603 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.021516105  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:28:07,896 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.029086629  lr: 0.005674  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:28:08,401 [INFO] [metadata.py:55] train_wall_time: 24.333505392074585
2023-07-10 16:28:08,401 [INFO] [metadata.py:55] train_loss: 0.041677786381271176
2023-07-10 16:28:08,401 [INFO] [metadata.py:55] train_accuracy: 0.9868621826171875
2023-07-10 16:28:08,401 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:28:09,275 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1321447  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:28:10,117 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1300654  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:28:10,506 [INFO] [metadata.py:55] test_wall_time: 2.1037826538085938
2023-07-10 16:28:10,506 [INFO] [metadata.py:55] test_loss: 2.116570802251245
2023-07-10 16:28:10,506 [INFO] [metadata.py:55] test_accuracy: 0.5413017515923567
2023-07-10 16:28:10,510 [INFO] [train.py:190] Epoch: 119
2023-07-10 16:28:11,085 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:28:12,057 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0035290911  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:28:14,280 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0043016048  lr: 0.007959  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:28:16,577 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0060185739  lr: 0.01089  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:28:18,820 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0068842159  lr: 0.01382  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:28:21,018 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0097018918  lr: 0.01675  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:28:23,219 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.001918984  lr: 0.01968  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:28:25,457 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.077826105  lr: 0.01739  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:28:27,719 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.090929814  lr: 0.01446  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:28:29,933 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.074839592  lr: 0.01153  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:28:32,169 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0070932945  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:28:34,465 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0065867691  lr: 0.005674  cpu_mem: 23.2%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:28:34,934 [INFO] [metadata.py:55] train_wall_time: 23.84936785697937
2023-07-10 16:28:34,934 [INFO] [metadata.py:55] train_loss: 0.043897757852903396
2023-07-10 16:28:34,935 [INFO] [metadata.py:55] train_accuracy: 0.9865264892578125
2023-07-10 16:28:34,935 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:28:35,869 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9551251  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:28:36,690 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8867157  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:28:37,038 [INFO] [metadata.py:55] test_wall_time: 2.102309226989746
2023-07-10 16:28:37,038 [INFO] [metadata.py:55] test_loss: 2.062562908336615
2023-07-10 16:28:37,038 [INFO] [metadata.py:55] test_accuracy: 0.5505573248407644
2023-07-10 16:28:37,042 [INFO] [train.py:216] Updating best model with epoch: 119
2023-07-10 16:28:37,054 [INFO] [train.py:190] Epoch: 120
2023-07-10 16:28:37,687 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:28:38,609 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.064113259  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:28:40,834 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.023009734  lr: 0.007959  cpu_mem: 23.2%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:28:43,004 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.075738668  lr: 0.01089  cpu_mem: 23.2%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:28:45,141 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.073707521  lr: 0.01382  cpu_mem: 23.2%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:28:47,283 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.042508129  lr: 0.01675  cpu_mem: 23.2%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:28:49,447 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0606848  lr: 0.01968  cpu_mem: 23.2%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:28:51,700 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.056848433  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:28:53,889 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0066491957  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:28:56,065 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.028949022  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:28:58,255 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.063535355  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:29:00,401 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0038152384  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:29:00,853 [INFO] [metadata.py:55] train_wall_time: 23.165435075759888
2023-07-10 16:29:00,853 [INFO] [metadata.py:55] train_loss: 0.04267992769835871
2023-07-10 16:29:00,854 [INFO] [metadata.py:55] train_accuracy: 0.98651123046875
2023-07-10 16:29:00,854 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:29:01,726 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0938997  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:29:02,585 [INFO] [trainer.py:169]   batch 100/157  loss: 1.7698313  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:02,930 [INFO] [metadata.py:55] test_wall_time: 2.076011896133423
2023-07-10 16:29:02,931 [INFO] [metadata.py:55] test_loss: 2.076383791911374
2023-07-10 16:29:02,931 [INFO] [metadata.py:55] test_accuracy: 0.5492635350318471
2023-07-10 16:29:02,934 [INFO] [train.py:190] Epoch: 121
2023-07-10 16:29:03,494 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:29:04,401 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0010779283  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:06,584 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.027329188  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:29:08,665 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0041478807  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:29:10,818 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0091104517  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:29:12,970 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.01813598  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:15,189 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.055822663  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:29:17,392 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0098433821  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:29:19,572 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.14718227  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:29:21,797 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.022149561  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:24,021 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.034730274  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:29:26,257 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00074965239  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:29:26,717 [INFO] [metadata.py:55] train_wall_time: 23.222853899002075
2023-07-10 16:29:26,717 [INFO] [metadata.py:55] train_loss: 0.04590751785354996
2023-07-10 16:29:26,717 [INFO] [metadata.py:55] train_accuracy: 0.98583984375
2023-07-10 16:29:26,717 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:29:27,625 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9782929  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:28,501 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1701403  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:28,869 [INFO] [metadata.py:55] test_wall_time: 2.1510133743286133
2023-07-10 16:29:28,869 [INFO] [metadata.py:55] test_loss: 2.031508731234605
2023-07-10 16:29:28,869 [INFO] [metadata.py:55] test_accuracy: 0.5547372611464968
2023-07-10 16:29:28,873 [INFO] [train.py:216] Updating best model with epoch: 121
2023-07-10 16:29:28,885 [INFO] [train.py:190] Epoch: 122
2023-07-10 16:29:29,464 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:29:30,423 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0094116703  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:32,501 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.013881148  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:34,660 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.021840436  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:36,911 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0083325682  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:29:39,017 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.048674237  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:41,225 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.1121473  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:43,446 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.090922803  lr: 0.01739  cpu_mem: 23.2%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:45,712 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.097237326  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:47,866 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0016086771  lr: 0.01153  cpu_mem: 23.2%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:50,016 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.060358237  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:52,228 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0063874559  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:29:52,735 [INFO] [metadata.py:55] train_wall_time: 23.271204948425293
2023-07-10 16:29:52,735 [INFO] [metadata.py:55] train_loss: 0.043193389015470984
2023-07-10 16:29:52,736 [INFO] [metadata.py:55] train_accuracy: 0.9867095947265625
2023-07-10 16:29:52,736 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:29:53,569 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3557332  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:54,433 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9311297  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:54,809 [INFO] [metadata.py:55] test_wall_time: 2.072798490524292
2023-07-10 16:29:54,809 [INFO] [metadata.py:55] test_loss: 2.2400413964204726
2023-07-10 16:29:54,810 [INFO] [metadata.py:55] test_accuracy: 0.5261743630573248
2023-07-10 16:29:54,813 [INFO] [train.py:190] Epoch: 123
2023-07-10 16:29:55,417 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:29:56,324 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0030669651  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:29:58,397 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.05727163  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:00,580 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.011958081  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:02,814 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.13236091  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:04,961 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.045166891  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:07,137 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.021436211  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:09,211 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.02302636  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:11,292 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.066297181  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:30:13,370 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.11971401  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:30:15,452 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.040363535  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:30:17,639 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.027217435  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:30:18,126 [INFO] [metadata.py:55] train_wall_time: 22.709173679351807
2023-07-10 16:30:18,127 [INFO] [metadata.py:55] train_loss: 0.04242365430266659
2023-07-10 16:30:18,127 [INFO] [metadata.py:55] train_accuracy: 0.986785888671875
2023-07-10 16:30:18,127 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:30:18,994 [INFO] [trainer.py:169]   batch 0/157  loss: 2.375283  cpu_mem: 23.0%  gpu_mem: [9.7]% of [20470]MiB
2023-07-10 16:30:19,854 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0233026  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:20,245 [INFO] [metadata.py:55] test_wall_time: 2.1169965267181396
2023-07-10 16:30:20,245 [INFO] [metadata.py:55] test_loss: 2.2404446002024754
2023-07-10 16:30:20,245 [INFO] [metadata.py:55] test_accuracy: 0.5259753184713376
2023-07-10 16:30:20,249 [INFO] [train.py:190] Epoch: 124
2023-07-10 16:30:20,893 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:30:21,801 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0024496755  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:23,900 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.07235454  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:26,111 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.013103419  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:28,340 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.069615453  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:30,568 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.073838085  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:32,786 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0049065761  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:34,971 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.010142763  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:37,101 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.020081438  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:39,196 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.021331334  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:41,348 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0028943955  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:43,536 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.011382254  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:43,996 [INFO] [metadata.py:55] train_wall_time: 23.103682279586792
2023-07-10 16:30:43,997 [INFO] [metadata.py:55] train_loss: 0.04163433237619074
2023-07-10 16:30:44,006 [INFO] [metadata.py:55] train_accuracy: 0.987396240234375
2023-07-10 16:30:44,006 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:30:44,917 [INFO] [trainer.py:169]   batch 0/157  loss: 2.4764826  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:45,739 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9669944  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:46,087 [INFO] [metadata.py:55] test_wall_time: 2.078714370727539
2023-07-10 16:30:46,087 [INFO] [metadata.py:55] test_loss: 2.2962405180475516
2023-07-10 16:30:46,087 [INFO] [metadata.py:55] test_accuracy: 0.5276671974522293
2023-07-10 16:30:46,091 [INFO] [train.py:190] Epoch: 125
2023-07-10 16:30:46,676 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:30:47,597 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0017053385  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:49,666 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.055327855  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:51,889 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0012265609  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:54,150 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.080490008  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:30:56,476 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.017074438  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:30:58,749 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.022487257  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:01,003 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.042781647  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:03,116 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.16756251  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:05,288 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0077585583  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:07,463 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.02571593  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:09,641 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0084702345  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:10,173 [INFO] [metadata.py:55] train_wall_time: 23.49671769142151
2023-07-10 16:31:10,174 [INFO] [metadata.py:55] train_loss: 0.0419759155906263
2023-07-10 16:31:10,174 [INFO] [metadata.py:55] train_accuracy: 0.9871368408203125
2023-07-10 16:31:10,174 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:31:11,051 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9262018  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:11,884 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0394289  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:12,254 [INFO] [metadata.py:55] test_wall_time: 2.0790176391601562
2023-07-10 16:31:12,254 [INFO] [metadata.py:55] test_loss: 2.2357648983123197
2023-07-10 16:31:12,254 [INFO] [metadata.py:55] test_accuracy: 0.525577229299363
2023-07-10 16:31:12,258 [INFO] [train.py:190] Epoch: 126
2023-07-10 16:31:12,829 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:31:13,742 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.006622876  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:31:15,817 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00021171181  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:31:17,817 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0034628822  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:31:19,863 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0053980057  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.6]% of [20470]MiB
2023-07-10 16:31:21,956 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.019662896  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:24,141 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.036667861  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:26,243 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.12538145  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:28,429 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.088411584  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:30,588 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.12152304  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:32,700 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0023222433  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:34,776 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.086644828  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:35,258 [INFO] [metadata.py:55] train_wall_time: 22.428781509399414
2023-07-10 16:31:35,258 [INFO] [metadata.py:55] train_loss: 0.03983183843534732
2023-07-10 16:31:35,258 [INFO] [metadata.py:55] train_accuracy: 0.9876251220703125
2023-07-10 16:31:35,258 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:31:36,178 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0807915  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:36,961 [INFO] [trainer.py:169]   batch 100/157  loss: 1.7189112  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:37,308 [INFO] [metadata.py:55] test_wall_time: 2.049097776412964
2023-07-10 16:31:37,308 [INFO] [metadata.py:55] test_loss: 2.068021163059648
2023-07-10 16:31:37,308 [INFO] [metadata.py:55] test_accuracy: 0.5472730891719745
2023-07-10 16:31:37,312 [INFO] [train.py:190] Epoch: 127
2023-07-10 16:31:37,956 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:31:38,912 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.029011533  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:31:41,069 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.004221099  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:31:43,245 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0061966376  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:31:45,492 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.032427967  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:31:47,722 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.095331863  lr: 0.01675  cpu_mem: 23.2%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:31:49,964 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.07246238  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:31:52,172 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0025305704  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:31:54,433 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0069093886  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:31:56,600 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.05483079  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:31:58,757 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0029936254  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:32:01,052 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0089881038  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:01,528 [INFO] [metadata.py:55] train_wall_time: 23.57218837738037
2023-07-10 16:32:01,529 [INFO] [metadata.py:55] train_loss: 0.044697115772180496
2023-07-10 16:32:01,529 [INFO] [metadata.py:55] train_accuracy: 0.9864654541015625
2023-07-10 16:32:01,529 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:32:02,424 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9955752  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:03,205 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0272112  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:03,557 [INFO] [metadata.py:55] test_wall_time: 2.027988910675049
2023-07-10 16:32:03,558 [INFO] [metadata.py:55] test_loss: 2.111179683618485
2023-07-10 16:32:03,558 [INFO] [metadata.py:55] test_accuracy: 0.5450835987261147
2023-07-10 16:32:03,562 [INFO] [train.py:190] Epoch: 128
2023-07-10 16:32:04,134 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:32:05,064 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.044341031  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:32:07,380 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0074628112  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:32:09,700 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.062437609  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:32:11,861 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0026360499  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:32:13,954 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.022306489  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:32:16,127 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.11360461  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:18,258 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.083283089  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:20,413 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.07235454  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:22,520 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0011068949  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:24,597 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.087688275  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:26,784 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00070539484  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:27,256 [INFO] [metadata.py:55] train_wall_time: 23.121779441833496
2023-07-10 16:32:27,256 [INFO] [metadata.py:55] train_loss: 0.041628060248996235
2023-07-10 16:32:27,257 [INFO] [metadata.py:55] train_accuracy: 0.9874420166015625
2023-07-10 16:32:27,257 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:32:28,139 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1319659  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:29,027 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2880139  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:29,401 [INFO] [metadata.py:55] test_wall_time: 2.143848180770874
2023-07-10 16:32:29,402 [INFO] [metadata.py:55] test_loss: 2.0762769963331285
2023-07-10 16:32:29,402 [INFO] [metadata.py:55] test_accuracy: 0.5586186305732485
2023-07-10 16:32:29,405 [INFO] [train.py:216] Updating best model with epoch: 128
2023-07-10 16:32:29,418 [INFO] [train.py:190] Epoch: 129
2023-07-10 16:32:29,984 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:32:30,955 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0043814997  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:33,268 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0027311349  lr: 0.007959  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:35,549 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0041351225  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:32:37,697 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.024789918  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:39,850 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.029384337  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:42,002 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.045807105  lr: 0.01968  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:44,091 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.056281004  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:46,269 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.046979181  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:48,464 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.072248816  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:50,620 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0079580322  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:52,755 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00054774113  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:53,235 [INFO] [metadata.py:55] train_wall_time: 23.251200199127197
2023-07-10 16:32:53,236 [INFO] [metadata.py:55] train_loss: 0.04214922827799228
2023-07-10 16:32:53,236 [INFO] [metadata.py:55] train_accuracy: 0.987030029296875
2023-07-10 16:32:53,236 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:32:54,207 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0121758  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:55,101 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0941153  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:55,468 [INFO] [metadata.py:55] test_wall_time: 2.2309839725494385
2023-07-10 16:32:55,468 [INFO] [metadata.py:55] test_loss: 2.176987937301587
2023-07-10 16:32:55,468 [INFO] [metadata.py:55] test_accuracy: 0.5410031847133758
2023-07-10 16:32:55,472 [INFO] [train.py:190] Epoch: 130
2023-07-10 16:32:56,032 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:32:56,991 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.044715688  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:32:59,160 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.01328338  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:01,333 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.057641335  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:03,485 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0016227074  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:05,660 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.039222736  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:07,816 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.064434052  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:10,012 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.068118222  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:12,208 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0027042073  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:14,448 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.083650358  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:33:16,729 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0049346532  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:33:18,968 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.001170192  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:33:19,480 [INFO] [metadata.py:55] train_wall_time: 23.447747230529785
2023-07-10 16:33:19,480 [INFO] [metadata.py:55] train_loss: 0.0409662850349406
2023-07-10 16:33:19,480 [INFO] [metadata.py:55] train_accuracy: 0.98773193359375
2023-07-10 16:33:19,481 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:33:20,369 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0643775  cpu_mem: 22.9%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:21,156 [INFO] [trainer.py:169]   batch 100/157  loss: 1.642964  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:21,503 [INFO] [metadata.py:55] test_wall_time: 2.0221927165985107
2023-07-10 16:33:21,504 [INFO] [metadata.py:55] test_loss: 2.04333949278874
2023-07-10 16:33:21,504 [INFO] [metadata.py:55] test_accuracy: 0.5597133757961783
2023-07-10 16:33:21,508 [INFO] [train.py:216] Updating best model with epoch: 130
2023-07-10 16:33:21,520 [INFO] [train.py:190] Epoch: 131
2023-07-10 16:33:22,086 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:33:23,061 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0010370367  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:25,326 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.096638165  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:33:27,475 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0064814128  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:33:29,748 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.049472228  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:33:32,026 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.037985746  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.5]% of [20470]MiB
2023-07-10 16:33:34,231 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.030535169  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:36,368 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.013391496  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:33:38,491 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.046057958  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:40,660 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.010752012  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:42,912 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.086517788  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:45,137 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.057315093  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:45,621 [INFO] [metadata.py:55] train_wall_time: 23.534746885299683
2023-07-10 16:33:45,621 [INFO] [metadata.py:55] train_loss: 0.04143513925896514
2023-07-10 16:33:45,621 [INFO] [metadata.py:55] train_accuracy: 0.98736572265625
2023-07-10 16:33:45,621 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:33:46,536 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9627228  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:47,367 [INFO] [trainer.py:169]   batch 100/157  loss: 1.7483435  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:47,744 [INFO] [metadata.py:55] test_wall_time: 2.1223385334014893
2023-07-10 16:33:47,744 [INFO] [metadata.py:55] test_loss: 2.066402366966199
2023-07-10 16:33:47,753 [INFO] [metadata.py:55] test_accuracy: 0.5467754777070064
2023-07-10 16:33:47,762 [INFO] [train.py:190] Epoch: 132
2023-07-10 16:33:48,355 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:33:49,253 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0020005463  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:51,329 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00095631392  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:53,419 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0023199019  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:55,525 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.03309118  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:57,673 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.097769864  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:33:59,825 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.050672706  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:02,004 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.044582821  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:04,096 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.016907981  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:06,174 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.087400474  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:08,352 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.030560853  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:10,589 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.035215318  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:11,057 [INFO] [metadata.py:55] train_wall_time: 22.701670169830322
2023-07-10 16:34:11,057 [INFO] [metadata.py:55] train_loss: 0.043170379012934745
2023-07-10 16:34:11,057 [INFO] [metadata.py:55] train_accuracy: 0.9868316650390625
2023-07-10 16:34:11,057 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:34:11,937 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0290096  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:12,731 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8424789  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:13,105 [INFO] [metadata.py:55] test_wall_time: 2.0470895767211914
2023-07-10 16:34:13,105 [INFO] [metadata.py:55] test_loss: 2.127801447916942
2023-07-10 16:34:13,105 [INFO] [metadata.py:55] test_accuracy: 0.5341361464968153
2023-07-10 16:34:13,109 [INFO] [train.py:190] Epoch: 133
2023-07-10 16:34:13,679 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:34:14,593 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.026209908  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:16,832 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.13131531  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:19,010 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.05096896  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:21,188 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0038556478  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:23,313 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.03349426  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:25,433 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.13080536  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:27,524 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.034495849  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:29,698 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.085000098  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:31,884 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.10871498  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:34,018 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0039171148  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:34:36,169 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.012462852  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:36,641 [INFO] [metadata.py:55] train_wall_time: 22.961599826812744
2023-07-10 16:34:36,641 [INFO] [metadata.py:55] train_loss: 0.04233906331057824
2023-07-10 16:34:36,641 [INFO] [metadata.py:55] train_accuracy: 0.9869384765625
2023-07-10 16:34:36,641 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:34:37,479 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3982854  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:38,329 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1865697  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:38,678 [INFO] [metadata.py:55] test_wall_time: 2.036135196685791
2023-07-10 16:34:38,678 [INFO] [metadata.py:55] test_loss: 2.1988363622859786
2023-07-10 16:34:38,678 [INFO] [metadata.py:55] test_accuracy: 0.5376194267515924
2023-07-10 16:34:38,682 [INFO] [train.py:190] Epoch: 134
2023-07-10 16:34:39,326 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:34:40,297 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0070659579  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:42,540 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.13699469  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:44,806 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.059469841  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:34:47,023 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0048145857  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:34:49,138 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.014852159  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:51,390 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.016293591  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:34:53,559 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.066084571  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:55,761 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.013718282  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:34:57,980 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.11631899  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:00,213 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.10667292  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:02,404 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0087408582  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:02,878 [INFO] [metadata.py:55] train_wall_time: 23.551852464675903
2023-07-10 16:35:02,878 [INFO] [metadata.py:55] train_loss: 0.04423358843118308
2023-07-10 16:35:02,878 [INFO] [metadata.py:55] train_accuracy: 0.9865570068359375
2023-07-10 16:35:02,879 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:35:03,818 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9461167  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:04,665 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1769245  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:05,025 [INFO] [metadata.py:55] test_wall_time: 2.1460466384887695
2023-07-10 16:35:05,026 [INFO] [metadata.py:55] test_loss: 2.045047419845678
2023-07-10 16:35:05,026 [INFO] [metadata.py:55] test_accuracy: 0.5528463375796179
2023-07-10 16:35:05,029 [INFO] [train.py:190] Epoch: 135
2023-07-10 16:35:05,624 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:35:06,542 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.045267481  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:08,682 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0010568388  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:10,881 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00070655637  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:13,014 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0049088974  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:15,129 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.073848367  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:17,276 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.14599812  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.3]% of [20470]MiB
2023-07-10 16:35:19,411 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.036650546  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:35:21,557 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0095510622  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:35:23,688 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.014321194  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:35:25,832 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.016665775  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.4]% of [20470]MiB
2023-07-10 16:35:28,024 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0088891303  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:28,482 [INFO] [metadata.py:55] train_wall_time: 22.857263803482056
2023-07-10 16:35:28,482 [INFO] [metadata.py:55] train_loss: 0.0409369621769855
2023-07-10 16:35:28,482 [INFO] [metadata.py:55] train_accuracy: 0.9874420166015625
2023-07-10 16:35:28,483 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:35:29,351 [INFO] [trainer.py:169]   batch 0/157  loss: 2.058367  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:30,185 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9823152  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:30,548 [INFO] [metadata.py:55] test_wall_time: 2.065213680267334
2023-07-10 16:35:30,549 [INFO] [metadata.py:55] test_loss: 2.128451003390513
2023-07-10 16:35:30,549 [INFO] [metadata.py:55] test_accuracy: 0.5409036624203821
2023-07-10 16:35:30,553 [INFO] [train.py:190] Epoch: 136
2023-07-10 16:35:31,117 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:35:31,999 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0028852758  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:34,256 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.074086189  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:35:36,571 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.024137439  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:38,785 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0094660828  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:35:41,012 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.077295236  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:43,250 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.14500014  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:45,470 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.068437539  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:35:47,755 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.059840642  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:49,945 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0098603787  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:52,114 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0069309874  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:54,303 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0022686711  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:54,762 [INFO] [metadata.py:55] train_wall_time: 23.64497470855713
2023-07-10 16:35:54,762 [INFO] [metadata.py:55] train_loss: 0.039972153692872325
2023-07-10 16:35:54,762 [INFO] [metadata.py:55] train_accuracy: 0.987457275390625
2023-07-10 16:35:54,763 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:35:55,638 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3538439  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:56,416 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3275797  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:35:56,767 [INFO] [metadata.py:55] test_wall_time: 2.003506660461426
2023-07-10 16:35:56,767 [INFO] [metadata.py:55] test_loss: 2.1166533474709577
2023-07-10 16:35:56,767 [INFO] [metadata.py:55] test_accuracy: 0.539609872611465
2023-07-10 16:35:56,771 [INFO] [train.py:190] Epoch: 137
2023-07-10 16:35:57,427 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:35:58,395 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.033931866  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:00,713 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0039353059  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:02,900 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.044863258  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:05,217 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.010010836  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:07,468 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.020197442  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:36:09,671 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.008039332  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:36:11,879 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.039969057  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:36:14,112 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.079944596  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.2]% of [20470]MiB
2023-07-10 16:36:16,386 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.017200956  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:18,600 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.053870846  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:20,808 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.018172598  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:21,281 [INFO] [metadata.py:55] train_wall_time: 23.85381293296814
2023-07-10 16:36:21,281 [INFO] [metadata.py:55] train_loss: 0.042753539333702406
2023-07-10 16:36:21,282 [INFO] [metadata.py:55] train_accuracy: 0.98687744140625
2023-07-10 16:36:21,282 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:36:22,189 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0017216  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:22,985 [INFO] [trainer.py:169]   batch 100/157  loss: 1.8450595  cpu_mem: 22.9%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:23,332 [INFO] [metadata.py:55] test_wall_time: 2.0496134757995605
2023-07-10 16:36:23,332 [INFO] [metadata.py:55] test_loss: 2.166952061804996
2023-07-10 16:36:23,332 [INFO] [metadata.py:55] test_accuracy: 0.5356289808917197
2023-07-10 16:36:23,336 [INFO] [train.py:190] Epoch: 138
2023-07-10 16:36:23,914 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:36:24,848 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0022318894  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:36:27,067 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0015446724  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:36:29,294 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.001425641  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:36:31,328 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.050910413  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:36:33,359 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.021023454  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:35,423 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.053154439  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:37,485 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.052554954  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:36:39,506 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.084784664  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:41,576 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0062749889  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 16:36:43,601 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.10021133  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [9.1]% of [20470]MiB
2023-07-10 16:36:45,692 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00079278229  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:36:46,147 [INFO] [metadata.py:55] train_wall_time: 22.23298192024231
2023-07-10 16:36:46,148 [INFO] [metadata.py:55] train_loss: 0.04224266518362185
2023-07-10 16:36:46,148 [INFO] [metadata.py:55] train_accuracy: 0.9870452880859375
2023-07-10 16:36:46,148 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:36:47,034 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1191716  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:36:47,872 [INFO] [trainer.py:169]   batch 100/157  loss: 2.155771  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:36:48,249 [INFO] [metadata.py:55] test_wall_time: 2.1002628803253174
2023-07-10 16:36:48,249 [INFO] [metadata.py:55] test_loss: 2.078894758680064
2023-07-10 16:36:48,249 [INFO] [metadata.py:55] test_accuracy: 0.5571257961783439
2023-07-10 16:36:48,253 [INFO] [train.py:190] Epoch: 139
2023-07-10 16:36:48,838 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:36:49,756 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.11173626  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:36:51,865 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.073799804  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:36:53,956 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00085245504  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:36:56,107 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0020426943  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:36:58,268 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.095104992  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:00,462 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.032857664  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:02,632 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.14616716  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:04,734 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.013482264  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:06,920 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.11750247  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:09,140 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.08367499  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:11,274 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.008835745  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:11,726 [INFO] [metadata.py:55] train_wall_time: 22.887606859207153
2023-07-10 16:37:11,726 [INFO] [metadata.py:55] train_loss: 0.041949366747076056
2023-07-10 16:37:11,726 [INFO] [metadata.py:55] train_accuracy: 0.987091064453125
2023-07-10 16:37:11,727 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:37:12,602 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1122589  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:13,363 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4824634  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:13,706 [INFO] [metadata.py:55] test_wall_time: 1.9792470932006836
2023-07-10 16:37:13,707 [INFO] [metadata.py:55] test_loss: 2.1538010175061073
2023-07-10 16:37:13,707 [INFO] [metadata.py:55] test_accuracy: 0.5391122611464968
2023-07-10 16:37:13,711 [INFO] [train.py:190] Epoch: 140
2023-07-10 16:37:14,355 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:37:15,270 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00098157325  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:17,451 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0072635962  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:19,692 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0017786876  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:21,901 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.014283756  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:23,988 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.038203809  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:26,129 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.097855344  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:28,269 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.095936336  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:30,456 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.026335333  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:32,626 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.086518034  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:34,854 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.007374852  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:37,092 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0037041877  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:37,567 [INFO] [metadata.py:55] train_wall_time: 23.21165633201599
2023-07-10 16:37:37,567 [INFO] [metadata.py:55] train_loss: 0.044302124895608586
2023-07-10 16:37:37,567 [INFO] [metadata.py:55] train_accuracy: 0.9863128662109375
2023-07-10 16:37:37,568 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:37:38,531 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0079596  cpu_mem: 22.9%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:39,289 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0656366  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:39,637 [INFO] [metadata.py:55] test_wall_time: 2.069154739379883
2023-07-10 16:37:39,638 [INFO] [metadata.py:55] test_loss: 2.0090545271612275
2023-07-10 16:37:39,638 [INFO] [metadata.py:55] test_accuracy: 0.5418988853503185
2023-07-10 16:37:39,642 [INFO] [train.py:190] Epoch: 141
2023-07-10 16:37:40,237 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:37:41,160 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0032233868  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:43,415 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.058977317  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:45,586 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00093245896  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:47,793 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.036755424  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:49,942 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.01358329  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:52,166 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.01408155  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:54,378 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.022470655  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:56,695 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.046836842  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:37:59,008 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.050031662  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:38:01,291 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.004709769  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:03,579 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.010807405  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:04,048 [INFO] [metadata.py:55] train_wall_time: 23.810996294021606
2023-07-10 16:38:04,048 [INFO] [metadata.py:55] train_loss: 0.04335871788653378
2023-07-10 16:38:04,048 [INFO] [metadata.py:55] train_accuracy: 0.9867401123046875
2023-07-10 16:38:04,048 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:38:04,939 [INFO] [trainer.py:169]   batch 0/157  loss: 2.177278  cpu_mem: 22.9%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:05,796 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1197834  cpu_mem: 23.0%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:06,166 [INFO] [metadata.py:55] test_wall_time: 2.117465019226074
2023-07-10 16:38:06,167 [INFO] [metadata.py:55] test_loss: 2.042593611273796
2023-07-10 16:38:06,167 [INFO] [metadata.py:55] test_accuracy: 0.5528463375796179
2023-07-10 16:38:06,171 [INFO] [train.py:190] Epoch: 142
2023-07-10 16:38:06,750 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:38:07,654 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.040129542  lr: 0.005029  cpu_mem: 22.9%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:09,853 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0012535694  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:12,216 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.016912922  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:14,616 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.14042383  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:16,892 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.043612961  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:19,142 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.10216457  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:21,305 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.038674116  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:23,536 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.082122125  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:25,779 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.031365015  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:28,028 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.047369372  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:30,270 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.001531151  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:30,737 [INFO] [metadata.py:55] train_wall_time: 23.986263513565063
2023-07-10 16:38:30,737 [INFO] [metadata.py:55] train_loss: 0.041584864430220136
2023-07-10 16:38:30,737 [INFO] [metadata.py:55] train_accuracy: 0.987213134765625
2023-07-10 16:38:30,738 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:38:31,602 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1094072  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:32,505 [INFO] [trainer.py:169]   batch 100/157  loss: 2.5541654  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:32,873 [INFO] [metadata.py:55] test_wall_time: 2.135070562362671
2023-07-10 16:38:32,874 [INFO] [metadata.py:55] test_loss: 2.124101990347455
2023-07-10 16:38:32,874 [INFO] [metadata.py:55] test_accuracy: 0.5378184713375797
2023-07-10 16:38:32,878 [INFO] [train.py:190] Epoch: 143
2023-07-10 16:38:33,465 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:38:34,409 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0016044131  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:36,659 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.17238247  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:38,845 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0062157712  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:41,007 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0044248011  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:43,139 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.041817799  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:38:45,323 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.01632973  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:47,632 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.02418687  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:38:49,859 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.059144694  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:38:52,017 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.028807396  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:38:54,236 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.005753187  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:38:56,397 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0011971153  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:38:56,897 [INFO] [metadata.py:55] train_wall_time: 23.43150782585144
2023-07-10 16:38:56,897 [INFO] [metadata.py:55] train_loss: 0.04097683522533657
2023-07-10 16:38:56,897 [INFO] [metadata.py:55] train_accuracy: 0.9874420166015625
2023-07-10 16:38:56,898 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:38:57,747 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2519855  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:38:58,583 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9460505  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:38:58,931 [INFO] [metadata.py:55] test_wall_time: 2.0324690341949463
2023-07-10 16:38:58,931 [INFO] [metadata.py:55] test_loss: 2.1875462152396037
2023-07-10 16:38:58,931 [INFO] [metadata.py:55] test_accuracy: 0.5401074840764332
2023-07-10 16:38:58,935 [INFO] [train.py:190] Epoch: 144
2023-07-10 16:38:59,624 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:39:00,590 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0051519508  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:02,911 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0010374425  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:05,145 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.019033015  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:07,364 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.006866931  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:09,548 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.019985579  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:11,720 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.14971192  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:13,908 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.086222976  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:39:16,095 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.23264766  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:18,265 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0089273788  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:20,420 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.02965939  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:22,637 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.014875479  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:23,105 [INFO] [metadata.py:55] train_wall_time: 23.48087167739868
2023-07-10 16:39:23,105 [INFO] [metadata.py:55] train_loss: 0.0401172643143326
2023-07-10 16:39:23,106 [INFO] [metadata.py:55] train_accuracy: 0.98736572265625
2023-07-10 16:39:23,106 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:39:24,019 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1009514  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:24,920 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1145656  cpu_mem: 22.9%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:25,299 [INFO] [metadata.py:55] test_wall_time: 2.192469358444214
2023-07-10 16:39:25,299 [INFO] [metadata.py:55] test_loss: 2.1108150808674515
2023-07-10 16:39:25,299 [INFO] [metadata.py:55] test_accuracy: 0.5395103503184714
2023-07-10 16:39:25,303 [INFO] [train.py:190] Epoch: 145
2023-07-10 16:39:25,899 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:39:26,884 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.014940627  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:29,082 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.14138222  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:31,172 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0065263161  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:33,268 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00086803839  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:39:35,356 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.028775981  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:39:37,426 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0631973  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:39,505 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.090937063  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:41,595 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.019888073  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:43,714 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0071280277  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:45,830 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.01795488  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:48,056 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.025591554  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:48,546 [INFO] [metadata.py:55] train_wall_time: 22.646729230880737
2023-07-10 16:39:48,546 [INFO] [metadata.py:55] train_loss: 0.0400544669514602
2023-07-10 16:39:48,546 [INFO] [metadata.py:55] train_accuracy: 0.9879913330078125
2023-07-10 16:39:48,547 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:39:49,427 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3444571  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:50,309 [INFO] [trainer.py:169]   batch 100/157  loss: 2.6979151  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:50,684 [INFO] [metadata.py:55] test_wall_time: 2.136636734008789
2023-07-10 16:39:50,684 [INFO] [metadata.py:55] test_loss: 2.3095968825042625
2023-07-10 16:39:50,684 [INFO] [metadata.py:55] test_accuracy: 0.5375199044585988
2023-07-10 16:39:50,688 [INFO] [train.py:190] Epoch: 146
2023-07-10 16:39:51,276 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:39:52,248 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0010328048  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:39:54,404 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0013443172  lr: 0.007959  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:39:56,576 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0018033658  lr: 0.01089  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:39:58,728 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.099429488  lr: 0.01382  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:40:00,860 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0041960175  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:40:02,975 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.020738412  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:05,227 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.051947046  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:07,359 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0081326785  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:09,560 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0016590653  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:11,757 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0018256879  lr: 0.008604  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:13,883 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.001009049  lr: 0.005674  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:14,371 [INFO] [metadata.py:55] train_wall_time: 23.095317602157593
2023-07-10 16:40:14,372 [INFO] [metadata.py:55] train_loss: 0.04085927413412094
2023-07-10 16:40:14,372 [INFO] [metadata.py:55] train_accuracy: 0.987701416015625
2023-07-10 16:40:14,372 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:40:15,241 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3072751  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:16,008 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3829827  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:16,382 [INFO] [metadata.py:55] test_wall_time: 2.0089879035949707
2023-07-10 16:40:16,382 [INFO] [metadata.py:55] test_loss: 2.027615897215096
2023-07-10 16:40:16,382 [INFO] [metadata.py:55] test_accuracy: 0.5572253184713376
2023-07-10 16:40:16,386 [INFO] [train.py:190] Epoch: 147
2023-07-10 16:40:17,038 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:40:18,008 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.089404091  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:20,404 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0011167099  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:22,716 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.079771116  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:25,013 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.058555543  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:27,159 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0086010899  lr: 0.01675  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:29,291 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0712943  lr: 0.01968  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:31,490 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.16977906  lr: 0.01739  cpu_mem: 23.0%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:40:33,582 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.04310853  lr: 0.01446  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:35,652 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0011796479  lr: 0.01153  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:37,800 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0019838624  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:39,848 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.036226828  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:40,320 [INFO] [metadata.py:55] train_wall_time: 23.2822265625
2023-07-10 16:40:40,321 [INFO] [metadata.py:55] train_loss: 0.03992086991496535
2023-07-10 16:40:40,321 [INFO] [metadata.py:55] train_accuracy: 0.9876251220703125
2023-07-10 16:40:40,321 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:40:41,167 [INFO] [trainer.py:169]   batch 0/157  loss: 2.4716353  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:41,964 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1239798  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:42,328 [INFO] [metadata.py:55] test_wall_time: 2.006105899810791
2023-07-10 16:40:42,328 [INFO] [metadata.py:55] test_loss: 2.139415544309434
2023-07-10 16:40:42,328 [INFO] [metadata.py:55] test_accuracy: 0.5584195859872612
2023-07-10 16:40:42,332 [INFO] [train.py:190] Epoch: 148
2023-07-10 16:40:42,908 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:40:43,829 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.048569914  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:46,005 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0033296985  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:48,244 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0023821464  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:50,398 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.051206626  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:52,600 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.026830863  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:54,836 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.033471771  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:57,118 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.12291811  lr: 0.01739  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:40:59,391 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.022277547  lr: 0.01446  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:01,516 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.028084751  lr: 0.01153  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:03,550 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.016951542  lr: 0.008604  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:41:05,889 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0047150669  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:41:06,387 [INFO] [metadata.py:55] train_wall_time: 23.479352712631226
2023-07-10 16:41:06,388 [INFO] [metadata.py:55] train_loss: 0.04037179287814752
2023-07-10 16:41:06,388 [INFO] [metadata.py:55] train_accuracy: 0.9873504638671875
2023-07-10 16:41:06,388 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:41:07,234 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7838812  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:41:08,023 [INFO] [trainer.py:169]   batch 100/157  loss: 2.4535699  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:41:08,390 [INFO] [metadata.py:55] test_wall_time: 2.00080943107605
2023-07-10 16:41:08,390 [INFO] [metadata.py:55] test_loss: 2.129998808453797
2023-07-10 16:41:08,390 [INFO] [metadata.py:55] test_accuracy: 0.544187898089172
2023-07-10 16:41:08,394 [INFO] [train.py:190] Epoch: 149
2023-07-10 16:41:08,955 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:41:09,862 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.008843597  lr: 0.005029  cpu_mem: 23.0%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:41:12,026 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0058122762  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:41:14,154 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.061462  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:41:16,356 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0080922665  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:41:18,499 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.15229718  lr: 0.01675  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:20,652 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.028659379  lr: 0.01968  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:41:22,740 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0074392278  lr: 0.01739  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:25,040 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.099497035  lr: 0.01446  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:27,194 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.094799004  lr: 0.01153  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:29,419 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.020507133  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:31,660 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.019108478  lr: 0.005674  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:32,119 [INFO] [metadata.py:55] train_wall_time: 23.16422939300537
2023-07-10 16:41:32,119 [INFO] [metadata.py:55] train_loss: 0.040888507752953274
2023-07-10 16:41:32,120 [INFO] [metadata.py:55] train_accuracy: 0.9875335693359375
2023-07-10 16:41:32,120 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:41:32,978 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9786229  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:33,807 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0788181  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:34,183 [INFO] [metadata.py:55] test_wall_time: 2.062260150909424
2023-07-10 16:41:34,183 [INFO] [metadata.py:55] test_loss: 2.1581175699355497
2023-07-10 16:41:34,183 [INFO] [metadata.py:55] test_accuracy: 0.5474721337579618
2023-07-10 16:41:34,187 [INFO] [train.py:190] Epoch: 150
2023-07-10 16:41:34,841 [INFO] [metadata.py:55] learning_rate: 0.01
2023-07-10 16:41:35,770 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0016313833  lr: 0.005029  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:41:38,019 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00030628568  lr: 0.007959  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:40,197 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.020375241  lr: 0.01089  cpu_mem: 23.1%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 16:41:42,425 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.011487133  lr: 0.01382  cpu_mem: 23.1%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:44,668 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.12882903  lr: 0.01675  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 16:41:46,985 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0081527894  lr: 0.01968  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:41:49,174 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.028819947  lr: 0.01739  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:41:51,300 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.059256621  lr: 0.01446  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:41:53,466 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.006921059  lr: 0.01153  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:41:55,593 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.016560961  lr: 0.008604  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:41:57,647 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0057299184  lr: 0.005674  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:41:58,097 [INFO] [metadata.py:55] train_wall_time: 23.255717277526855
2023-07-10 16:41:58,097 [INFO] [metadata.py:55] train_loss: 0.04143982152289993
2023-07-10 16:41:58,097 [INFO] [metadata.py:55] train_accuracy: 0.98748779296875
2023-07-10 16:41:58,098 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:41:59,037 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0291612  cpu_mem: 23.1%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:41:59,813 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0299349  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:00,182 [INFO] [metadata.py:55] test_wall_time: 2.083656072616577
2023-07-10 16:42:00,182 [INFO] [metadata.py:55] test_loss: 2.027250595153517
2023-07-10 16:42:00,182 [INFO] [metadata.py:55] test_accuracy: 0.556031050955414
2023-07-10 16:42:00,183 [INFO] [train.py:173] Learning rate reduced
2023-07-10 16:42:00,186 [INFO] [train.py:190] Epoch: 151
2023-07-10 16:42:00,774 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:42:01,663 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.030415006  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:42:03,855 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00016606864  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:42:06,012 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00057664455  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:42:08,142 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00047441173  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:42:10,250 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0014982213  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:12,374 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.011726889  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:42:14,604 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.024309244  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:42:16,848 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.020613043  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:42:19,066 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0003177943  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:21,287 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.035800491  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:23,533 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00011762261  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:24,025 [INFO] [metadata.py:55] train_wall_time: 23.25052571296692
2023-07-10 16:42:24,025 [INFO] [metadata.py:55] train_loss: 0.012974708464660978
2023-07-10 16:42:24,025 [INFO] [metadata.py:55] train_accuracy: 0.99615478515625
2023-07-10 16:42:24,025 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:42:24,945 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3437033  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:25,844 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2304924  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:42:26,238 [INFO] [metadata.py:55] test_wall_time: 2.212130546569824
2023-07-10 16:42:26,238 [INFO] [metadata.py:55] test_loss: 1.983985504527001
2023-07-10 16:42:26,238 [INFO] [metadata.py:55] test_accuracy: 0.5624004777070064
2023-07-10 16:42:26,243 [INFO] [train.py:216] Updating best model with epoch: 151
2023-07-10 16:42:26,255 [INFO] [train.py:190] Epoch: 152
2023-07-10 16:42:26,885 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:42:27,779 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00017295803  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:42:30,034 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00035117895  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:42:32,343 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00019994327  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:42:34,583 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00037326035  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:42:36,824 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.021164645  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:39,097 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00088927854  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:41,440 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00029608014  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:43,604 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.038318999  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:45,899 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.015754832  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:48,180 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.060459554  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:50,572 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0016931935  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:51,069 [INFO] [metadata.py:55] train_wall_time: 24.183786869049072
2023-07-10 16:42:51,069 [INFO] [metadata.py:55] train_loss: 0.008616287190690741
2023-07-10 16:42:51,069 [INFO] [metadata.py:55] train_accuracy: 0.997406005859375
2023-07-10 16:42:51,069 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:42:51,946 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8488485  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:52,780 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9506627  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:53,180 [INFO] [metadata.py:55] test_wall_time: 2.1105265617370605
2023-07-10 16:42:53,181 [INFO] [metadata.py:55] test_loss: 1.9780052224541926
2023-07-10 16:42:53,181 [INFO] [metadata.py:55] test_accuracy: 0.567078025477707
2023-07-10 16:42:53,185 [INFO] [train.py:216] Updating best model with epoch: 152
2023-07-10 16:42:53,198 [INFO] [train.py:190] Epoch: 153
2023-07-10 16:42:53,817 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:42:54,784 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00022993051  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:57,083 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00023729319  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:42:59,329 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00035831649  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:01,654 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0060430714  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:03,972 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0043871752  lr: 0.00335  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:06,290 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.025711948  lr: 0.003936  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:08,664 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00018297679  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:10,975 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0015613124  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:13,237 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0020556408  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:15,476 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00011171376  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:17,705 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00052767585  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:18,211 [INFO] [metadata.py:55] train_wall_time: 24.394415616989136
2023-07-10 16:43:18,212 [INFO] [metadata.py:55] train_loss: 0.007863666732262686
2023-07-10 16:43:18,212 [INFO] [metadata.py:55] train_accuracy: 0.997589111328125
2023-07-10 16:43:18,212 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:43:19,113 [INFO] [trainer.py:169]   batch 0/157  loss:  2.26279  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:19,895 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1981356  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:20,288 [INFO] [metadata.py:55] test_wall_time: 2.0756006240844727
2023-07-10 16:43:20,289 [INFO] [metadata.py:55] test_loss: 2.0467583472561683
2023-07-10 16:43:20,289 [INFO] [metadata.py:55] test_accuracy: 0.5625
2023-07-10 16:43:20,293 [INFO] [train.py:190] Epoch: 154
2023-07-10 16:43:20,916 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:43:21,900 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00079177273  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:43:24,112 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00031395844  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:26,296 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00023681756  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:28,528 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0022232302  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:30,781 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00037181258  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:33,069 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.046411019  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:43:35,217 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0053110374  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:37,372 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.078513213  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:39,506 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00021380725  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:41,692 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0004083458  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:43,904 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0014704192  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:44,366 [INFO] [metadata.py:55] train_wall_time: 23.44945764541626
2023-07-10 16:43:44,366 [INFO] [metadata.py:55] train_loss: 0.0071216106016152025
2023-07-10 16:43:44,366 [INFO] [metadata.py:55] train_accuracy: 0.9980316162109375
2023-07-10 16:43:44,366 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:43:45,236 [INFO] [trainer.py:169]   batch 0/157  loss: 2.083118  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:46,056 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2393177  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:46,419 [INFO] [metadata.py:55] test_wall_time: 2.052356481552124
2023-07-10 16:43:46,419 [INFO] [metadata.py:55] test_loss: 2.0396724590070687
2023-07-10 16:43:46,420 [INFO] [metadata.py:55] test_accuracy: 0.5723527070063694
2023-07-10 16:43:46,424 [INFO] [train.py:216] Updating best model with epoch: 154
2023-07-10 16:43:46,436 [INFO] [train.py:190] Epoch: 155
2023-07-10 16:43:47,044 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:43:47,988 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00019266136  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:50,227 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00015982606  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:52,468 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0042641745  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:54,634 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00032705022  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:56,818 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0069255908  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:43:58,975 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00071059435  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:01,128 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0043054135  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:03,276 [INFO] [trainer.py:122]   batch 700/1024  loss: 9.7486809e-05  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:05,441 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.024303442  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:07,766 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00078352948  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:09,972 [INFO] [trainer.py:122]   batch 1000/1024  loss: 8.8277091e-05  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:10,495 [INFO] [metadata.py:55] train_wall_time: 23.450525045394897
2023-07-10 16:44:10,496 [INFO] [metadata.py:55] train_loss: 0.00644081689311804
2023-07-10 16:44:10,496 [INFO] [metadata.py:55] train_accuracy: 0.9981536865234375
2023-07-10 16:44:10,496 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:44:11,365 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1834793  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:12,208 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3160496  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:12,597 [INFO] [metadata.py:55] test_wall_time: 2.100095272064209
2023-07-10 16:44:12,597 [INFO] [metadata.py:55] test_loss: 2.0886226938029004
2023-07-10 16:44:12,597 [INFO] [metadata.py:55] test_accuracy: 0.5678742038216561
2023-07-10 16:44:12,601 [INFO] [train.py:190] Epoch: 156
2023-07-10 16:44:13,272 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:44:14,225 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0010206955  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:16,539 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00026575712  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:18,872 [INFO] [trainer.py:122]   batch 200/1024  loss: 8.1985425e-05  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:21,129 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.007854362  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:23,277 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0018042881  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:44:25,503 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00051172037  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:27,565 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00016355093  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:29,662 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0022248663  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:31,744 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00014552579  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:33,830 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.021001503  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:35,985 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0017129531  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:36,485 [INFO] [metadata.py:55] train_wall_time: 23.212755918502808
2023-07-10 16:44:36,485 [INFO] [metadata.py:55] train_loss: 0.007296490863410554
2023-07-10 16:44:36,485 [INFO] [metadata.py:55] train_accuracy: 0.997833251953125
2023-07-10 16:44:36,486 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:44:37,335 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1211333  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:38,153 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2098265  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:38,516 [INFO] [metadata.py:55] test_wall_time: 2.0295698642730713
2023-07-10 16:44:38,516 [INFO] [metadata.py:55] test_loss: 2.0237370615552184
2023-07-10 16:44:38,516 [INFO] [metadata.py:55] test_accuracy: 0.568172770700637
2023-07-10 16:44:38,520 [INFO] [train.py:190] Epoch: 157
2023-07-10 16:44:39,124 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:44:40,101 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.000577892  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:42,391 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0010056421  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:44,668 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00027337944  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:46,875 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0061463797  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:49,076 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00019982978  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:51,291 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.01244723  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:53,363 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.009341117  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:55,436 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00087885128  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:57,492 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00029877774  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:44:59,544 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0080519812  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:01,616 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00032023972  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:02,074 [INFO] [metadata.py:55] train_wall_time: 22.949557065963745
2023-07-10 16:45:02,074 [INFO] [metadata.py:55] train_loss: 0.005474189514814043
2023-07-10 16:45:02,074 [INFO] [metadata.py:55] train_accuracy: 0.9983978271484375
2023-07-10 16:45:02,074 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:45:02,990 [INFO] [trainer.py:169]   batch 0/157  loss: 2.2526183  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:03,825 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3531067  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:04,182 [INFO] [metadata.py:55] test_wall_time: 2.1072521209716797
2023-07-10 16:45:04,183 [INFO] [metadata.py:55] test_loss: 2.0408458345255274
2023-07-10 16:45:04,183 [INFO] [metadata.py:55] test_accuracy: 0.5595143312101911
2023-07-10 16:45:04,187 [INFO] [train.py:190] Epoch: 158
2023-07-10 16:45:04,804 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:45:05,720 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00026385474  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:07,823 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0002921781  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:09,890 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00014433195  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:11,905 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00054424547  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:13,923 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00047247275  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:15,972 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0022807948  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:18,080 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00025571586  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:20,258 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.003990232  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:22,429 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0082521737  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:24,610 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00013877888  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:26,717 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00029231238  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:27,202 [INFO] [metadata.py:55] train_wall_time: 22.3980975151062
2023-07-10 16:45:27,202 [INFO] [metadata.py:55] train_loss: 0.00547835606508329
2023-07-10 16:45:27,202 [INFO] [metadata.py:55] train_accuracy: 0.9984893798828125
2023-07-10 16:45:27,203 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:45:28,101 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0633428  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:28,973 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1202376  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:29,325 [INFO] [metadata.py:55] test_wall_time: 2.122091293334961
2023-07-10 16:45:29,326 [INFO] [metadata.py:55] test_loss: 2.076670990628042
2023-07-10 16:45:29,326 [INFO] [metadata.py:55] test_accuracy: 0.5616042993630573
2023-07-10 16:45:29,330 [INFO] [train.py:190] Epoch: 159
2023-07-10 16:45:29,928 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:45:30,879 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00011050813  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:33,029 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.007259937  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:35,212 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00020613959  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:37,507 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0015070656  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:39,796 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.010122375  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:41,832 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0023363417  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:43,906 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00034504861  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:46,126 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0011816294  lr: 0.002893  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:48,275 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00014556167  lr: 0.002307  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:50,415 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00078284292  lr: 0.001721  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:52,524 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.065741293  lr: 0.001135  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:52,977 [INFO] [metadata.py:55] train_wall_time: 23.04905605316162
2023-07-10 16:45:52,978 [INFO] [metadata.py:55] train_loss: 0.006142254631058108
2023-07-10 16:45:52,978 [INFO] [metadata.py:55] train_accuracy: 0.9982147216796875
2023-07-10 16:45:52,978 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:45:53,885 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9645792  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:54,702 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9301351  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:55,063 [INFO] [metadata.py:55] test_wall_time: 2.084599494934082
2023-07-10 16:45:55,064 [INFO] [metadata.py:55] test_loss: 2.1035948262852466
2023-07-10 16:45:55,064 [INFO] [metadata.py:55] test_accuracy: 0.556827229299363
2023-07-10 16:45:55,068 [INFO] [train.py:190] Epoch: 160
2023-07-10 16:45:55,691 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:45:56,620 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.001089631  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:45:58,757 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00017319128  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:00,931 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00017506516  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:03,096 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00052293588  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:05,357 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00015957007  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:07,604 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.000601482  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:09,792 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00012376743  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:12,003 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0009583495  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:14,164 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00038978871  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:16,314 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00090410485  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:18,432 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.01621823  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:18,931 [INFO] [metadata.py:55] train_wall_time: 23.239689588546753
2023-07-10 16:46:18,931 [INFO] [metadata.py:55] train_loss: 0.005159358440501194
2023-07-10 16:46:18,931 [INFO] [metadata.py:55] train_accuracy: 0.9985809326171875
2023-07-10 16:46:18,931 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:46:19,891 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0993693  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:20,697 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0065873  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:21,066 [INFO] [metadata.py:55] test_wall_time: 2.1342077255249023
2023-07-10 16:46:21,066 [INFO] [metadata.py:55] test_loss: 2.0436193646898695
2023-07-10 16:46:21,066 [INFO] [metadata.py:55] test_accuracy: 0.5617038216560509
2023-07-10 16:46:21,071 [INFO] [train.py:190] Epoch: 161
2023-07-10 16:46:21,683 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:46:22,616 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00013680969  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:24,821 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0002997632  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:27,015 [INFO] [trainer.py:122]   batch 200/1024  loss: 8.6410735e-05  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:29,166 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0015729921  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:31,305 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0004404567  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:33,368 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00016009546  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:46:35,537 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00057743373  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:37,578 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00045828629  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:39,620 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.013666515  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:41,680 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00010489333  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:43,747 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00021911437  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:44,194 [INFO] [metadata.py:55] train_wall_time: 22.51120948791504
2023-07-10 16:46:44,194 [INFO] [metadata.py:55] train_loss: 0.005531895102041773
2023-07-10 16:46:44,195 [INFO] [metadata.py:55] train_accuracy: 0.9984283447265625
2023-07-10 16:46:44,195 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:46:45,060 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0374372  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:45,855 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1861062  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:46:46,201 [INFO] [metadata.py:55] test_wall_time: 2.0059573650360107
2023-07-10 16:46:46,202 [INFO] [metadata.py:55] test_loss: 2.106842236154398
2023-07-10 16:46:46,202 [INFO] [metadata.py:55] test_accuracy: 0.5589171974522293
2023-07-10 16:46:46,206 [INFO] [train.py:190] Epoch: 162
2023-07-10 16:46:46,877 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:46:47,782 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0030850712  lr: 0.001006  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:46:50,002 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00044461808  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:46:52,257 [INFO] [trainer.py:122]   batch 200/1024  loss: 8.3105806e-05  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:46:54,568 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00020058168  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:46:56,792 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00016590394  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:46:58,946 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00021023299  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:47:01,123 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00048124816  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:03,229 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00011391453  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:47:05,389 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00015176449  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:07,616 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.002337445  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:09,796 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0034151729  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:10,332 [INFO] [metadata.py:55] train_wall_time: 23.454879760742188
2023-07-10 16:47:10,332 [INFO] [metadata.py:55] train_loss: 0.0051548096998814685
2023-07-10 16:47:10,332 [INFO] [metadata.py:55] train_accuracy: 0.998504638671875
2023-07-10 16:47:10,333 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:47:11,199 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9944437  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:12,072 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0825706  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:12,422 [INFO] [metadata.py:55] test_wall_time: 2.0889732837677
2023-07-10 16:47:12,422 [INFO] [metadata.py:55] test_loss: 1.988624657794928
2023-07-10 16:47:12,422 [INFO] [metadata.py:55] test_accuracy: 0.570859872611465
2023-07-10 16:47:12,427 [INFO] [train.py:190] Epoch: 163
2023-07-10 16:47:13,047 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:47:14,014 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00024091646  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:47:16,208 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00017179678  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:18,325 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00047489631  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:20,499 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0068797092  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:22,646 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.014146218  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:24,798 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.001100412  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:26,980 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00013392825  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:29,139 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00011867558  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:31,269 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.002303706  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:33,353 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00011497123  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:35,516 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.034513317  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:35,977 [INFO] [metadata.py:55] train_wall_time: 22.929725408554077
2023-07-10 16:47:35,977 [INFO] [metadata.py:55] train_loss: 0.004754709307697169
2023-07-10 16:47:35,977 [INFO] [metadata.py:55] train_accuracy: 0.9986724853515625
2023-07-10 16:47:35,978 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:47:36,936 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9840566  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:37,759 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9484224  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:38,125 [INFO] [metadata.py:55] test_wall_time: 2.1470251083374023
2023-07-10 16:47:38,125 [INFO] [metadata.py:55] test_loss: 2.067335982990872
2023-07-10 16:47:38,125 [INFO] [metadata.py:55] test_accuracy: 0.5717555732484076
2023-07-10 16:47:38,130 [INFO] [train.py:190] Epoch: 164
2023-07-10 16:47:38,747 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:47:39,633 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00045488827  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:41,780 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00021199991  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:43,815 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00012938131  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:45,939 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00011108076  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:48,079 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0004820273  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:50,266 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00028602956  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:52,486 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.02416453  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:54,696 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00024848391  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:47:56,901 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0013528125  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:47:59,011 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00037049304  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:48:01,130 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00014094397  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:48:01,603 [INFO] [metadata.py:55] train_wall_time: 22.855990886688232
2023-07-10 16:48:01,604 [INFO] [metadata.py:55] train_loss: 0.004702874404276969
2023-07-10 16:48:01,604 [INFO] [metadata.py:55] train_accuracy: 0.9985809326171875
2023-07-10 16:48:01,604 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:48:02,521 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9046396  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:48:03,320 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1120756  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:03,687 [INFO] [metadata.py:55] test_wall_time: 2.082509994506836
2023-07-10 16:48:03,687 [INFO] [metadata.py:55] test_loss: 2.0639538377713245
2023-07-10 16:48:03,687 [INFO] [metadata.py:55] test_accuracy: 0.5644904458598726
2023-07-10 16:48:03,691 [INFO] [train.py:190] Epoch: 165
2023-07-10 16:48:04,349 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:48:05,265 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.016161736  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:07,469 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00035432621  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:09,683 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0033515131  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:11,891 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0004124218  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:14,096 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00083775481  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:16,312 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00046463698  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:18,524 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0002403774  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:20,728 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00027748317  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:48:22,952 [INFO] [trainer.py:122]   batch 800/1024  loss: 8.0431448e-05  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:48:25,201 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00053514459  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:27,451 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00014432179  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:27,910 [INFO] [metadata.py:55] train_wall_time: 23.56170415878296
2023-07-10 16:48:27,911 [INFO] [metadata.py:55] train_loss: 0.004804620013580063
2023-07-10 16:48:27,911 [INFO] [metadata.py:55] train_accuracy: 0.998748779296875
2023-07-10 16:48:27,911 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:48:28,815 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8422178  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:29,640 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0326171  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:30,007 [INFO] [metadata.py:55] test_wall_time: 2.095273733139038
2023-07-10 16:48:30,007 [INFO] [metadata.py:55] test_loss: 2.0493454409253067
2023-07-10 16:48:30,007 [INFO] [metadata.py:55] test_accuracy: 0.5663813694267515
2023-07-10 16:48:30,012 [INFO] [train.py:190] Epoch: 166
2023-07-10 16:48:30,633 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:48:31,559 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0015920409  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:33,714 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00014399215  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:48:35,808 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.014001159  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:37,852 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00012354304  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:39,947 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00016059497  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:41,998 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.002808104  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:44,029 [INFO] [trainer.py:122]   batch 600/1024  loss: 7.941293e-05  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:48:46,092 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0024528916  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:48,242 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00027312164  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:50,396 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00020392869  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:52,553 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.013655105  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:53,010 [INFO] [metadata.py:55] train_wall_time: 22.376768589019775
2023-07-10 16:48:53,010 [INFO] [metadata.py:55] train_loss: 0.005011310611450881
2023-07-10 16:48:53,010 [INFO] [metadata.py:55] train_accuracy: 0.998565673828125
2023-07-10 16:48:53,010 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:48:53,905 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9698284  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:54,746 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1521623  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:48:55,115 [INFO] [metadata.py:55] test_wall_time: 2.1039443016052246
2023-07-10 16:48:55,115 [INFO] [metadata.py:55] test_loss: 2.140711445717295
2023-07-10 16:48:55,115 [INFO] [metadata.py:55] test_accuracy: 0.5581210191082803
2023-07-10 16:48:55,120 [INFO] [train.py:190] Epoch: 167
2023-07-10 16:48:55,772 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:48:56,874 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00011114566  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:48:59,016 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00043146696  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:49:01,179 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00013235661  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:03,356 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0010365994  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:05,480 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0008808471  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:07,661 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00018236935  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:09,864 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00013481545  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:12,048 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0015273632  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:14,288 [INFO] [trainer.py:122]   batch 800/1024  loss: 7.0931492e-05  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:16,540 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00072268583  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:49:18,733 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00012750133  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:19,206 [INFO] [metadata.py:55] train_wall_time: 23.434011220932007
2023-07-10 16:49:19,206 [INFO] [metadata.py:55] train_loss: 0.00502607545629985
2023-07-10 16:49:19,207 [INFO] [metadata.py:55] train_accuracy: 0.9985198974609375
2023-07-10 16:49:19,207 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:49:20,213 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0129118  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:49:21,084 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1487157  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:49:21,455 [INFO] [metadata.py:55] test_wall_time: 2.247727632522583
2023-07-10 16:49:21,455 [INFO] [metadata.py:55] test_loss: 2.0443731121196866
2023-07-10 16:49:21,458 [INFO] [metadata.py:55] test_accuracy: 0.5723527070063694
2023-07-10 16:49:21,468 [INFO] [train.py:216] Updating best model with epoch: 167
2023-07-10 16:49:21,481 [INFO] [train.py:190] Epoch: 168
2023-07-10 16:49:22,099 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:49:23,064 [INFO] [trainer.py:122]   batch 0/1024  loss: 8.5482541e-05  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:25,484 [INFO] [trainer.py:122]   batch 100/1024  loss: 8.6614957e-05  lr: 0.001592  cpu_mem: 24.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:27,694 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.012440936  lr: 0.002178  cpu_mem: 24.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:49:29,924 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.095934339  lr: 0.002764  cpu_mem: 24.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:49:32,198 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.013580173  lr: 0.00335  cpu_mem: 24.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:49:34,484 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00011880534  lr: 0.003936  cpu_mem: 24.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:36,775 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00015224586  lr: 0.003479  cpu_mem: 24.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:49:38,949 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0002701355  lr: 0.002893  cpu_mem: 24.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:41,165 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.012221858  lr: 0.002307  cpu_mem: 24.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:43,384 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00011973232  lr: 0.001721  cpu_mem: 24.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:45,649 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00022891091  lr: 0.001135  cpu_mem: 24.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:46,118 [INFO] [metadata.py:55] train_wall_time: 24.01911497116089
2023-07-10 16:49:46,118 [INFO] [metadata.py:55] train_loss: 0.005432403872603686
2023-07-10 16:49:46,119 [INFO] [metadata.py:55] train_accuracy: 0.9983978271484375
2023-07-10 16:49:46,119 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:49:46,993 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0891969  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:47,821 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0299618  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:49:48,201 [INFO] [metadata.py:55] test_wall_time: 2.0814766883850098
2023-07-10 16:49:48,201 [INFO] [metadata.py:55] test_loss: 2.0452978428761672
2023-07-10 16:49:48,201 [INFO] [metadata.py:55] test_accuracy: 0.5642914012738853
2023-07-10 16:49:48,205 [INFO] [train.py:190] Epoch: 169
2023-07-10 16:49:48,794 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:49:49,694 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00015775108  lr: 0.001006  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:52,000 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.098594666  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:54,248 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0036307152  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:56,380 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00028165599  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:49:58,529 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00062588422  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:50:00,646 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00036973043  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:02,789 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.083793826  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:04,879 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00048076149  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:06,968 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00012436449  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:09,127 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.031292982  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:11,214 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00095085299  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:11,665 [INFO] [metadata.py:55] train_wall_time: 22.87100124359131
2023-07-10 16:50:11,666 [INFO] [metadata.py:55] train_loss: 0.005111844066249205
2023-07-10 16:50:11,666 [INFO] [metadata.py:55] train_accuracy: 0.9985809326171875
2023-07-10 16:50:11,666 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:50:12,589 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0341771  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:13,443 [INFO] [trainer.py:169]   batch 100/157  loss: 2.0950596  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:13,827 [INFO] [metadata.py:55] test_wall_time: 2.160921335220337
2023-07-10 16:50:13,828 [INFO] [metadata.py:55] test_loss: 2.1021926410638603
2023-07-10 16:50:13,828 [INFO] [metadata.py:55] test_accuracy: 0.5572253184713376
2023-07-10 16:50:13,832 [INFO] [train.py:190] Epoch: 170
2023-07-10 16:50:14,429 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:50:15,364 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00015311808  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:17,489 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00010659174  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:19,585 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00016053968  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:21,689 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0010083956  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:23,776 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.000318618  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:25,897 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0022985882  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:27,975 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00020698855  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:30,056 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00074659107  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:32,216 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00014676551  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:34,372 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00016681888  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:36,520 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00013176365  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:50:36,979 [INFO] [metadata.py:55] train_wall_time: 22.54931902885437
2023-07-10 16:50:36,979 [INFO] [metadata.py:55] train_loss: 0.004365913566257262
2023-07-10 16:50:36,979 [INFO] [metadata.py:55] train_accuracy: 0.9987945556640625
2023-07-10 16:50:36,980 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:50:37,833 [INFO] [trainer.py:169]   batch 0/157  loss: 2.3128369  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:50:38,707 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2048004  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:50:39,076 [INFO] [metadata.py:55] test_wall_time: 2.0959582328796387
2023-07-10 16:50:39,076 [INFO] [metadata.py:55] test_loss: 2.1027627826496293
2023-07-10 16:50:39,077 [INFO] [metadata.py:55] test_accuracy: 0.5594148089171974
2023-07-10 16:50:39,081 [INFO] [train.py:190] Epoch: 171
2023-07-10 16:50:39,680 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:50:40,653 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00028198733  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:50:42,917 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0001408399  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:45,109 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0006652578  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:47,332 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0039088465  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:49,468 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00016840726  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:50:51,619 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00017583814  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:53,763 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00036621143  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:55,923 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00019308836  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:50:58,055 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00013968484  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:00,233 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.070412934  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:02,410 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00031524332  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:02,874 [INFO] [metadata.py:55] train_wall_time: 23.193978309631348
2023-07-10 16:51:02,874 [INFO] [metadata.py:55] train_loss: 0.00432255576745888
2023-07-10 16:51:02,874 [INFO] [metadata.py:55] train_accuracy: 0.9988555908203125
2023-07-10 16:51:02,875 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:51:03,754 [INFO] [trainer.py:169]   batch 0/157  loss: 2.1941936  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:04,581 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1165915  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:04,936 [INFO] [metadata.py:55] test_wall_time: 2.060480833053589
2023-07-10 16:51:04,936 [INFO] [metadata.py:55] test_loss: 2.1244150149594447
2023-07-10 16:51:04,936 [INFO] [metadata.py:55] test_accuracy: 0.5563296178343949
2023-07-10 16:51:04,940 [INFO] [train.py:190] Epoch: 172
2023-07-10 16:51:05,636 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:51:06,576 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00018372507  lr: 0.001006  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:08,752 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00034589961  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:51:10,962 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00022796736  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:13,127 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00011915178  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:51:15,244 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0010159501  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:51:17,356 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00067895494  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:51:19,407 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00016138193  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:21,520 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00010200961  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:23,726 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00083593291  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:25,974 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00018723823  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:28,224 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00045639093  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:28,691 [INFO] [metadata.py:55] train_wall_time: 23.0545015335083
2023-07-10 16:51:28,691 [INFO] [metadata.py:55] train_loss: 0.004878388335882278
2023-07-10 16:51:28,691 [INFO] [metadata.py:55] train_accuracy: 0.99859619140625
2023-07-10 16:51:28,692 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:51:29,643 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0743144  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:30,526 [INFO] [trainer.py:169]   batch 100/157  loss: 1.9592326  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:30,890 [INFO] [metadata.py:55] test_wall_time: 2.197383165359497
2023-07-10 16:51:30,890 [INFO] [metadata.py:55] test_loss: 2.0788038255302768
2023-07-10 16:51:30,890 [INFO] [metadata.py:55] test_accuracy: 0.568172770700637
2023-07-10 16:51:30,894 [INFO] [train.py:190] Epoch: 173
2023-07-10 16:51:31,521 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:51:32,444 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00017555791  lr: 0.001006  cpu_mem: 23.1%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:34,643 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00068724202  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:51:36,712 [INFO] [trainer.py:122]   batch 200/1024  loss: 9.3509203e-05  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:51:38,782 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00035925378  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:51:40,844 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.013648658  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:42,953 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0043015219  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:45,005 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0001897289  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:51:47,114 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0017703577  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:51:49,216 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00019483414  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:51:51,294 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00073217129  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:51:53,384 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00030928393  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:51:53,845 [INFO] [metadata.py:55] train_wall_time: 22.323118686676025
2023-07-10 16:51:53,845 [INFO] [metadata.py:55] train_loss: 0.005311541107822393
2023-07-10 16:51:53,845 [INFO] [metadata.py:55] train_accuracy: 0.9984893798828125
2023-07-10 16:51:53,845 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:51:54,746 [INFO] [trainer.py:169]   batch 0/157  loss: 2.0715685  cpu_mem: 23.1%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:51:55,655 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3904986  cpu_mem: 23.1%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:51:56,004 [INFO] [metadata.py:55] test_wall_time: 2.1580913066864014
2023-07-10 16:51:56,004 [INFO] [metadata.py:55] test_loss: 2.1624353091428232
2023-07-10 16:51:56,005 [INFO] [metadata.py:55] test_accuracy: 0.5529458598726115
2023-07-10 16:51:56,011 [INFO] [train.py:190] Epoch: 174
2023-07-10 16:51:56,635 [INFO] [metadata.py:55] learning_rate: 0.002
2023-07-10 16:51:57,560 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00038226161  lr: 0.001006  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:51:59,763 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0002362861  lr: 0.001592  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:52:02,019 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00024065495  lr: 0.002178  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:04,195 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00067891856  lr: 0.002764  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:52:06,387 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0010396545  lr: 0.00335  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:52:08,624 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00014140886  lr: 0.003936  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:52:10,884 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00029451505  lr: 0.003479  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:13,068 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.002718417  lr: 0.002893  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:15,352 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00018520345  lr: 0.002307  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:17,588 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00029238863  lr: 0.001721  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:19,748 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0001180102  lr: 0.001135  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:20,233 [INFO] [metadata.py:55] train_wall_time: 23.59753131866455
2023-07-10 16:52:20,233 [INFO] [metadata.py:55] train_loss: 0.004820331709822767
2023-07-10 16:52:20,234 [INFO] [metadata.py:55] train_accuracy: 0.99859619140625
2023-07-10 16:52:20,234 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:52:21,125 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9977293  cpu_mem: 23.1%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:21,967 [INFO] [trainer.py:169]   batch 100/157  loss: 2.154043  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:22,328 [INFO] [metadata.py:55] test_wall_time: 2.093066930770874
2023-07-10 16:52:22,328 [INFO] [metadata.py:55] test_loss: 2.0152749362265228
2023-07-10 16:52:22,328 [INFO] [metadata.py:55] test_accuracy: 0.5717555732484076
2023-07-10 16:52:22,328 [INFO] [train.py:173] Learning rate reduced
2023-07-10 16:52:22,332 [INFO] [train.py:190] Epoch: 175
2023-07-10 16:52:23,010 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:52:23,985 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00040570006  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:26,213 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00036029975  lr: 0.0003184  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:28,373 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.027499635  lr: 0.0004355  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:30,542 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0050834594  lr: 0.0005527  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:32,715 [INFO] [trainer.py:122]   batch 400/1024  loss: 9.0491107e-05  lr: 0.0006699  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:34,979 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.012406221  lr: 0.0007871  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:37,089 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00010636577  lr: 0.0006957  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:39,119 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00012462845  lr: 0.0005785  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:41,220 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00025281089  lr: 0.0004613  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:52:43,307 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00017321164  lr: 0.0003441  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:45,410 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0091267247  lr: 0.000227  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:45,865 [INFO] [metadata.py:55] train_wall_time: 22.854625701904297
2023-07-10 16:52:45,865 [INFO] [metadata.py:55] train_loss: 0.0031934577554473265
2023-07-10 16:52:45,865 [INFO] [metadata.py:55] train_accuracy: 0.999053955078125
2023-07-10 16:52:45,866 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:52:46,763 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9118958  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:47,628 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1564636  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:48,009 [INFO] [metadata.py:55] test_wall_time: 2.142413854598999
2023-07-10 16:52:48,009 [INFO] [metadata.py:55] test_loss: 2.040998917476387
2023-07-10 16:52:48,009 [INFO] [metadata.py:55] test_accuracy: 0.5676751592356688
2023-07-10 16:52:48,013 [INFO] [train.py:190] Epoch: 176
2023-07-10 16:52:48,624 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:52:49,545 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0042080241  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:51,801 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00056182453  lr: 0.0003184  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:52:53,980 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00017576871  lr: 0.0004355  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:52:56,108 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00010514363  lr: 0.0005527  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:52:58,292 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0036929096  lr: 0.0006699  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:00,372 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00013086744  lr: 0.0007871  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:02,510 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00025379291  lr: 0.0006957  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:04,614 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00020296234  lr: 0.0005785  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:53:06,774 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.001470524  lr: 0.0004613  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:53:08,924 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00031458345  lr: 0.0003441  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:11,104 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0001831733  lr: 0.000227  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:11,574 [INFO] [metadata.py:55] train_wall_time: 22.950237274169922
2023-07-10 16:53:11,574 [INFO] [metadata.py:55] train_loss: 0.003197179096723346
2023-07-10 16:53:11,575 [INFO] [metadata.py:55] train_accuracy: 0.9991455078125
2023-07-10 16:53:11,575 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:53:12,492 [INFO] [trainer.py:169]   batch 0/157  loss: 1.920451  cpu_mem: 23.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:13,340 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2046697  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:13,709 [INFO] [metadata.py:55] test_wall_time: 2.133340835571289
2023-07-10 16:53:13,709 [INFO] [metadata.py:55] test_loss: 2.0693230461922423
2023-07-10 16:53:13,709 [INFO] [metadata.py:55] test_accuracy: 0.5608081210191083
2023-07-10 16:53:13,714 [INFO] [train.py:190] Epoch: 177
2023-07-10 16:53:14,316 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:53:15,216 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00023521815  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:53:17,316 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00017760498  lr: 0.0003184  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:53:19,496 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00039612097  lr: 0.0004355  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:53:21,612 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00025758584  lr: 0.0005527  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:53:23,700 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00012719554  lr: 0.0006699  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:25,838 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00015594313  lr: 0.0007871  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 16:53:27,980 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00012503596  lr: 0.0006957  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:30,085 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0002298472  lr: 0.0005785  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:32,230 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00013288778  lr: 0.0004613  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:34,303 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00015037491  lr: 0.0003441  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:36,463 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0056279697  lr: 0.000227  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:36,986 [INFO] [metadata.py:55] train_wall_time: 22.67012667655945
2023-07-10 16:53:36,987 [INFO] [metadata.py:55] train_loss: 0.002910253097404336
2023-07-10 16:53:36,987 [INFO] [metadata.py:55] train_accuracy: 0.999237060546875
2023-07-10 16:53:36,987 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:53:37,862 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9710171  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:38,757 [INFO] [trainer.py:169]   batch 100/157  loss: 2.246654  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:39,133 [INFO] [metadata.py:55] test_wall_time: 2.1449732780456543
2023-07-10 16:53:39,133 [INFO] [metadata.py:55] test_loss: 2.0749215517833735
2023-07-10 16:53:39,133 [INFO] [metadata.py:55] test_accuracy: 0.5609076433121019
2023-07-10 16:53:39,137 [INFO] [train.py:190] Epoch: 178
2023-07-10 16:53:39,725 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:53:40,837 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00012359099  lr: 0.0002012  cpu_mem: 23.4%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:43,090 [INFO] [trainer.py:122]   batch 100/1024  loss: 8.6816406e-05  lr: 0.0003184  cpu_mem: 24.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:45,302 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00013609538  lr: 0.0004355  cpu_mem: 24.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:47,606 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00015639797  lr: 0.0005527  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:49,868 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00024167349  lr: 0.0006699  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:52,034 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00012968101  lr: 0.0007871  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:54,166 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00022492123  lr: 0.0006957  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:56,340 [INFO] [trainer.py:122]   batch 700/1024  loss: 8.0999613e-05  lr: 0.0005785  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:53:58,478 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00030016381  lr: 0.0004613  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:54:00,636 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00017730457  lr: 0.0003441  cpu_mem: 24.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:02,768 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00024720273  lr: 0.000227  cpu_mem: 24.1%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:54:03,248 [INFO] [metadata.py:55] train_wall_time: 23.52211570739746
2023-07-10 16:54:03,248 [INFO] [metadata.py:55] train_loss: 0.0028884205796515516
2023-07-10 16:54:03,248 [INFO] [metadata.py:55] train_accuracy: 0.9991455078125
2023-07-10 16:54:03,248 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:54:04,180 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9151314  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:04,958 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2469859  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 16:54:05,321 [INFO] [metadata.py:55] test_wall_time: 2.0718915462493896
2023-07-10 16:54:05,321 [INFO] [metadata.py:55] test_loss: 2.0395544790158606
2023-07-10 16:54:05,321 [INFO] [metadata.py:55] test_accuracy: 0.5694665605095541
2023-07-10 16:54:05,326 [INFO] [train.py:190] Epoch: 179
2023-07-10 16:54:05,915 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:54:06,893 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00017272118  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:09,101 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00022032966  lr: 0.0003184  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:11,336 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0001811991  lr: 0.0004355  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:13,612 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00021560933  lr: 0.0005527  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:15,859 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0029905308  lr: 0.0006699  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:18,081 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0012716812  lr: 0.0007871  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:20,324 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00033918305  lr: 0.0006957  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:22,477 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00013245821  lr: 0.0005785  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:24,616 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00055114937  lr: 0.0004613  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:26,795 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00012149947  lr: 0.0003441  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:29,016 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00014868772  lr: 0.000227  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:29,475 [INFO] [metadata.py:55] train_wall_time: 23.558989763259888
2023-07-10 16:54:29,475 [INFO] [metadata.py:55] train_loss: 0.003306010742939236
2023-07-10 16:54:29,475 [INFO] [metadata.py:55] train_accuracy: 0.999237060546875
2023-07-10 16:54:29,475 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:54:30,381 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9826546  cpu_mem: 23.1%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:54:31,234 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1890187  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:54:31,617 [INFO] [metadata.py:55] test_wall_time: 2.140915870666504
2023-07-10 16:54:31,617 [INFO] [metadata.py:55] test_loss: 2.0489894303546587
2023-07-10 16:54:31,617 [INFO] [metadata.py:55] test_accuracy: 0.5674761146496815
2023-07-10 16:54:31,621 [INFO] [train.py:190] Epoch: 180
2023-07-10 16:54:32,222 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:54:33,199 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00012221979  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:35,425 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0010493762  lr: 0.0003184  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:54:37,647 [INFO] [trainer.py:122]   batch 200/1024  loss: 9.4955591e-05  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:39,767 [INFO] [trainer.py:122]   batch 300/1024  loss: 8.979936e-05  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:41,996 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00011297386  lr: 0.0006699  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:44,179 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0001057186  lr: 0.0007871  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:46,367 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00013676958  lr: 0.0006957  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:48,600 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0018788937  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:50,775 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00012758288  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:52,814 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00010446989  lr: 0.0003441  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:54:54,907 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00023820656  lr: 0.000227  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:54:55,409 [INFO] [metadata.py:55] train_wall_time: 23.187414407730103
2023-07-10 16:54:55,410 [INFO] [metadata.py:55] train_loss: 0.0030024658073060095
2023-07-10 16:54:55,410 [INFO] [metadata.py:55] train_accuracy: 0.9991607666015625
2023-07-10 16:54:55,410 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:54:56,328 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9830168  cpu_mem: 23.1%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:54:57,110 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3020148  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:54:57,484 [INFO] [metadata.py:55] test_wall_time: 2.0734076499938965
2023-07-10 16:54:57,484 [INFO] [metadata.py:55] test_loss: 2.0588482549995373
2023-07-10 16:54:57,484 [INFO] [metadata.py:55] test_accuracy: 0.5645899681528662
2023-07-10 16:54:57,489 [INFO] [train.py:190] Epoch: 181
2023-07-10 16:54:58,092 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:54:59,068 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00020009661  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:01,290 [INFO] [trainer.py:122]   batch 100/1024  loss: 9.2391616e-05  lr: 0.0003184  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:03,446 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0001740498  lr: 0.0004355  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:05,664 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00025034844  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:07,773 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00017168418  lr: 0.0006699  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:09,947 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00011972008  lr: 0.0007871  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:12,211 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00014050143  lr: 0.0006957  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:14,438 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00034601518  lr: 0.0005785  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:16,646 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00025750903  lr: 0.0004613  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:18,836 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.010399984  lr: 0.0003441  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:21,008 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00011179639  lr: 0.000227  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:21,501 [INFO] [metadata.py:55] train_wall_time: 23.408923387527466
2023-07-10 16:55:21,501 [INFO] [metadata.py:55] train_loss: 0.0025939211562473474
2023-07-10 16:55:21,501 [INFO] [metadata.py:55] train_accuracy: 0.9993438720703125
2023-07-10 16:55:21,502 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:55:22,436 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8869379  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:23,210 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2230511  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:23,554 [INFO] [metadata.py:55] test_wall_time: 2.052140951156616
2023-07-10 16:55:23,554 [INFO] [metadata.py:55] test_loss: 2.0251459695731
2023-07-10 16:55:23,555 [INFO] [metadata.py:55] test_accuracy: 0.5720541401273885
2023-07-10 16:55:23,559 [INFO] [train.py:190] Epoch: 182
2023-07-10 16:55:24,227 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:55:25,133 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00010578456  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:27,259 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00022611055  lr: 0.0003184  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:29,343 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00022478429  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:31,495 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0022697991  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:33,676 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00012197185  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:35,819 [INFO] [trainer.py:122]   batch 500/1024  loss: 8.6603395e-05  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:37,976 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0027338103  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:40,269 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0013629775  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:42,530 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00023421484  lr: 0.0004613  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:44,733 [INFO] [trainer.py:122]   batch 900/1024  loss: 6.9453839e-05  lr: 0.0003441  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:46,987 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00065089331  lr: 0.000227  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:47,484 [INFO] [metadata.py:55] train_wall_time: 23.257580995559692
2023-07-10 16:55:47,485 [INFO] [metadata.py:55] train_loss: 0.002349086642027487
2023-07-10 16:55:47,485 [INFO] [metadata.py:55] train_accuracy: 0.999420166015625
2023-07-10 16:55:47,485 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:55:48,385 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8843056  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:49,228 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2240124  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:49,581 [INFO] [metadata.py:55] test_wall_time: 2.095574378967285
2023-07-10 16:55:49,582 [INFO] [metadata.py:55] test_loss: 2.0192589691490124
2023-07-10 16:55:49,582 [INFO] [metadata.py:55] test_accuracy: 0.5707603503184714
2023-07-10 16:55:49,586 [INFO] [train.py:190] Epoch: 183
2023-07-10 16:55:50,198 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:55:51,089 [INFO] [trainer.py:122]   batch 0/1024  loss: 7.9529433e-05  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:53,284 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00096279226  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:55:55,431 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00023816613  lr: 0.0004355  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:57,604 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0081033465  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:55:59,762 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00013905951  lr: 0.0006699  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:01,907 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00054579979  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:04,084 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00056253956  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:06,286 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0048787915  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:08,460 [INFO] [trainer.py:122]   batch 800/1024  loss: 9.5335687e-05  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:10,728 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0011473867  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:12,829 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0076889982  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:13,298 [INFO] [metadata.py:55] train_wall_time: 23.099920749664307
2023-07-10 16:56:13,299 [INFO] [metadata.py:55] train_loss: 0.003034131838653309
2023-07-10 16:56:13,299 [INFO] [metadata.py:55] train_accuracy: 0.9991912841796875
2023-07-10 16:56:13,299 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:56:14,215 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9045727  cpu_mem: 23.1%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:15,109 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3912864  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:15,470 [INFO] [metadata.py:55] test_wall_time: 2.169922113418579
2023-07-10 16:56:15,470 [INFO] [metadata.py:55] test_loss: 2.0624941655784657
2023-07-10 16:56:15,470 [INFO] [metadata.py:55] test_accuracy: 0.5715565286624203
2023-07-10 16:56:15,475 [INFO] [train.py:190] Epoch: 184
2023-07-10 16:56:16,061 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:56:16,983 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00010962037  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:19,282 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00032532157  lr: 0.0003184  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:21,560 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00010724596  lr: 0.0004355  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:23,776 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00017260946  lr: 0.0005527  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:25,919 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00014092035  lr: 0.0006699  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:28,058 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00022161071  lr: 0.0007871  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:30,259 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00021597718  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:32,404 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.000605418  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:34,605 [INFO] [trainer.py:122]   batch 800/1024  loss: 6.4933774e-05  lr: 0.0004613  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:36,823 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00012960918  lr: 0.0003441  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:38,989 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00032338523  lr: 0.000227  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:39,451 [INFO] [metadata.py:55] train_wall_time: 23.39017653465271
2023-07-10 16:56:39,452 [INFO] [metadata.py:55] train_loss: 0.0028411319021586223
2023-07-10 16:56:39,452 [INFO] [metadata.py:55] train_accuracy: 0.99920654296875
2023-07-10 16:56:39,452 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:56:40,360 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8600723  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:41,142 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3263674  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:41,501 [INFO] [metadata.py:55] test_wall_time: 2.0486807823181152
2023-07-10 16:56:41,502 [INFO] [metadata.py:55] test_loss: 2.0243872275018386
2023-07-10 16:56:41,502 [INFO] [metadata.py:55] test_accuracy: 0.5739450636942676
2023-07-10 16:56:41,506 [INFO] [train.py:216] Updating best model with epoch: 184
2023-07-10 16:56:41,519 [INFO] [train.py:190] Epoch: 185
2023-07-10 16:56:42,193 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:56:43,151 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00021972806  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:45,344 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00012629559  lr: 0.0003184  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:56:47,552 [INFO] [trainer.py:122]   batch 200/1024  loss: 8.5821746e-05  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:56:49,717 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0001228496  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:56:51,863 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00030830011  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:56:54,021 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0001760025  lr: 0.0007871  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:56:56,324 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00012529448  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:56:58,477 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00023514846  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:00,652 [INFO] [trainer.py:122]   batch 800/1024  loss: 8.2302875e-05  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:02,811 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0055296137  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:04,955 [INFO] [trainer.py:122]   batch 1000/1024  loss: 9.9644698e-05  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:05,454 [INFO] [metadata.py:55] train_wall_time: 23.2606143951416
2023-07-10 16:57:05,454 [INFO] [metadata.py:55] train_loss: 0.002332976056415248
2023-07-10 16:57:05,455 [INFO] [metadata.py:55] train_accuracy: 0.999359130859375
2023-07-10 16:57:05,455 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:57:06,393 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8330193  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:07,173 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2804928  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:07,540 [INFO] [metadata.py:55] test_wall_time: 2.084907293319702
2023-07-10 16:57:07,541 [INFO] [metadata.py:55] test_loss: 2.0073530772689043
2023-07-10 16:57:07,541 [INFO] [metadata.py:55] test_accuracy: 0.5729498407643312
2023-07-10 16:57:07,545 [INFO] [train.py:190] Epoch: 186
2023-07-10 16:57:08,156 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:57:09,091 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0001988921  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:11,267 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00041277998  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:13,416 [INFO] [trainer.py:122]   batch 200/1024  loss: 7.4885407e-05  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:15,565 [INFO] [trainer.py:122]   batch 300/1024  loss: 8.8695691e-05  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:17,672 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00010612018  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:19,787 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00045727353  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:22,044 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00010453881  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:24,119 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0028675699  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:26,346 [INFO] [trainer.py:122]   batch 800/1024  loss: 9.0063506e-05  lr: 0.0004613  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:28,544 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0017527234  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:30,713 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0088718385  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:31,193 [INFO] [metadata.py:55] train_wall_time: 23.037084341049194
2023-07-10 16:57:31,194 [INFO] [metadata.py:55] train_loss: 0.0022932399073063436
2023-07-10 16:57:31,194 [INFO] [metadata.py:55] train_accuracy: 0.9993133544921875
2023-07-10 16:57:31,194 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:57:32,071 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8683184  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:32,924 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2669148  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:33,303 [INFO] [metadata.py:55] test_wall_time: 2.1086299419403076
2023-07-10 16:57:33,304 [INFO] [metadata.py:55] test_loss: 2.014348203209555
2023-07-10 16:57:33,304 [INFO] [metadata.py:55] test_accuracy: 0.5725517515923567
2023-07-10 16:57:33,308 [INFO] [train.py:190] Epoch: 187
2023-07-10 16:57:33,918 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:57:34,853 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0046040239  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:37,036 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00051910611  lr: 0.0003184  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:39,228 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00020320281  lr: 0.0004355  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:41,375 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00012493054  lr: 0.0005527  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:43,520 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00032024659  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:45,630 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00021463857  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:47,810 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00016568047  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:49,900 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00017494963  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:52,031 [INFO] [trainer.py:122]   batch 800/1024  loss: 7.8712379e-05  lr: 0.0004613  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:54,192 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00030780974  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:57:56,355 [INFO] [trainer.py:122]   batch 1000/1024  loss: 7.7897559e-05  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:56,820 [INFO] [metadata.py:55] train_wall_time: 22.902543306350708
2023-07-10 16:57:56,821 [INFO] [metadata.py:55] train_loss: 0.0027421401109002375
2023-07-10 16:57:56,821 [INFO] [metadata.py:55] train_accuracy: 0.9992218017578125
2023-07-10 16:57:56,821 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:57:57,694 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7853169  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:58,457 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1672721  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:57:58,808 [INFO] [metadata.py:55] test_wall_time: 1.9862473011016846
2023-07-10 16:57:58,808 [INFO] [metadata.py:55] test_loss: 1.9975272637263985
2023-07-10 16:57:58,808 [INFO] [metadata.py:55] test_accuracy: 0.573546974522293
2023-07-10 16:57:58,813 [INFO] [train.py:190] Epoch: 188
2023-07-10 16:57:59,390 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:58:00,360 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.03517478  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 16:58:02,865 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00026534515  lr: 0.0003184  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:05,152 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.028737489  lr: 0.0004355  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:07,431 [INFO] [trainer.py:122]   batch 300/1024  loss: 6.5195432e-05  lr: 0.0005527  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:09,794 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00010062374  lr: 0.0006699  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:12,028 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00012956306  lr: 0.0007871  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:14,187 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0002087419  lr: 0.0006957  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:16,402 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0001291021  lr: 0.0005785  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:18,568 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00029912233  lr: 0.0004613  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:20,756 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0001354922  lr: 0.0003441  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:22,977 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00022632297  lr: 0.000227  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:23,457 [INFO] [metadata.py:55] train_wall_time: 24.066550493240356
2023-07-10 16:58:23,458 [INFO] [metadata.py:55] train_loss: 0.0029015096075468705
2023-07-10 16:58:23,458 [INFO] [metadata.py:55] train_accuracy: 0.999114990234375
2023-07-10 16:58:23,458 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:58:24,343 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8736308  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:25,169 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2672327  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:25,537 [INFO] [metadata.py:55] test_wall_time: 2.0780727863311768
2023-07-10 16:58:25,537 [INFO] [metadata.py:55] test_loss: 2.04680621320275
2023-07-10 16:58:25,537 [INFO] [metadata.py:55] test_accuracy: 0.5654856687898089
2023-07-10 16:58:25,542 [INFO] [train.py:190] Epoch: 189
2023-07-10 16:58:26,131 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:58:27,091 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00014278122  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:58:29,274 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0020208787  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:58:31,354 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0095791165  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:58:33,416 [INFO] [trainer.py:122]   batch 300/1024  loss: 7.7525925e-05  lr: 0.0005527  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:58:35,523 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00052846334  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:58:37,669 [INFO] [trainer.py:122]   batch 500/1024  loss: 7.8192061e-05  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:58:39,818 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00019454939  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:41,960 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00017928184  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:44,042 [INFO] [trainer.py:122]   batch 800/1024  loss: 9.7964446e-05  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:46,199 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00045565789  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:48,350 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.005853489  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:48,817 [INFO] [metadata.py:55] train_wall_time: 22.685452938079834
2023-07-10 16:58:48,817 [INFO] [metadata.py:55] train_loss: 0.002238143642610879
2023-07-10 16:58:48,817 [INFO] [metadata.py:55] train_accuracy: 0.999298095703125
2023-07-10 16:58:48,818 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:58:49,685 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8657306  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:50,473 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3020425  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:50,834 [INFO] [metadata.py:55] test_wall_time: 2.0160744190216064
2023-07-10 16:58:50,834 [INFO] [metadata.py:55] test_loss: 2.02979431410504
2023-07-10 16:58:50,835 [INFO] [metadata.py:55] test_accuracy: 0.5637937898089171
2023-07-10 16:58:50,839 [INFO] [train.py:190] Epoch: 190
2023-07-10 16:58:51,431 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:58:52,413 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00021542245  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:54,579 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00027602303  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:56,754 [INFO] [trainer.py:122]   batch 200/1024  loss: 9.2539703e-05  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:58:58,926 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00036583462  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:01,033 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00025419172  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:03,152 [INFO] [trainer.py:122]   batch 500/1024  loss: 8.0570244e-05  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:05,332 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00023409649  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:07,504 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00011731919  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:09,643 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00022841571  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:11,828 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00069364114  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:13,943 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00012156773  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:14,399 [INFO] [metadata.py:55] train_wall_time: 22.967023134231567
2023-07-10 16:59:14,399 [INFO] [metadata.py:55] train_loss: 0.0026871109492461187
2023-07-10 16:59:14,399 [INFO] [metadata.py:55] train_accuracy: 0.999237060546875
2023-07-10 16:59:14,399 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:59:15,254 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9063852  cpu_mem: 23.1%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:16,132 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2322557  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:16,503 [INFO] [metadata.py:55] test_wall_time: 2.103113889694214
2023-07-10 16:59:16,503 [INFO] [metadata.py:55] test_loss: 2.002749433183366
2023-07-10 16:59:16,503 [INFO] [metadata.py:55] test_accuracy: 0.5713574840764332
2023-07-10 16:59:16,508 [INFO] [train.py:190] Epoch: 191
2023-07-10 16:59:17,128 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:59:18,152 [INFO] [trainer.py:122]   batch 0/1024  loss: 9.5462528e-05  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:20,371 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00016950956  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:22,544 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0077058841  lr: 0.0004355  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:24,652 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00012670559  lr: 0.0005527  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:26,747 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00031198101  lr: 0.0006699  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:28,865 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0084316349  lr: 0.0007871  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:30,937 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00023818968  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:33,096 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00035036626  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:35,152 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00015805633  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:37,278 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00013396482  lr: 0.0003441  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:39,430 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00046617261  lr: 0.000227  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:40,018 [INFO] [metadata.py:55] train_wall_time: 22.8894259929657
2023-07-10 16:59:40,018 [INFO] [metadata.py:55] train_loss: 0.002229836976233912
2023-07-10 16:59:40,018 [INFO] [metadata.py:55] train_accuracy: 0.999420166015625
2023-07-10 16:59:40,019 [INFO] [train.py:200]   evaluating against test data
2023-07-10 16:59:40,932 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9037907  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:41,836 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3424206  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:42,213 [INFO] [metadata.py:55] test_wall_time: 2.194139242172241
2023-07-10 16:59:42,214 [INFO] [metadata.py:55] test_loss: 2.0313273949228274
2023-07-10 16:59:42,214 [INFO] [metadata.py:55] test_accuracy: 0.5677746815286624
2023-07-10 16:59:42,218 [INFO] [train.py:190] Epoch: 192
2023-07-10 16:59:42,896 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 16:59:43,784 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00012076351  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:45,964 [INFO] [trainer.py:122]   batch 100/1024  loss: 8.1471946e-05  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:48,146 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00071266427  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:50,308 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00010031353  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 16:59:52,531 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00010534334  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:54,689 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.001772791  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:56,910 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00018670323  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 16:59:59,099 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.012413051  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:01,243 [INFO] [trainer.py:122]   batch 800/1024  loss: 6.9792266e-05  lr: 0.0004613  cpu_mem: 23.4%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:03,404 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0015262507  lr: 0.0003441  cpu_mem: 23.4%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:00:05,563 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00018750211  lr: 0.000227  cpu_mem: 23.4%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:00:06,036 [INFO] [metadata.py:55] train_wall_time: 23.139890670776367
2023-07-10 17:00:06,037 [INFO] [metadata.py:55] train_loss: 0.0022075012681455064
2023-07-10 17:00:06,037 [INFO] [metadata.py:55] train_accuracy: 0.9993896484375
2023-07-10 17:00:06,037 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:00:06,924 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8854231  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:07,799 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1964953  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:08,174 [INFO] [metadata.py:55] test_wall_time: 2.1365740299224854
2023-07-10 17:00:08,174 [INFO] [metadata.py:55] test_loss: 2.013649026299738
2023-07-10 17:00:08,175 [INFO] [metadata.py:55] test_accuracy: 0.5703622611464968
2023-07-10 17:00:08,179 [INFO] [train.py:190] Epoch: 193
2023-07-10 17:00:08,789 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:00:09,702 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00017913667  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:11,906 [INFO] [trainer.py:122]   batch 100/1024  loss: 9.5813491e-05  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:14,074 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0001000828  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:16,264 [INFO] [trainer.py:122]   batch 300/1024  loss: 9.9427176e-05  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:18,512 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.026427222  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:20,673 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0003603696  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:22,927 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0001056306  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:25,145 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00019100893  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:27,327 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00035561869  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:29,576 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00020354547  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:31,688 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0001214662  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:32,150 [INFO] [metadata.py:55] train_wall_time: 23.36098861694336
2023-07-10 17:00:32,151 [INFO] [metadata.py:55] train_loss: 0.0023849251443834873
2023-07-10 17:00:32,151 [INFO] [metadata.py:55] train_accuracy: 0.9993133544921875
2023-07-10 17:00:32,151 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:00:33,023 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8818855  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:33,816 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1778228  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:34,173 [INFO] [metadata.py:55] test_wall_time: 2.020761728286743
2023-07-10 17:00:34,173 [INFO] [metadata.py:55] test_loss: 1.9963332118502088
2023-07-10 17:00:34,173 [INFO] [metadata.py:55] test_accuracy: 0.5694665605095541
2023-07-10 17:00:34,177 [INFO] [train.py:190] Epoch: 194
2023-07-10 17:00:34,779 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:00:35,705 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00075170008  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:37,903 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00065464381  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:40,084 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00012000895  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:42,253 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00039188124  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:44,428 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0001989585  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:00:46,736 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00026205441  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:48,958 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0001032792  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:51,099 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00034329257  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:53,265 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00014821779  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:55,432 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00020470802  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:57,564 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00085869303  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:58,029 [INFO] [metadata.py:55] train_wall_time: 23.249791383743286
2023-07-10 17:00:58,029 [INFO] [metadata.py:55] train_loss: 0.002975774834485634
2023-07-10 17:00:58,029 [INFO] [metadata.py:55] train_accuracy: 0.9991912841796875
2023-07-10 17:00:58,029 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:00:58,900 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8751953  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:00:59,682 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2836869  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:00,037 [INFO] [metadata.py:55] test_wall_time: 2.007291316986084
2023-07-10 17:01:00,037 [INFO] [metadata.py:55] test_loss: 2.0020284455293305
2023-07-10 17:01:00,037 [INFO] [metadata.py:55] test_accuracy: 0.5726512738853503
2023-07-10 17:01:00,042 [INFO] [train.py:190] Epoch: 195
2023-07-10 17:01:00,729 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:01:01,631 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0022205005  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:01:03,804 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00010881486  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:06,032 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.000248141  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:01:08,294 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00019506038  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:01:10,515 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00019935971  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:01:12,731 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00016136879  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:01:14,903 [INFO] [trainer.py:122]   batch 600/1024  loss: 9.3660405e-05  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:01:17,200 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00015572873  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:19,410 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00018256152  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:21,652 [INFO] [trainer.py:122]   batch 900/1024  loss: 7.9011079e-05  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:23,901 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0001308194  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:24,368 [INFO] [metadata.py:55] train_wall_time: 23.639285802841187
2023-07-10 17:01:24,369 [INFO] [metadata.py:55] train_loss: 0.001970993538613186
2023-07-10 17:01:24,369 [INFO] [metadata.py:55] train_accuracy: 0.99945068359375
2023-07-10 17:01:24,369 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:01:25,225 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8608159  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:26,069 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2814894  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:26,434 [INFO] [metadata.py:55] test_wall_time: 2.0647311210632324
2023-07-10 17:01:26,434 [INFO] [metadata.py:55] test_loss: 1.9857203087229638
2023-07-10 17:01:26,435 [INFO] [metadata.py:55] test_accuracy: 0.5717555732484076
2023-07-10 17:01:26,439 [INFO] [train.py:190] Epoch: 196
2023-07-10 17:01:27,040 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:01:27,954 [INFO] [trainer.py:122]   batch 0/1024  loss: 9.5575269e-05  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:30,245 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00011721799  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:32,393 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00011675086  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:01:34,552 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00012415161  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:01:36,752 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.015151806  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:01:38,893 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00039647971  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:41,050 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0001505181  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:43,197 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00046385147  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:45,329 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00012276211  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:47,527 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00028613437  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:01:49,751 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00011391863  lr: 0.000227  cpu_mem: 23.4%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:01:50,234 [INFO] [metadata.py:55] train_wall_time: 23.194101572036743
2023-07-10 17:01:50,234 [INFO] [metadata.py:55] train_loss: 0.002460547985606354
2023-07-10 17:01:50,234 [INFO] [metadata.py:55] train_accuracy: 0.999298095703125
2023-07-10 17:01:50,235 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:01:51,089 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8286599  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:01:51,893 [INFO] [trainer.py:169]   batch 100/157  loss: 2.332022  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:01:52,242 [INFO] [metadata.py:55] test_wall_time: 2.006272315979004
2023-07-10 17:01:52,242 [INFO] [metadata.py:55] test_loss: 2.0077882709017225
2023-07-10 17:01:52,242 [INFO] [metadata.py:55] test_accuracy: 0.5732484076433121
2023-07-10 17:01:52,246 [INFO] [train.py:190] Epoch: 197
2023-07-10 17:01:52,839 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:01:53,753 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00055567297  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:01:55,852 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00048048125  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:01:57,916 [INFO] [trainer.py:122]   batch 200/1024  loss: 7.1727882e-05  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:00,072 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.000144013  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:02,228 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00015689414  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:04,373 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00012784798  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:06,527 [INFO] [trainer.py:122]   batch 600/1024  loss: 7.8536053e-05  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:08,669 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00020380544  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:10,832 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.000105043  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:13,023 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0001326864  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:15,216 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00015588745  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:15,686 [INFO] [metadata.py:55] train_wall_time: 22.846466064453125
2023-07-10 17:02:15,686 [INFO] [metadata.py:55] train_loss: 0.0022412969362513024
2023-07-10 17:02:15,686 [INFO] [metadata.py:55] train_accuracy: 0.9994354248046875
2023-07-10 17:02:15,687 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:02:16,602 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7872512  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:17,383 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2317936  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:17,782 [INFO] [metadata.py:55] test_wall_time: 2.094547748565674
2023-07-10 17:02:17,782 [INFO] [metadata.py:55] test_loss: 1.976994121150606
2023-07-10 17:02:17,782 [INFO] [metadata.py:55] test_accuracy: 0.5745421974522293
2023-07-10 17:02:17,787 [INFO] [train.py:216] Updating best model with epoch: 197
2023-07-10 17:02:17,800 [INFO] [train.py:190] Epoch: 198
2023-07-10 17:02:18,495 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:02:19,408 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00010330645  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:21,573 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00037456414  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:23,787 [INFO] [trainer.py:122]   batch 200/1024  loss: 9.7869211e-05  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:25,960 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0063226488  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:28,188 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00024308177  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:30,430 [INFO] [trainer.py:122]   batch 500/1024  loss: 6.9194684e-05  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:32,620 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00010043127  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:34,796 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00012229354  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:37,017 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00010924035  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:39,212 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00022666439  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:41,323 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00018209484  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:41,827 [INFO] [metadata.py:55] train_wall_time: 23.331568956375122
2023-07-10 17:02:41,828 [INFO] [metadata.py:55] train_loss: 0.0025879062450684387
2023-07-10 17:02:41,828 [INFO] [metadata.py:55] train_accuracy: 0.9993896484375
2023-07-10 17:02:41,828 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:02:42,743 [INFO] [trainer.py:169]   batch 0/157  loss: 1.809692  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:43,541 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1560993  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:43,925 [INFO] [metadata.py:55] test_wall_time: 2.096430540084839
2023-07-10 17:02:43,925 [INFO] [metadata.py:55] test_loss: 2.0057167665214295
2023-07-10 17:02:43,925 [INFO] [metadata.py:55] test_accuracy: 0.5723527070063694
2023-07-10 17:02:43,930 [INFO] [train.py:190] Epoch: 199
2023-07-10 17:02:44,556 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:02:45,542 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00010068613  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:47,734 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0056925262  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:49,863 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0001469025  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:02:52,034 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00016527723  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:54,227 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00024587056  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:56,468 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0095617697  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:02:58,792 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0001041722  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:01,075 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00315811  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:03,260 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0025477489  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:05,399 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00015347637  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:07,509 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00013410494  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:07,967 [INFO] [metadata.py:55] train_wall_time: 23.41116690635681
2023-07-10 17:03:07,967 [INFO] [metadata.py:55] train_loss: 0.0019090640461243424
2023-07-10 17:03:07,967 [INFO] [metadata.py:55] train_accuracy: 0.99951171875
2023-07-10 17:03:07,968 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:03:08,886 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8017727  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:03:09,647 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2424097  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:03:10,002 [INFO] [metadata.py:55] test_wall_time: 2.0332748889923096
2023-07-10 17:03:10,002 [INFO] [metadata.py:55] test_loss: 2.037881695540847
2023-07-10 17:03:10,002 [INFO] [metadata.py:55] test_accuracy: 0.5626990445859873
2023-07-10 17:03:10,007 [INFO] [train.py:190] Epoch: 200
2023-07-10 17:03:10,631 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:03:11,521 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00018349852  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:03:13,598 [INFO] [trainer.py:122]   batch 100/1024  loss: 8.2759529e-05  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:15,684 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00010435336  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:03:17,868 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00012067408  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:20,075 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0062373281  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:22,289 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00015680052  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:24,517 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0015483109  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:26,691 [INFO] [trainer.py:122]   batch 700/1024  loss: 9.3494535e-05  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:28,850 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00017591333  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:31,069 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00020600142  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:33,219 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00013104379  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:33,689 [INFO] [metadata.py:55] train_wall_time: 23.05749535560608
2023-07-10 17:03:33,689 [INFO] [metadata.py:55] train_loss: 0.0021443140683743422
2023-07-10 17:03:33,689 [INFO] [metadata.py:55] train_accuracy: 0.99945068359375
2023-07-10 17:03:33,689 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:03:34,570 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8327358  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:35,472 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2987711  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:35,846 [INFO] [metadata.py:55] test_wall_time: 2.1565730571746826
2023-07-10 17:03:35,847 [INFO] [metadata.py:55] test_loss: 2.0120786071582963
2023-07-10 17:03:35,847 [INFO] [metadata.py:55] test_accuracy: 0.569765127388535
2023-07-10 17:03:35,852 [INFO] [train.py:190] Epoch: 201
2023-07-10 17:03:36,457 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:03:37,365 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00012615793  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:39,728 [INFO] [trainer.py:122]   batch 100/1024  loss: 8.2131868e-05  lr: 0.0003184  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:41,899 [INFO] [trainer.py:122]   batch 200/1024  loss: 9.146901e-05  lr: 0.0004355  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:44,031 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00052755256  lr: 0.0005527  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:46,146 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00011781196  lr: 0.0006699  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:48,290 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00032451266  lr: 0.0007871  cpu_mem: 24.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:50,472 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00026607944  lr: 0.0006957  cpu_mem: 24.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:52,625 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0003686767  lr: 0.0005785  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:54,800 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00016158701  lr: 0.0004613  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:56,969 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.032975025  lr: 0.0003441  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:59,224 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00021310194  lr: 0.000227  cpu_mem: 24.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:03:59,699 [INFO] [metadata.py:55] train_wall_time: 23.24181294441223
2023-07-10 17:03:59,700 [INFO] [metadata.py:55] train_loss: 0.002098539373733388
2023-07-10 17:03:59,700 [INFO] [metadata.py:55] train_accuracy: 0.99945068359375
2023-07-10 17:03:59,700 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:04:00,610 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8033401  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:01,458 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2579942  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:01,840 [INFO] [metadata.py:55] test_wall_time: 2.139756441116333
2023-07-10 17:04:01,841 [INFO] [metadata.py:55] test_loss: 2.0503809740588923
2023-07-10 17:04:01,841 [INFO] [metadata.py:55] test_accuracy: 0.5607085987261147
2023-07-10 17:04:01,845 [INFO] [train.py:190] Epoch: 202
2023-07-10 17:04:02,450 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:04:03,337 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00048321058  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:05,588 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00016832964  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:07,756 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00017941048  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:09,915 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0001859514  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:04:12,232 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00010375692  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:14,335 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00070289982  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:16,616 [INFO] [trainer.py:122]   batch 600/1024  loss: 8.9887566e-05  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:04:18,944 [INFO] [trainer.py:122]   batch 700/1024  loss: 9.9661906e-05  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:04:21,172 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00010258138  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:04:23,397 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00023621395  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:04:25,624 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00026896675  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:26,107 [INFO] [metadata.py:55] train_wall_time: 23.657480001449585
2023-07-10 17:04:26,108 [INFO] [metadata.py:55] train_loss: 0.002805508934589085
2023-07-10 17:04:26,108 [INFO] [metadata.py:55] train_accuracy: 0.999237060546875
2023-07-10 17:04:26,108 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:04:26,981 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8164138  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:27,777 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3195903  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:28,122 [INFO] [metadata.py:55] test_wall_time: 2.0132267475128174
2023-07-10 17:04:28,122 [INFO] [metadata.py:55] test_loss: 2.03485381451382
2023-07-10 17:04:28,122 [INFO] [metadata.py:55] test_accuracy: 0.5639928343949044
2023-07-10 17:04:28,127 [INFO] [train.py:190] Epoch: 203
2023-07-10 17:04:28,727 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:04:29,614 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00014683491  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:31,856 [INFO] [trainer.py:122]   batch 100/1024  loss: 9.4466377e-05  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:34,098 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00014776984  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:36,440 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00012928752  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:04:38,749 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00012790535  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:04:40,936 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00013199035  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:04:43,096 [INFO] [trainer.py:122]   batch 600/1024  loss: 9.385898e-05  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:04:45,282 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00018260497  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:04:47,492 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00012144589  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:49,687 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0001580356  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:51,842 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00014514767  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:52,319 [INFO] [metadata.py:55] train_wall_time: 23.592692375183105
2023-07-10 17:04:52,320 [INFO] [metadata.py:55] train_loss: 0.002083068025601875
2023-07-10 17:04:52,320 [INFO] [metadata.py:55] train_accuracy: 0.99945068359375
2023-07-10 17:04:52,320 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:04:53,183 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8156427  cpu_mem: 23.2%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:53,959 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3153586  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:54,302 [INFO] [metadata.py:55] test_wall_time: 1.9808073043823242
2023-07-10 17:04:54,302 [INFO] [metadata.py:55] test_loss: 2.0480756941874314
2023-07-10 17:04:54,302 [INFO] [metadata.py:55] test_accuracy: 0.5619028662420382
2023-07-10 17:04:54,307 [INFO] [train.py:190] Epoch: 204
2023-07-10 17:04:54,893 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:04:55,829 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00011223788  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:04:58,081 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00011745709  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:05:00,308 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00010890517  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:05:02,548 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00015471001  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:04,752 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00016041542  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:05:06,908 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.001418085  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:09,076 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.002527104  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:11,248 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00032474933  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:13,443 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0041432292  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.6]% of [20470]MiB
2023-07-10 17:05:15,497 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00016477251  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:17,635 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00018717014  lr: 0.000227  cpu_mem: 23.4%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:18,103 [INFO] [metadata.py:55] train_wall_time: 23.209812879562378
2023-07-10 17:05:18,104 [INFO] [metadata.py:55] train_loss: 0.00235501541112626
2023-07-10 17:05:18,104 [INFO] [metadata.py:55] train_accuracy: 0.9993896484375
2023-07-10 17:05:18,104 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:05:19,086 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8160363  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:19,902 [INFO] [trainer.py:169]   batch 100/157  loss: 2.253793  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:20,282 [INFO] [metadata.py:55] test_wall_time: 2.1778359413146973
2023-07-10 17:05:20,283 [INFO] [metadata.py:55] test_loss: 1.999962868204542
2023-07-10 17:05:20,283 [INFO] [metadata.py:55] test_accuracy: 0.5704617834394905
2023-07-10 17:05:20,287 [INFO] [train.py:190] Epoch: 205
2023-07-10 17:05:20,898 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:05:21,803 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00016377239  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:24,025 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.054836676  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:26,220 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.0001156113  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:28,397 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00020691616  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:30,556 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00014486082  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:05:32,745 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00020483028  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:34,912 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00014288828  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:37,100 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00020421667  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.7]% of [20470]MiB
2023-07-10 17:05:39,265 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00011933137  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:05:41,432 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0023686315  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:05:43,572 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0001301876  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:05:44,023 [INFO] [metadata.py:55] train_wall_time: 23.12484312057495
2023-07-10 17:05:44,023 [INFO] [metadata.py:55] train_loss: 0.0021483183895441016
2023-07-10 17:05:44,032 [INFO] [metadata.py:55] train_accuracy: 0.9994049072265625
2023-07-10 17:05:44,033 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:05:44,979 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8361166  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:05:45,808 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2574501  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:05:46,171 [INFO] [metadata.py:55] test_wall_time: 2.1365411281585693
2023-07-10 17:05:46,171 [INFO] [metadata.py:55] test_loss: 2.0085061629107046
2023-07-10 17:05:46,171 [INFO] [metadata.py:55] test_accuracy: 0.564390923566879
2023-07-10 17:05:46,176 [INFO] [train.py:190] Epoch: 206
2023-07-10 17:05:46,748 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:05:47,677 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.028723851  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:05:49,748 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0004134824  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:05:51,820 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00010633178  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:05:53,915 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00018074102  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:05:56,038 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0001009886  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:05:58,084 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00023030171  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.8]% of [20470]MiB
2023-07-10 17:06:00,224 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0001035748  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:02,305 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00010211628  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:04,373 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00011974167  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:06,436 [INFO] [trainer.py:122]   batch 900/1024  loss: 8.3151892e-05  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:08,543 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00024502023  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:08,995 [INFO] [metadata.py:55] train_wall_time: 22.24738383293152
2023-07-10 17:06:08,996 [INFO] [metadata.py:55] train_loss: 0.0013919162440245714
2023-07-10 17:06:09,005 [INFO] [metadata.py:55] train_accuracy: 0.999542236328125
2023-07-10 17:06:09,005 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:06:09,945 [INFO] [trainer.py:169]   batch 0/157  loss: 1.9156744  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:10,739 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2477584  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:11,087 [INFO] [metadata.py:55] test_wall_time: 2.0797903537750244
2023-07-10 17:06:11,087 [INFO] [metadata.py:55] test_loss: 2.055507872514664
2023-07-10 17:06:11,087 [INFO] [metadata.py:55] test_accuracy: 0.5639928343949044
2023-07-10 17:06:11,092 [INFO] [train.py:190] Epoch: 207
2023-07-10 17:06:11,650 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:06:12,652 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.002645947  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:14,912 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00017733003  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:17,103 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00017659411  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:19,272 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00018417933  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:21,497 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0076584443  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:23,635 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0001744981  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:25,788 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00014129181  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:27,962 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00012498771  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:30,217 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00031490962  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:32,335 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00011270978  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 17:06:34,406 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.015998941  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 17:06:34,872 [INFO] [metadata.py:55] train_wall_time: 23.222546577453613
2023-07-10 17:06:34,873 [INFO] [metadata.py:55] train_loss: 0.002244669133112609
2023-07-10 17:06:34,873 [INFO] [metadata.py:55] train_accuracy: 0.99932861328125
2023-07-10 17:06:34,873 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:06:35,763 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8391548  cpu_mem: 23.2%  gpu_mem: [9.0]% of [20470]MiB
2023-07-10 17:06:36,608 [INFO] [trainer.py:169]   batch 100/157  loss: 2.246804  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:36,964 [INFO] [metadata.py:55] test_wall_time: 2.090618848800659
2023-07-10 17:06:36,965 [INFO] [metadata.py:55] test_loss: 2.0367047224834467
2023-07-10 17:06:36,965 [INFO] [metadata.py:55] test_accuracy: 0.5684713375796179
2023-07-10 17:06:36,969 [INFO] [train.py:190] Epoch: 208
2023-07-10 17:06:37,599 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:06:38,551 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00072699471  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:40,823 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00064574962  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:42,989 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00013018583  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:45,180 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00012118123  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:47,402 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00027532157  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.9]% of [20470]MiB
2023-07-10 17:06:49,648 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.0026198896  lr: 0.0007871  cpu_mem: 23.4%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 17:06:51,827 [INFO] [trainer.py:122]   batch 600/1024  loss: 8.0140038e-05  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 17:06:53,971 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.079867445  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:06:56,137 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00011306268  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:06:58,304 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00014045215  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 17:07:00,476 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.012655269  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 17:07:00,957 [INFO] [metadata.py:55] train_wall_time: 23.3580961227417
2023-07-10 17:07:00,957 [INFO] [metadata.py:55] train_loss: 0.002166407064756015
2023-07-10 17:07:00,958 [INFO] [metadata.py:55] train_accuracy: 0.9993743896484375
2023-07-10 17:07:00,958 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:07:01,815 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8090253  cpu_mem: 23.2%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 17:07:02,664 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2348382  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:03,023 [INFO] [metadata.py:55] test_wall_time: 2.0644023418426514
2023-07-10 17:07:03,023 [INFO] [metadata.py:55] test_loss: 2.011293425681485
2023-07-10 17:07:03,023 [INFO] [metadata.py:55] test_accuracy: 0.5693670382165605
2023-07-10 17:07:03,028 [INFO] [train.py:190] Epoch: 209
2023-07-10 17:07:03,591 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:07:04,535 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00028040621  lr: 0.0002012  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:06,773 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.0012082767  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:08,982 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00015752016  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:11,087 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00033431718  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.3]% of [20470]MiB
2023-07-10 17:07:13,181 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00012578003  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:15,296 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00012907815  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:17,500 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00014467312  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:19,704 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0002000313  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:21,911 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00012135926  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:24,068 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0024068693  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:26,270 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.000589801  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:26,736 [INFO] [metadata.py:55] train_wall_time: 23.145099878311157
2023-07-10 17:07:26,736 [INFO] [metadata.py:55] train_loss: 0.0025275956623715956
2023-07-10 17:07:26,737 [INFO] [metadata.py:55] train_accuracy: 0.999359130859375
2023-07-10 17:07:26,737 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:07:27,621 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8724577  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:28,472 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2869315  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:28,847 [INFO] [metadata.py:55] test_wall_time: 2.109318494796753
2023-07-10 17:07:28,847 [INFO] [metadata.py:55] test_loss: 2.00126016899279
2023-07-10 17:07:28,847 [INFO] [metadata.py:55] test_accuracy: 0.5680732484076433
2023-07-10 17:07:28,852 [INFO] [train.py:190] Epoch: 210
2023-07-10 17:07:29,440 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:07:30,355 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00022130448  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:32,600 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00015678536  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:34,868 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00010689229  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:37,096 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00023143436  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:39,308 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00031364808  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:41,465 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.11765045  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:43,552 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00054616877  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:45,652 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00026552277  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:47,809 [INFO] [trainer.py:122]   batch 800/1024  loss: 8.2827355e-05  lr: 0.0004613  cpu_mem: 23.4%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:49,968 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00081477547  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:52,158 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.0001218187  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:07:52,617 [INFO] [metadata.py:55] train_wall_time: 23.177181005477905
2023-07-10 17:07:52,617 [INFO] [metadata.py:55] train_loss: 0.0026243711124607216
2023-07-10 17:07:52,618 [INFO] [metadata.py:55] train_accuracy: 0.9992523193359375
2023-07-10 17:07:52,618 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:07:53,460 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7898078  cpu_mem: 23.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:54,323 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2673991  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:54,696 [INFO] [metadata.py:55] test_wall_time: 2.0778229236602783
2023-07-10 17:07:54,696 [INFO] [metadata.py:55] test_loss: 2.003338852505775
2023-07-10 17:07:54,697 [INFO] [metadata.py:55] test_accuracy: 0.5688694267515924
2023-07-10 17:07:54,701 [INFO] [train.py:190] Epoch: 211
2023-07-10 17:07:55,281 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:07:56,239 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.0006697317  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:07:58,553 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00015569315  lr: 0.0003184  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:00,745 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00014907918  lr: 0.0004355  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:02,935 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0079526436  lr: 0.0005527  cpu_mem: 24.2%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:05,184 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00010521881  lr: 0.0006699  cpu_mem: 24.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:07,466 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00011106386  lr: 0.0007871  cpu_mem: 24.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:09,725 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.001680267  lr: 0.0006957  cpu_mem: 24.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:11,968 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00011815829  lr: 0.0005785  cpu_mem: 24.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:14,269 [INFO] [trainer.py:122]   batch 800/1024  loss: 8.7438464e-05  lr: 0.0004613  cpu_mem: 24.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:16,604 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00013192339  lr: 0.0003441  cpu_mem: 24.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:18,836 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00033795371  lr: 0.000227  cpu_mem: 24.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:19,313 [INFO] [metadata.py:55] train_wall_time: 24.032171487808228
2023-07-10 17:08:19,314 [INFO] [metadata.py:55] train_loss: 0.0019403204175532096
2023-07-10 17:08:19,314 [INFO] [metadata.py:55] train_accuracy: 0.9994659423828125
2023-07-10 17:08:19,314 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:08:20,237 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7622979  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:21,086 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3209076  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:21,453 [INFO] [metadata.py:55] test_wall_time: 2.1377830505371094
2023-07-10 17:08:21,453 [INFO] [metadata.py:55] test_loss: 2.0041010243118187
2023-07-10 17:08:21,453 [INFO] [metadata.py:55] test_accuracy: 0.565187101910828
2023-07-10 17:08:21,458 [INFO] [train.py:190] Epoch: 212
2023-07-10 17:08:22,019 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:08:22,970 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00010358918  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:25,141 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00021810722  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:27,387 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00024085787  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:29,539 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00010957239  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:31,634 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0046198564  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:33,720 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.010305574  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:35,893 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00020248095  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:38,108 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00017061265  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:40,310 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0026550659  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:42,552 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00019819137  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:08:44,779 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00014065714  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:45,280 [INFO] [metadata.py:55] train_wall_time: 23.260826349258423
2023-07-10 17:08:45,281 [INFO] [metadata.py:55] train_loss: 0.002066840257242575
2023-07-10 17:08:45,281 [INFO] [metadata.py:55] train_accuracy: 0.9994354248046875
2023-07-10 17:08:45,281 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:08:46,193 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7808568  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:47,012 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3511713  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:47,375 [INFO] [metadata.py:55] test_wall_time: 2.0930638313293457
2023-07-10 17:08:47,375 [INFO] [metadata.py:55] test_loss: 2.0316861533814934
2023-07-10 17:08:47,375 [INFO] [metadata.py:55] test_accuracy: 0.5645899681528662
2023-07-10 17:08:47,380 [INFO] [train.py:190] Epoch: 213
2023-07-10 17:08:47,947 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:08:48,881 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00011745461  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:51,168 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00015407668  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:53,388 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00013790569  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:55,553 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.0043663955  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:57,706 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0002221289  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:08:59,828 [INFO] [trainer.py:122]   batch 500/1024  loss: 7.6413562e-05  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:02,008 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00011509858  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:04,184 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.0078462446  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:06,337 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.001540972  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:08,475 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00011754967  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:10,615 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00010552454  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:11,077 [INFO] [metadata.py:55] train_wall_time: 23.12959122657776
2023-07-10 17:09:11,077 [INFO] [metadata.py:55] train_loss: 0.002600347417079263
2023-07-10 17:09:11,077 [INFO] [metadata.py:55] train_accuracy: 0.9993133544921875
2023-07-10 17:09:11,077 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:09:11,960 [INFO] [trainer.py:169]   batch 0/157  loss: 1.8336657  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:12,811 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3262196  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:13,165 [INFO] [metadata.py:55] test_wall_time: 2.0868146419525146
2023-07-10 17:09:13,165 [INFO] [metadata.py:55] test_loss: 2.0084617039200605
2023-07-10 17:09:13,165 [INFO] [metadata.py:55] test_accuracy: 0.5647890127388535
2023-07-10 17:09:13,170 [INFO] [train.py:190] Epoch: 214
2023-07-10 17:09:13,737 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:09:14,744 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00021561865  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:16,915 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00091538829  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:19,059 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00017238918  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:21,134 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00025503099  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:23,193 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0019162453  lr: 0.0006699  cpu_mem: 23.4%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:25,324 [INFO] [trainer.py:122]   batch 500/1024  loss: 8.4702791e-05  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:27,415 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.0001269865  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:29,482 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00010934045  lr: 0.0005785  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:31,566 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00023568797  lr: 0.0004613  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:33,615 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00010283042  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:35,712 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00016061148  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:36,166 [INFO] [metadata.py:55] train_wall_time: 22.428914308547974
2023-07-10 17:09:36,166 [INFO] [metadata.py:55] train_loss: 0.0019212890374049607
2023-07-10 17:09:36,166 [INFO] [metadata.py:55] train_accuracy: 0.99945068359375
2023-07-10 17:09:36,166 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:09:37,058 [INFO] [trainer.py:169]   batch 0/157  loss: 1.862619  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:37,897 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2681191  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:38,242 [INFO] [metadata.py:55] test_wall_time: 2.075261354446411
2023-07-10 17:09:38,243 [INFO] [metadata.py:55] test_loss: 1.985734857571353
2023-07-10 17:09:38,243 [INFO] [metadata.py:55] test_accuracy: 0.5720541401273885
2023-07-10 17:09:38,247 [INFO] [train.py:190] Epoch: 215
2023-07-10 17:09:38,875 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:09:39,772 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00010275853  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:41,920 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00020175782  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:09:44,144 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00020433147  lr: 0.0004355  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:46,322 [INFO] [trainer.py:122]   batch 300/1024  loss: 8.0341844e-05  lr: 0.0005527  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:48,525 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00011483514  lr: 0.0006699  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:50,694 [INFO] [trainer.py:122]   batch 500/1024  loss: 9.9933633e-05  lr: 0.0007871  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:52,851 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00011443604  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:55,035 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00011189595  lr: 0.0005785  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:57,189 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.005604072  lr: 0.0004613  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:09:59,345 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.001561025  lr: 0.0003441  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:01,567 [INFO] [trainer.py:122]   batch 1000/1024  loss: 7.0559872e-05  lr: 0.000227  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:02,039 [INFO] [metadata.py:55] train_wall_time: 23.164003133773804
2023-07-10 17:10:02,040 [INFO] [metadata.py:55] train_loss: 0.0021405284707114447
2023-07-10 17:10:02,040 [INFO] [metadata.py:55] train_accuracy: 0.9994049072265625
2023-07-10 17:10:02,040 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:10:02,952 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7799926  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:03,842 [INFO] [trainer.py:169]   batch 100/157  loss: 2.3564703  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:04,207 [INFO] [metadata.py:55] test_wall_time: 2.1659374237060547
2023-07-10 17:10:04,207 [INFO] [metadata.py:55] test_loss: 1.9799781620122825
2023-07-10 17:10:04,207 [INFO] [metadata.py:55] test_accuracy: 0.5718550955414012
2023-07-10 17:10:04,212 [INFO] [train.py:190] Epoch: 216
2023-07-10 17:10:04,794 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:10:05,792 [INFO] [trainer.py:122]   batch 0/1024  loss: 8.7704269e-05  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:08,095 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00023884556  lr: 0.0003184  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:10,205 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00010832778  lr: 0.0004355  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:12,368 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00014428767  lr: 0.0005527  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:14,511 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.0001521503  lr: 0.0006699  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:16,663 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00011754208  lr: 0.0007871  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:18,780 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00011316733  lr: 0.0006957  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:20,948 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00011368208  lr: 0.0005785  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:23,096 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.00042887632  lr: 0.0004613  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:25,245 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.0001062611  lr: 0.0003441  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:27,377 [INFO] [trainer.py:122]   batch 1000/1024  loss: 0.00027257146  lr: 0.000227  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:27,849 [INFO] [metadata.py:55] train_wall_time: 23.054040670394897
2023-07-10 17:10:27,849 [INFO] [metadata.py:55] train_loss: 0.0016796887509826774
2023-07-10 17:10:27,849 [INFO] [metadata.py:55] train_accuracy: 0.9995574951171875
2023-07-10 17:10:27,849 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:10:28,772 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7997333  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:29,608 [INFO] [trainer.py:169]   batch 100/157  loss: 2.2365184  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:29,979 [INFO] [metadata.py:55] test_wall_time: 2.128519296646118
2023-07-10 17:10:29,979 [INFO] [metadata.py:55] test_loss: 1.9992847996912184
2023-07-10 17:10:29,979 [INFO] [metadata.py:55] test_accuracy: 0.5707603503184714
2023-07-10 17:10:29,984 [INFO] [train.py:190] Epoch: 217
2023-07-10 17:10:30,579 [INFO] [metadata.py:55] learning_rate: 0.0004
2023-07-10 17:10:31,473 [INFO] [trainer.py:122]   batch 0/1024  loss: 0.00012197412  lr: 0.0002012  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:33,796 [INFO] [trainer.py:122]   batch 100/1024  loss: 0.00014915665  lr: 0.0003184  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:36,136 [INFO] [trainer.py:122]   batch 200/1024  loss: 0.00011288472  lr: 0.0004355  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:38,452 [INFO] [trainer.py:122]   batch 300/1024  loss: 0.00021557978  lr: 0.0005527  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:40,712 [INFO] [trainer.py:122]   batch 400/1024  loss: 0.00015649573  lr: 0.0006699  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:42,904 [INFO] [trainer.py:122]   batch 500/1024  loss: 0.00015280009  lr: 0.0007871  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:45,134 [INFO] [trainer.py:122]   batch 600/1024  loss: 0.00012874768  lr: 0.0006957  cpu_mem: 23.3%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:47,565 [INFO] [trainer.py:122]   batch 700/1024  loss: 0.00013200115  lr: 0.0005785  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:49,748 [INFO] [trainer.py:122]   batch 800/1024  loss: 0.0024346849  lr: 0.0004613  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:51,890 [INFO] [trainer.py:122]   batch 900/1024  loss: 0.00013791854  lr: 0.0003441  cpu_mem: 23.4%  gpu_mem: [8.4]% of [20470]MiB
2023-07-10 17:10:54,029 [INFO] [trainer.py:122]   batch 1000/1024  loss: 8.1995226e-05  lr: 0.000227  cpu_mem: 23.4%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:10:54,484 [INFO] [metadata.py:55] train_wall_time: 23.905157327651978
2023-07-10 17:10:54,485 [INFO] [metadata.py:55] train_loss: 0.0018719910083788704
2023-07-10 17:10:54,485 [INFO] [metadata.py:55] train_accuracy: 0.999481201171875
2023-07-10 17:10:54,485 [INFO] [train.py:200]   evaluating against test data
2023-07-10 17:10:55,354 [INFO] [trainer.py:169]   batch 0/157  loss: 1.7761101  cpu_mem: 23.2%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:10:56,212 [INFO] [trainer.py:169]   batch 100/157  loss: 2.1378875  cpu_mem: 23.3%  gpu_mem: [8.5]% of [20470]MiB
2023-07-10 17:10:56,574 [INFO] [metadata.py:55] test_wall_time: 2.088693141937256
2023-07-10 17:10:56,575 [INFO] [metadata.py:55] test_loss: 2.0143189817477185
2023-07-10 17:10:56,575 [INFO] [metadata.py:55] test_accuracy: 0.5684713375796179
2023-07-10 17:10:56,579 [INFO] [train.py:227] Total WallTime: 5760.4162011146545seconds
